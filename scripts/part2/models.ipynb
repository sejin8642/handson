{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7d6c62-a4a0-439f-b77c-ab25b7dd3043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f7c372-80f5-4b00-8d86-989a185ebfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_path = str(Path.home()/'gd'/'projects')\n",
    "\n",
    "sys.path.insert(0, project_path + '/ftnmr/scripts')\n",
    "sys.path.insert(0, project_path + '/projnmr/scripts')\n",
    "sys.path.insert(0, project_path + '/handson/scripts/part2')\n",
    "sys.path.insert(0, project_path + '/mods/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91040b55-0159-48ba-8f9e-bbf6b2d7f263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ftnmr\n",
    "import projnmr\n",
    "import handson\n",
    "import mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076bdc0e-0897-41af-922a-6ab04e918d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import random\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69489b61-cf83-4dff-976f-c018d86d4c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# for error \"not creating xla devices tf_xla_enable_xla_devices not set\"\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#TF_XLA_FLAGS is an environment variable used by TensorFlow's XLA (Accelerated Linear Algebra) \n",
    "#compiler to control its behavior. In this case, setting TF_XLA_FLAGS to \n",
    "#--tf_xla_enable_xla_devices enables the XLA compiler to use all available XLA devices, \n",
    "#such as GPUs or TPUs, for faster execution of TensorFlow computations.\n",
    "\n",
    "# for error \"Successfully opened dynamic library libcudart.so.10.1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e641b883-5dec-4722-aea7-14f6113a476a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to os.environ['TF_XLA_FLAGS'], but preferred way to enable XLA\n",
    "tf.config.optimizer.set_jit(True) \n",
    "\n",
    "tf.__version__ # TF version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da975d28-9400-4098-bcc8-78e4285ed055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/physical_device:CPU:0\n",
      "/physical_device:XLA_CPU:0\n",
      "/physical_device:GPU:0\n",
      "/physical_device:XLA_GPU:0\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.get_visible_devices()\n",
    "for dev in devices:\n",
    "    print(dev.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f37a21f-0c8c-4f7a-ace7-fedf5ec83951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e94d197-ab48-4036-9742-6b15bf58614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Total memory: 24576.0 MB\n",
      "       Free memory: 24054.375 MB\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "gpus = pynvml.nvmlDeviceGetCount()\n",
    "for i in range(gpus):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU {i}: Total memory: {info.total / (1024**2)} MB\")\n",
    "    print(f\"       Free memory: {info.free / (1024**2)} MB\")\n",
    "\n",
    "pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2cc9c-c1d4-4d93-a7dd-aa10a4aaf0f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## fully connected model with flatten input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14c87d0-cc56-48a0-9e63-a8f81b9e7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d127b31-98d7-4fcb-a371-5adff6a31ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # add flatten layer to the model first\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # add dense layer with 300 neurons second\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # third\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # last, which is output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c268ced8-7dae-441e-961b-5d6bd867e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495c9c41-dfee-4e31-b141-dd44dd4429c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'weight_decay': None,\n",
       " 'clipnorm': None,\n",
       " 'global_clipnorm': None,\n",
       " 'clipvalue': None,\n",
       " 'use_ema': False,\n",
       " 'ema_momentum': 0.99,\n",
       " 'ema_overwrite_frequency': None,\n",
       " 'jit_compile': True,\n",
       " 'is_legacy_optimizer': False,\n",
       " 'learning_rate': 0.01,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Keras, compile() is a method used to configure the learning process of a model. \n",
    "# This method defines the loss function, optimizer, and metrics for training\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", # sparse when categories are in integers\n",
    "    optimizer=\"sgd\", # Stochastic Gradient Descent\n",
    "    metrics=[\"accuracy\"]) # performance metrics for each epoch on validataion dataset\n",
    "\n",
    "# An optimizer is an gradient descent method algorithm to update the weights and biases\n",
    "model.optimizer.get_config() # default mini batch size for SGD is 32 in keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b3b795-479a-4501-8a5f-32f122c0051f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7192 - accuracy: 0.7661 - val_loss: 0.5073 - val_accuracy: 0.8338\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4900 - accuracy: 0.8295 - val_loss: 0.4574 - val_accuracy: 0.8430\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4446 - accuracy: 0.8453 - val_loss: 0.4217 - val_accuracy: 0.8572\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4177 - accuracy: 0.8527 - val_loss: 0.3932 - val_accuracy: 0.8634\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3976 - accuracy: 0.8601 - val_loss: 0.3940 - val_accuracy: 0.8612\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3805 - accuracy: 0.8664 - val_loss: 0.3911 - val_accuracy: 0.8618\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3661 - accuracy: 0.8708 - val_loss: 0.3672 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3543 - accuracy: 0.8744 - val_loss: 0.3567 - val_accuracy: 0.8758\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8784 - val_loss: 0.3549 - val_accuracy: 0.8740\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8808 - val_loss: 0.3582 - val_accuracy: 0.8690\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3253 - accuracy: 0.8834 - val_loss: 0.3329 - val_accuracy: 0.8828\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3178 - accuracy: 0.8856 - val_loss: 0.3359 - val_accuracy: 0.8800\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3100 - accuracy: 0.8881 - val_loss: 0.3271 - val_accuracy: 0.8798\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3033 - accuracy: 0.8913 - val_loss: 0.3213 - val_accuracy: 0.8850\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2977 - accuracy: 0.8931 - val_loss: 0.3273 - val_accuracy: 0.8778\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2911 - accuracy: 0.8955 - val_loss: 0.3150 - val_accuracy: 0.8854\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2849 - accuracy: 0.8960 - val_loss: 0.3196 - val_accuracy: 0.8840\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2806 - accuracy: 0.8988 - val_loss: 0.3103 - val_accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2751 - accuracy: 0.8998 - val_loss: 0.3142 - val_accuracy: 0.8848\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2692 - accuracy: 0.9024 - val_loss: 0.3340 - val_accuracy: 0.8772\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2656 - accuracy: 0.9050 - val_loss: 0.3062 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2608 - accuracy: 0.9062 - val_loss: 0.3009 - val_accuracy: 0.8890\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2560 - accuracy: 0.9079 - val_loss: 0.2997 - val_accuracy: 0.8942\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2521 - accuracy: 0.9087 - val_loss: 0.3011 - val_accuracy: 0.8892\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2482 - accuracy: 0.9107 - val_loss: 0.3017 - val_accuracy: 0.8912\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2441 - accuracy: 0.9116 - val_loss: 0.2951 - val_accuracy: 0.8942\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2409 - accuracy: 0.9131 - val_loss: 0.2992 - val_accuracy: 0.8918\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2365 - accuracy: 0.9155 - val_loss: 0.3016 - val_accuracy: 0.8892\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2330 - accuracy: 0.9164 - val_loss: 0.2991 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2291 - accuracy: 0.9183 - val_loss: 0.2974 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid)) # fit method initiates training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce9478-42b7-4f80-a074-80509293e386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## basic keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2f5c5fc7-4e01-4896-a377-c47c02d877f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractRNNCell          Activation               ActivityRegularization   Add                      AdditiveAttention        AlphaDropout             Attention                Average                  AveragePooling1D         AveragePooling2D         AveragePooling3D         AvgPool1D                AvgPool2D                AvgPool3D                BatchNormalization       Bidirectional            CategoryEncoding         CenterCrop               Concatenate              Conv1D                   Conv1DTranspose          Conv2D                   Conv2DTranspose          Conv3D                   Conv3DTranspose          ConvLSTM1D               ConvLSTM2D               ConvLSTM3D               Convolution1D            Convolution1DTranspose   Convolution2D            Convolution2DTranspose   Convolution3D            Convolution3DTranspose   Cropping1D               Cropping2D               Cropping3D               Dense                    DenseFeatures            DepthwiseConv1D          DepthwiseConv2D          Discretization           Dot                      Dropout                  ELU                      EinsumDense              Embedding                Flatten                  GRU                      GRUCell                  GaussianDropout          GaussianNoise            GlobalAveragePooling1D   GlobalAveragePooling2D   GlobalAveragePooling3D   GlobalAvgPool1D          GlobalAvgPool2D          GlobalAvgPool3D          GlobalMaxPool1D          GlobalMaxPool2D          GlobalMaxPool3D          GlobalMaxPooling1D       GlobalMaxPooling2D       GlobalMaxPooling3D       Hashing                  InputLayer               IntegerLookup            LSTM                     LSTMCell                 Lambda                   Layer                    LayerNormalization       LeakyReLU                LocallyConnected1D       LocallyConnected2D       Masking                  MaxPool1D                MaxPool2D                MaxPool3D                MaxPooling1D             MaxPooling2D             MaxPooling3D             Maximum                  Minimum                  MultiHeadAttention       Multiply                 Normalization            PReLU                    Permute                  RNN                      RandomBrightness         RandomContrast           RandomCrop               RandomFlip               RandomHeight             RandomRotation           RandomTranslation        RandomWidth              RandomZoom               ReLU                     RepeatVector             Rescaling                Reshape                  Resizing                 SeparableConv1D          SeparableConv2D          SeparableConvolution1D   SeparableConvolution2D   SimpleRNN                SimpleRNNCell            Softmax                  SpatialDropout1D         SpatialDropout2D         SpatialDropout3D         StackedRNNCells          StringLookup             Subtract                 TextVectorization        ThresholdedReLU          TimeDistributed          UnitNormalization        UpSampling1D             UpSampling2D             UpSampling3D             Wrapper                  ZeroPadding1D            ZeroPadding2D            ZeroPadding3D            "
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.layers.pooling.average_pooling3d.AveragePooling3D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AveragePooling3D\n"
     ]
    }
   ],
   "source": [
    "# list of laysers in keras (ignore Layer method below)\n",
    "layers = mods.list_attr('layers')\n",
    "\n",
    "# randomly select a layer name\n",
    "rand_layer = random.choice(layers) # randomly select an layer name\n",
    "\n",
    "# layer class with the above layer name with 300 neurons\n",
    "rand_layer = getattr(keras.layers, rand_layer)\n",
    "display(rand_layer)\n",
    "\n",
    "# get the name of the chosen layer \n",
    "layer_name = rand_layer.__name__\n",
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb160f-ca66-4a9c-b878-a3110928a3f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## basic keras layer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816e2236-20e6-4403-ad87-dea942db822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units: This specifies the number of neurons in the layer\n",
    "# use_bias: This specifies whether to include a bias term in the layer (default True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507dfb1b-b008-4d86-87ec-04de356eecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elu                 exponential         gelu                hard_sigmoid        linear              relu                selu                sigmoid             softmax             softplus            softsign            swish               tanh                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function keras.activations.tanh(x)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n"
     ]
    }
   ],
   "source": [
    "# activation: This specifies the activation function to be used in the layer.\n",
    "\n",
    "# the below code lists activation functions (ignore deserialize, get, and serialize methods)\n",
    "activations = []\n",
    "for act in dir(keras.activations):\n",
    "    if not act.startswith('_') and act not in ['deserialize', 'get', 'serialize']:\n",
    "        activations.append(act)\n",
    "        print(act.ljust(20), end='')\n",
    "\n",
    "# randomly select an activation function name\n",
    "rand_act = random.choice(activations) \n",
    "\n",
    "# dense layer instantiation with the above activation name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, activation=rand_act)\n",
    "display(dense_layer.activation)\n",
    "\n",
    "# get the name of the activation function from the above layer \n",
    "act_name = dense_layer.activation.__name__\n",
    "print(act_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fac56e50-747d-47a2-8824-ad8aff992eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all activation functions on one figure\n",
    "# Define the x values\n",
    "x = tf.linspace(-5., 5., 200)\n",
    "\n",
    "# Define the activation functions with out exponential\n",
    "activation_functions = [\n",
    "    tf.nn.elu, \n",
    "    tf.nn.gelu, \n",
    "    tf.nn.relu, \n",
    "    tf.nn.selu, \n",
    "    tf.nn.sigmoid, \n",
    "    tf.nn.softmax, \n",
    "    tf.nn.softplus, \n",
    "    tf.nn.softsign, \n",
    "    tf.nn.swish, \n",
    "    tf.nn.tanh]\n",
    "\n",
    "# Plot the activation functions\n",
    "for activation in activation_functions[:]: # select the ones you want to plot\n",
    "    with tf.compat.v1.Session().as_default():\n",
    "        plt.plot(x, activation(tf.constant(x)).numpy(), label=activation.__name__)\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Activation functions')\n",
    "plt.legend(loc='best', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "30064ee5-d4f2-4b20-b8c4-88223a8a5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant                 GlorotNormal             GlorotUniform            HeNormal                 HeUniform                Identity                 Initializer              LecunNormal              LecunUniform             Ones                     Orthogonal               RandomNormal             RandomUniform            TruncatedNormal          VarianceScaling          Zeros                    "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.initializers.initializers_v2.HeNormal at 0x2ba0cf4b5f00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeNormal\n"
     ]
    }
   ],
   "source": [
    "# kernel_initializer: This specifies the method for initializing the weights of the layer\n",
    "# bias_initializer is for biases\n",
    "\n",
    "# list of kernel initializers in keras (ignore Initializer method below)\n",
    "initializers = mods.list_attr('initializers')\n",
    "\n",
    "# randomly select an kernel initializer name\n",
    "rand_init = random.choice(initializers) \n",
    "\n",
    "# dense layer instantiation with the above kernel initializer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_initializer=rand_init)\n",
    "display(dense_layer.kernel_initializer)\n",
    "\n",
    "# get the name of the kernel initializer from the above layer \n",
    "init_name = dense_layer.kernel_initializer.__class__.__name__\n",
    "print(init_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "542d30c2-6ec6-47db-a408-de941d8991e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1                       L1L2                     L2                       OrthogonalRegularizer    Regularizer              "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.Regularizer at 0x2ba0cf4b65c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularizer\n"
     ]
    }
   ],
   "source": [
    "# kernel_regularizer: This specifies the regularization method to be applied to the weights \n",
    "# of the layer. bias_regularizer is for biases\n",
    "\n",
    "# list of kernel regularizers in keras (ignore Regularizer method below)\n",
    "kernel_regularizer = mods.list_attr('regularizers')\n",
    "# randomly select a kernel regularizer name\n",
    "rand_reg = random.choice(kernel_regularizer) \n",
    "\n",
    "# dense layer instantiation with the above kernel regularizer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_regularizer=rand_reg)\n",
    "display(dense_layer.kernel_regularizer)\n",
    "\n",
    "# get the name of the kernel regularizer from the above layer \n",
    "reg_name = dense_layer.kernel_regularizer.__class__.__name__\n",
    "print(reg_name)\n",
    "\n",
    "# activity_regularizer: regularization method applied to the output of the layer\n",
    "# same regularizers from kernel regularizations can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "e8d15c15-5a88-4cba-94a8-62e88f479183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint               MaxNorm                  MinMaxNorm               NonNeg                   RadialConstraint         UnitNorm                 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.constraints.MaxNorm at 0x2ba0f6692230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxNorm\n"
     ]
    }
   ],
   "source": [
    "# kernel_constraint: This specifies the constraint to be applied to the weights of the layer.\n",
    "# bias_constraint is for biases\n",
    "# kernel constraints enforce constraints directly on the weights of the neural network.\n",
    "# whereas kernel regularizers add a penalty term to the loss function \n",
    "\n",
    "# list of kernel constraints in keras (ignore Constraint method below)\n",
    "kernel_constraints = mods.list_attr('constraints')\n",
    "\n",
    "# randomly select a kernel constraints name\n",
    "rand_con = random.choice(kernel_constraints) \n",
    "\n",
    "# dense layer instantiation with the above kernel regularizer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_constraint=rand_con)\n",
    "display(dense_layer.kernel_constraint)\n",
    "\n",
    "# get the name of the kernel regularizer from the above layer \n",
    "con_name = dense_layer.kernel_constraint.__class__.__name__\n",
    "print(con_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe858618-6083-4c73-86d2-91b4728ff81e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## loss functions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "2d0bc2be-9155-4209-a61f-6a0040c05476",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryCrossentropy                 BinaryFocalCrossentropy            CategoricalCrossentropy            CategoricalHinge                   CosineSimilarity                   Hinge                              Huber                              KLD                                KLDivergence                       LogCosh                            Loss                               MAE                                MAPE                               MSE                                MSLE                               MeanAbsoluteError                  MeanAbsolutePercentageError        MeanSquaredError                   MeanSquaredLogarithmicError        Poisson                            Reduction                          SparseCategoricalCrossentropy      SquaredHinge                       binary_crossentropy                binary_focal_crossentropy          categorical_crossentropy           categorical_hinge                  cosine_similarity                  deserialize                        get                                hinge                              huber                              kl_divergence                      kld                                kullback_leibler_divergence        log_cosh                           logcosh                            mae                                mape                               mean_absolute_error                mean_absolute_percentage_error     mean_squared_error                 mean_squared_logarithmic_error     mse                                msle                               poisson                            serialize                          sparse_categorical_crossentropy    squared_hinge                      \n",
      "CosineSimilarity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CosineSimilarity'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss: This specifies the loss function (or cost function) to be used in the layer.\n",
    "\n",
    "# the below code lists loss functions (ignore deserialize, get, and serialize methods)\n",
    "losses = []\n",
    "for loss in dir(keras.losses):\n",
    "    if not loss.startswith('_') and act not in ['deserialize', 'get', 'serialize']:\n",
    "        losses.append(loss)\n",
    "        print(loss.ljust(35), end='')\n",
    "\n",
    "# randomly select an loss function name\n",
    "rand_loss = random.choice(losses) # randomly select an activation function name\n",
    "print()\n",
    "print(rand_loss)\n",
    "\n",
    "# load pretrained VGG16 model\n",
    "model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# compile the model with the randomly chosen loss function\n",
    "model.compile(loss=rand_loss)\n",
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8705f6-5af0-46bb-b64e-4c5f9d02bd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC                                               Accuracy                                          BinaryAccuracy                                    BinaryCrossentropy                                BinaryIoU                                         CategoricalAccuracy                               CategoricalCrossentropy                           CategoricalHinge                                  CosineSimilarity                                  FalseNegatives                                    FalsePositives                                    Hinge                                             IoU                                               KLDivergence                                      LogCoshError                                      Mean                                              MeanAbsoluteError                                 MeanAbsolutePercentageError                       MeanIoU                                           MeanMetricWrapper                                 MeanRelativeError                                 MeanSquaredError                                  MeanSquaredLogarithmicError                       MeanTensor                                        Metric                                            OneHotIoU                                         OneHotMeanIoU                                     Poisson                                           Precision                                         PrecisionAtRecall                                 Recall                                            RecallAtPrecision                                 RootMeanSquaredError                              SensitivityAtSpecificity                          SparseCategoricalAccuracy                         SparseCategoricalCrossentropy                     SparseTopKCategoricalAccuracy                     SpecificityAtSensitivity                          SquaredHinge                                      Sum                                               TopKCategoricalAccuracy                           TrueNegatives                                     TruePositives                                     \n",
      "SparseCategoricalAccuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of metrics in keras (ignore Metric method below)\n",
    "metrics = mods.list_attr('metrics', 50)\n",
    "print()\n",
    "\n",
    "# randomly select a metric name\n",
    "rand_metric = random.choice(metrics) # randomly select an activation function name\n",
    "\n",
    "# load pretrained VGG16 model\n",
    "model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# compile the model with the randomly chosen metric\n",
    "model.compile(metrics=[rand_metric])\n",
    "\n",
    "print(rand_metric)\n",
    "model.metrics # it will return an empty list since the model is never trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ea8d0-aa77-403d-aaa1-ea3695ad39e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model history and evaluation (previous model training needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc0f932-b283-49b5-b095-9e5fb2a618ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6e3d05a-8b38-4bd8-93df-b88d80a793d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys(), end='\\n\\n')\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(val_accuracy)), val_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ca71e4-7298-4c20-b51e-b6b04e62116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 992us/step - loss: 60.1161 - accuracy: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[60.116050720214844, 0.8503000140190125]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bb6f4-28ad-45cf-905b-f1b2c971a261",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93caeec1-a726-40ba-a23f-f55aac57430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee7d6aea-377f-4688-92e8-be5bce1a2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba6902b9-74b4-424a-9b70-be9814de5d76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8334 - val_loss: 0.6144\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.4973\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4847\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9033 - val_loss: 0.5254\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7038 - val_loss: 0.4664\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.4346\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4142\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4094\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4020\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3954\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3977\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3592 - val_loss: 0.3903\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3900\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3845\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3848\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3840\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3821\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3829\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3721\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3731\n",
      "162/162 [==============================] - 0s 786us/step - loss: 0.3539\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c36818d-0311-4d29-b1ca-171b79491a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353873074054718"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d382d2-d256-4101-a9fd-b2d4752379cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with hidden concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a61bf2-8dea-4a64-894c-32a9987b64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2856f740-b95d-4580-b77c-dafbd125cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c29ab04-4cc5-4c2c-bbc5-2ee819b014d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7307 - val_loss: 3.7913\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# it does not work well\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3b55-cd29-47a4-81e4-9dc6d8a46a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## two inputs model with concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f332dd-7cef-49d1-8835-a12ee8b711b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15f61c67-d27e-44f3-828c-0f5ff6511b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9340c31c-c01a-4296-8ee5-dbf1ef9c58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d895d54c-a784-467d-971e-3a3a45e474c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3)) \n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbe126c3-01a9-4324-8886-8b3ef93c9e61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2099 - val_loss: 0.9340\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8194 - val_loss: 0.7372\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7093 - val_loss: 0.6811\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6663 - val_loss: 0.6494\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6383 - val_loss: 0.6266\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6059\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.5857\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.5707\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5546\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5515 - val_loss: 0.5409\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.5288\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.5194\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5097\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.5017\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5010 - val_loss: 0.4955\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.4889\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4946 - val_loss: 0.4863\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4891 - val_loss: 0.4800\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4850\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4734\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), \n",
    "    y_train, \n",
    "    epochs=20,\n",
    "    validation_data=((X_valid_A, X_valid_B),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a758b4d8-5a45-40b0-a73c-56041085bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 865us/step - loss: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.486760675907135"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7917f9-f80d-4cad-a5bf-c0eb5c647879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## two inputs and two outputs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbafc9a-24bf-4d52-bb92-522bfe4b06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01fe8dd5-dc1f-4519-8c58-41ac22b74bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f35cca9d-bcc1-4610-893e-73d5fd9ad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07ae7f2a-9181-48a2-81b6-2368ca4766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first output is more important, so more weight is assigned on it for loss function\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1e79fb0-3bc6-43a7-bce1-990f9d1f90c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9012 - main_output_loss: 0.7970 - aux_output_loss: 1.8398 - val_loss: 1.0476 - val_main_output_loss: 1.0383 - val_aux_output_loss: 1.1313\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6920 - main_output_loss: 0.6541 - aux_output_loss: 1.0333 - val_loss: 0.6091 - val_main_output_loss: 0.5581 - val_aux_output_loss: 1.0682\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5399 - main_output_loss: 0.4935 - aux_output_loss: 0.9581 - val_loss: 0.6482 - val_main_output_loss: 0.6223 - val_aux_output_loss: 0.8817\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5700 - main_output_loss: 0.5435 - aux_output_loss: 0.8091 - val_loss: 0.5049 - val_main_output_loss: 0.4736 - val_aux_output_loss: 0.7862\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - main_output_loss: 0.4484 - aux_output_loss: 0.7354 - val_loss: 0.4858 - val_main_output_loss: 0.4574 - val_aux_output_loss: 0.7415\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4670 - main_output_loss: 0.4418 - aux_output_loss: 0.6933 - val_loss: 0.4743 - val_main_output_loss: 0.4475 - val_aux_output_loss: 0.7160\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4493 - main_output_loss: 0.4253 - aux_output_loss: 0.6655 - val_loss: 0.4676 - val_main_output_loss: 0.4415 - val_aux_output_loss: 0.7029\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4402 - main_output_loss: 0.4171 - aux_output_loss: 0.6479 - val_loss: 0.4542 - val_main_output_loss: 0.4309 - val_aux_output_loss: 0.6636\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4301 - main_output_loss: 0.4081 - aux_output_loss: 0.6281 - val_loss: 0.4458 - val_main_output_loss: 0.4229 - val_aux_output_loss: 0.6525\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4251 - main_output_loss: 0.4042 - aux_output_loss: 0.6136 - val_loss: 0.4437 - val_main_output_loss: 0.4219 - val_aux_output_loss: 0.6395\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4185 - main_output_loss: 0.3982 - aux_output_loss: 0.6009 - val_loss: 0.4390 - val_main_output_loss: 0.4155 - val_aux_output_loss: 0.6504\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4102 - main_output_loss: 0.3903 - aux_output_loss: 0.5891 - val_loss: 0.4310 - val_main_output_loss: 0.4101 - val_aux_output_loss: 0.6191\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - main_output_loss: 0.3850 - aux_output_loss: 0.5765 - val_loss: 0.4403 - val_main_output_loss: 0.4217 - val_aux_output_loss: 0.6078\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3996 - main_output_loss: 0.3810 - aux_output_loss: 0.5665 - val_loss: 0.5035 - val_main_output_loss: 0.4946 - val_aux_output_loss: 0.5831\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3958 - main_output_loss: 0.3777 - aux_output_loss: 0.5588 - val_loss: 0.4358 - val_main_output_loss: 0.4200 - val_aux_output_loss: 0.5783\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3907 - main_output_loss: 0.3729 - aux_output_loss: 0.5511 - val_loss: 0.4124 - val_main_output_loss: 0.3947 - val_aux_output_loss: 0.5721\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3866 - main_output_loss: 0.3695 - aux_output_loss: 0.5404 - val_loss: 0.4053 - val_main_output_loss: 0.3882 - val_aux_output_loss: 0.5593\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3819 - main_output_loss: 0.3649 - aux_output_loss: 0.5348 - val_loss: 0.4802 - val_main_output_loss: 0.4722 - val_aux_output_loss: 0.5524\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - main_output_loss: 0.3652 - aux_output_loss: 0.5281 - val_loss: 0.3991 - val_main_output_loss: 0.3829 - val_aux_output_loss: 0.5453\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - main_output_loss: 0.3593 - aux_output_loss: 0.5226 - val_loss: 0.4125 - val_main_output_loss: 0.3965 - val_aux_output_loss: 0.5567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], \n",
    "    [y_train, y_train], \n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fd740b9-dad4-461b-97c8-6844fcdcbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3910 - main_output_loss: 0.3742 - aux_output_loss: 0.5421\n",
      "0.39098742604255676 0.37419408559799194 0.5421300530433655\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "print(total_loss, main_loss, aux_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e88b5-1e4b-4843-b3bd-47824e2b128c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e832a0b-8542-42c1-914a-a5d6895728ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75ddd879-49c2-4684-94e9-d5d05d63e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint is a callback function in Keras that saves the model weights during training. \n",
    "# It allows you to save the best model observed during training based on a specified metric, \n",
    "# such as validation loss or accuracy.\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.hdf5\", save_best_only=True)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9f26f80-4712-4ee9-b03e-8f9cbb5cf745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0102 - val_loss: 1.0858\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6909 - val_loss: 0.4760\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4251\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4208\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3999\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4053\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3985\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4004\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4031\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.4025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    validation_data=(X_valid, y_valid), \n",
    "    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9aa11136-5296-4b39-a244-ee10290c107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.hdf5\") # roll back to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d79eb-6b30-4e0b-bfb5-9f2f656e1568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64c7626c-68dd-4c18-a773-4737928be829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f9ec7f48-5c78-4e70-8060-af4a99081c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping is a callback in Keras that can be used during training to automatically stop \n",
    "# training when a monitored metric stops improving. It is designed to prevent overfitting and \n",
    "# reduce training time by stopping the training process early when further training is unlikely\n",
    "# to improve the model's performance.\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# In early stopping, \"patience\" is a hyperparameter that determines the number of epochs \n",
    "# the model can undergo without improvement in the monitored quantity before stopping the \n",
    "# training process. \n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b7085dab-2f76-434e-96f3-d9d24b8e0b85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2088 - val_loss: 7.5077\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7584 - val_loss: 0.5632\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4733\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4236\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4147\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4266\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4127\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4273\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4150\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3880\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.3834\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3795\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3836\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3771\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3776\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3681\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3705\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3690\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3701\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3662\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3676\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3671\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3586\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3547\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3582\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3583\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3569\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3567\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3537\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3523\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3487\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.3437\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3441\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3412\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3505\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3483\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3420\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3408\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.3390\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3385\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3900\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3361\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3327\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3318\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3501\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.3335\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3325\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3361\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3741\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3312\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3250\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4395\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3283\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3269\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3336\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3291\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3770\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3272\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3290\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3270\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3265\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "cc4c6138-b48e-467f-b3f1-b02f726baf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 764us/step - loss: 0.3466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34658145904541016"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72763e0-dfb9-4e5c-a5ed-79bb7f7d3d4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with batch normalization layers and kernal initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61488ecc-aee4-4139-8cdf-fdd25f908da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1b810a4-2da7-4b23-9264-a1c7fcfc0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization normalizes intermediate vectors between layers. The benefits are:\n",
    "# 1. Improved training speed \n",
    "# 2. Better generalization\n",
    "# 3. Less sensitivity to weight initialization\n",
    "# 4. High tolerance on higher learning rates\n",
    "# 5. Regularization\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(15, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b79cd569-250e-4b41-bf7e-1fa1ef7c8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25aa0b53-6a2b-4c3a-b81a-ac091bb5bd54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6945 - val_loss: 0.6429\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4921 - val_loss: 0.8938\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4671 - val_loss: 1.5521\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 2.7702\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 4.2075\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 2.2570\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 4.9916\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 1.6127\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 2.9564\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 5.1739\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 1.9035\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4303 - val_loss: 1.5764\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 1.0910\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 3.1749\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 8.6971\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 4.1409\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 6.8884\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 1.0653\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 2.4973\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4305 - val_loss: 1.3900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38a387ab-0d3a-41c8-88ce-d5d56b47ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 927us/step - loss: 0.5709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5708961486816406"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4fbfad-0663-42f1-bd6c-cf6b6fe83f7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## transfer learning (skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2673d03-42fb-42c0-8427-02683ebbaced",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with dropout layers and functools.partial application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "decaf251-f309-4884-99e9-1463ae55864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.fashion_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "949116ca-d4b4-4196-8ae8-008697de29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dropout layer is a regularization layer that helps to prevent overfitting in deep \n",
    "# learning models. It works by randomly dropping out (i.e., setting to zero) a fraction of \n",
    "# the input units during training. This forces the network to learn more robust features and \n",
    "# reduces the likelihood of the network relying too heavily on any one input feature, which \n",
    "# can lead to overfitting. During inference or prediction, the dropout layer is typically \n",
    "# turned off, and the weights of the remaining neurons are scaled accordingly to ensure that \n",
    "# the expected output of the layer remains the same.\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05f1652e-8392-416c-8173-1419ad3b085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense = partial(\n",
    "    keras.layers.Dense,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "882bc711-c668-4cd0-aad1-7555a44d1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    Dense(300),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    Dense(100),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f601854-8d3c-459d-a117-d46415faadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db73bdd8-f111-4770-9aec-e4a43ea7ccc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7738 - accuracy: 0.7190 - val_loss: 0.5017 - val_accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5798 - accuracy: 0.7908 - val_loss: 0.4600 - val_accuracy: 0.8378\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5366 - accuracy: 0.8061 - val_loss: 0.4331 - val_accuracy: 0.8488\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5130 - accuracy: 0.8144 - val_loss: 0.4166 - val_accuracy: 0.8546\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4986 - accuracy: 0.8192 - val_loss: 0.4083 - val_accuracy: 0.8548\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4846 - accuracy: 0.8239 - val_loss: 0.4106 - val_accuracy: 0.8550\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4746 - accuracy: 0.8278 - val_loss: 0.3903 - val_accuracy: 0.8616\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4674 - accuracy: 0.8297 - val_loss: 0.3988 - val_accuracy: 0.8592\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4612 - accuracy: 0.8315 - val_loss: 0.3830 - val_accuracy: 0.8642\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4532 - accuracy: 0.8344 - val_loss: 0.3775 - val_accuracy: 0.8646\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4485 - accuracy: 0.8355 - val_loss: 0.3765 - val_accuracy: 0.8666\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4452 - accuracy: 0.8367 - val_loss: 0.3689 - val_accuracy: 0.8684\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4411 - accuracy: 0.8380 - val_loss: 0.3666 - val_accuracy: 0.8686\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4330 - accuracy: 0.8402 - val_loss: 0.3663 - val_accuracy: 0.8706\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4345 - accuracy: 0.8405 - val_loss: 0.3598 - val_accuracy: 0.8704\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4292 - accuracy: 0.8425 - val_loss: 0.3561 - val_accuracy: 0.8720\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4248 - accuracy: 0.8451 - val_loss: 0.3567 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4211 - accuracy: 0.8449 - val_loss: 0.3523 - val_accuracy: 0.8712\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4235 - accuracy: 0.8436 - val_loss: 0.3557 - val_accuracy: 0.8718\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4158 - accuracy: 0.8462 - val_loss: 0.3475 - val_accuracy: 0.8752\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4146 - accuracy: 0.8465 - val_loss: 0.3475 - val_accuracy: 0.8734\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4118 - accuracy: 0.8491 - val_loss: 0.3441 - val_accuracy: 0.8768\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4058 - accuracy: 0.8501 - val_loss: 0.3448 - val_accuracy: 0.8748\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4060 - accuracy: 0.8506 - val_loss: 0.3407 - val_accuracy: 0.8746\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4073 - accuracy: 0.8497 - val_loss: 0.3406 - val_accuracy: 0.8724\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4023 - accuracy: 0.8512 - val_loss: 0.3389 - val_accuracy: 0.8768\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3986 - accuracy: 0.8533 - val_loss: 0.3395 - val_accuracy: 0.8762\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3963 - accuracy: 0.8527 - val_loss: 0.3324 - val_accuracy: 0.8792\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3980 - accuracy: 0.8514 - val_loss: 0.3338 - val_accuracy: 0.8770\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3948 - accuracy: 0.8532 - val_loss: 0.3312 - val_accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b8d24db-8a58-4161-a127-c354b8cb1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37001723051071167, 0.8640000224113464]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d6a50-92c5-4db4-95e4-20129be03d40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## adding normalization layer to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b18d47-487a-444e-96bb-81dd4f52fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sejinnam/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfa046c-c7b8-4e21-8c0a-a70d073f523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple fully connected model with normalization layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Normalization(mean=0.0, variance=1.0),\n",
    "    keras.layers.Dense(32, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24f8317-7d8a-4792-8678-fbe482979eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = tf.keras.layers.Normalization() # create normalization layer\n",
    "norm_layer.adapt(X_train) # assign the layer mean and variance to those of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce216f4-9cf1-485f-9f85-7249f7d4e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final model that takes data that is not normalized\n",
    "final_model = tf.keras.Sequential([norm_layer, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f44f21b-0529-477e-8332-3a8cab359d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6be95b5-dd65-4960-a34e-048064de3329",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 2s 1ms/step - loss: 1.5499 - val_loss: 1.4351\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 3.0645 - val_loss: 1.3190\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3854 - val_loss: 1.3231\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3701 - val_loss: 1.2854\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3680 - val_loss: 1.3853\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3608 - val_loss: 1.3142\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3589 - val_loss: 1.2936\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3588 - val_loss: 1.2879\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3584 - val_loss: 1.2817\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3583 - val_loss: 1.2988\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3566 - val_loss: 1.2791\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3540 - val_loss: 1.2850\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3550 - val_loss: 1.2888\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3555 - val_loss: 1.2970\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3535 - val_loss: 1.2852\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3530 - val_loss: 1.2865\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3508 - val_loss: 1.2877\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3508 - val_loss: 1.2795\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3518 - val_loss: 1.2900\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3528 - val_loss: 1.2949\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b709ea-aaa9-42d8-ae2b-b785e330c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2976197004318237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = final_model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4792622-90a5-4612-ab9e-2c375c8b5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 8)                17        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1)                 2689      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,706\n",
      "Trainable params: 2,689\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e210c-65e8-454a-a2ae-9761e9b7e348",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## faster optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2a9e72-ac9c-4e5e-bd43-e2e668a8966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "c120010b-259c-4006-93e8-d14461cad036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model without specifying an optimizer (compile is needed)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "e271ff94-6370-4725-8abb-e1eb8cfcc1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SGD (Stochastic Gradient Descent)\n",
    "optimizer = keras.optimizers.SGD()\n",
    "\n",
    "# default configuration of SGD\n",
    "display(optimizer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "9347d2e2-0202-4412-a210-d0a7a4f23b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorter way to execute the above code\n",
    "getattr(keras.optimizers, 'SGD')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "2c38533a-3aa4-4ad8-afc0-f644dafc3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adagrad',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'initial_accumulator_value': 0.1,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaGrad optimizer default configuration\n",
    "getattr(keras.optimizers, 'Adagrad')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "99cfd405-a92a-4017-9dff-b10c0474edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'RMSprop',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'rho': 0.9,\n",
       " 'momentum': 0.0,\n",
       " 'epsilon': 1e-07,\n",
       " 'centered': False}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSprop optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'RMSprop')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "dfb79de5-6f15-4443-b4ed-73ad8514d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adam optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Adam')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "edeb0d2b-f467-4d21-8c40-99f378c794a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adamax',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adamax optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Adamax')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "89d10d22-9449-4f12-a6c8-bf99c75046f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nadam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.004,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nadam optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Nadam')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "567fcfdd-5ab9-4540-8cb9-44125ed92500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adadelta                 Adagrad                  Adam                     Adamax                   Ftrl                     Nadam                    Optimizer                RMSprop                  SGD                      \n",
      "Adamax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Adamax'"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of optimizers in keras (ignore Optimizer method below)\n",
    "optimizers = mods.list_attr('optimizers')\n",
    "\n",
    "# randomly select an kernel initializer name\n",
    "rand_opt = random.choice(optimizers)\n",
    "print()\n",
    "print(rand_opt)\n",
    "\n",
    "# model compile with the chosen optimizer\n",
    "model.compile(loss='mse', optimizer=rand_opt)\n",
    "model.optimizer.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7533383f-e97c-46a2-8ca9-08cc2af94995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3300\n",
      "Epoch 2/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.9098\n",
      "Epoch 3/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3651\n",
      "Epoch 4/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3376\n",
      "Epoch 5/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3503\n",
      "Epoch 6/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3351\n",
      "Epoch 7/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3337\n",
      "Epoch 8/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3336\n",
      "Epoch 9/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3304\n",
      "Epoch 10/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3281\n",
      "Epoch 11/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3396\n",
      "Epoch 12/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3308\n",
      "Epoch 13/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3300\n",
      "Epoch 14/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3351\n",
      "Epoch 15/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba0f664b9d0>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          epochs=15,\n",
    "          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172197c-2858-4d99-beb1-2d91f447c975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## learning rate schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00844f1-c621-4e3e-8ff8-1b053c8361f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "3c750e25-4803-486e-a584-57e715fbdc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "e79c67dc-cb05-45d1-b21f-7b3d9dcf4f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineDecay              CosineDecayRestarts      ExponentialDecay         InverseTimeDecay         PiecewiseConstantDecay   PolynomialDecay          "
     ]
    }
   ],
   "source": [
    "# A learning rate schedule is a way to adapt the learning rate during training\n",
    "# the below code lists keras builtin schedules \n",
    "schedules = []\n",
    "ignore = ['deserialize', 'LearningRateSchedule', 'serialize']\n",
    "\n",
    "for schedule in dir(keras.optimizers.schedules):\n",
    "    if not schedule.startswith('_') and schedule not in ignore:\n",
    "        schedules.append(schedule)\n",
    "        print(schedule.ljust(25), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "eafd7d47-34e6-483f-888b-0216f6c0db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay learning rate scheduler\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.05,\n",
    "    decay_rate = 0.1,\n",
    "    decay_steps = 5000)\n",
    "\n",
    "# RMSprop optimizer with the above lr_scheduler\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_scheduler)\n",
    "\n",
    "# model compile with mse loss and RMSprop optimizer\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "7cd7dce0-d50c-4a83-80e0-b55d78f0490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6544 - val_loss: 0.4351\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 5.6052\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.5103\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.6161\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4282\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3988\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3761\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3722\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3676\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3665\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3664\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3644\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3656\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3645\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3638\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3623\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3629\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3621\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3621\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3632\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3618\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3620\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3618\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3614\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3614\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3611\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3612\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3612\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3613\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba0c55a2b60>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training with expoential decay learning rate scheduler\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe1899-3d70-4e88-860e-e60ae2542e79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple convolution neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259d47da-6d02-4163-b1a8-226ba645c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520. 564. 502. 510. 482. 436. 496. 516. 485. 489.]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_784()\n",
    "print(np.sum(y_test, axis=0)) # check the test set target (one-hot encoding) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "039b9d00-6dee-447c-ba2b-954a418270b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_format', 'kernel_size', 'groups', 'dilation_rate', 'padding', 'strides', 'filters']\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.Conv2D arguments Dense layer does not have\n",
    "Conv2D_args = keras.layers.Conv2D(filters=4, kernel_size=5).get_config()\n",
    "Dense_args = keras.layers.Dense(units=4).get_config()\n",
    "Conv2D_args_only = list(set(Conv2D_args.keys()) - set(Dense_args.keys()))\n",
    "print(Conv2D_args_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc867071-0aaf-498c-9fa7-f5a239a95176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(8, 1), input_shape=[28, 28, 1]),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(1, 8), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, strides=3, activation='relu'),\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=7, groups=1, activation='relu'),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 10) to 10\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0185304e-8dfe-48a0-8abd-7d3c8d4df954",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028e91c6-db87-4cb5-90ff-a4c4573be93b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1719/1719 [==============================] - 7s 2ms/step - loss: 0.2100 - accuracy: 0.9370 - val_loss: 0.0998 - val_accuracy: 0.9697\n",
      "Epoch 2/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0688 - accuracy: 0.9798 - val_loss: 0.0607 - val_accuracy: 0.9807\n",
      "Epoch 3/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.0607 - val_accuracy: 0.9827\n",
      "Epoch 4/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0525 - val_accuracy: 0.9843\n",
      "Epoch 5/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
      "Epoch 6/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
      "Epoch 7/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0656 - val_accuracy: 0.9828\n",
      "Epoch 8/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0544 - val_accuracy: 0.9862\n",
      "Epoch 9/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0612 - val_accuracy: 0.9871\n",
      "Epoch 10/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0615 - val_accuracy: 0.9865\n",
      "Epoch 11/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0805 - val_accuracy: 0.9835\n",
      "Epoch 12/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0704 - val_accuracy: 0.9852\n",
      "Epoch 13/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0972 - val_accuracy: 0.9815\n",
      "Epoch 14/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0669 - val_accuracy: 0.9863\n",
      "Epoch 15/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0790 - val_accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=15,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb5674b-b2c7-4df0-be4e-6369dd2bb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03647341579198837, 0.9922000169754028]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfc972-dc62-46ec-b3e4-f6bb75a2d30c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN model with pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c6a20d-519f-4f3b-b6e2-c749250e6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520. 564. 502. 510. 482. 436. 496. 516. 485. 489.]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_784()\n",
    "print(np.sum(y_test, axis=0)) # check the test set target (one-hot encoding) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb99c006-3724-40c6-ad81-e2aa7a6064ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'max_pooling2d',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'pool_size': (2, 2),\n",
       " 'padding': 'valid',\n",
       " 'strides': (2, 2),\n",
       " 'data_format': 'channels_last'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.MaxPool2D().get_config() # Pooling layer has no trainable weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc60d426-8234-4ec1-adf2-d514a9989c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN model with pooling layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=9, input_shape=[28, 28, 1]),\n",
    "    keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=3, padding='same', activation='relu'), \n",
    "    keras.layers.GlobalAveragePooling2D(), # spatial dimensions collapse\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 10) to 10\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad0dfedb-a3a9-4266-8690-a14ff54f168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f7681a-27a1-472e-93f7-793eca373d50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4784 - accuracy: 0.8431 - val_loss: 0.1633 - val_accuracy: 0.9549\n",
      "Epoch 2/15\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1355 - accuracy: 0.9602 - val_loss: 0.1385 - val_accuracy: 0.9586\n",
      "Epoch 3/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0948 - accuracy: 0.9719 - val_loss: 0.0871 - val_accuracy: 0.9733\n",
      "Epoch 4/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.0700 - val_accuracy: 0.9793\n",
      "Epoch 5/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0633 - accuracy: 0.9807 - val_loss: 0.0531 - val_accuracy: 0.9849\n",
      "Epoch 6/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
      "Epoch 7/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0592 - val_accuracy: 0.9830\n",
      "Epoch 8/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.0490 - val_accuracy: 0.9841\n",
      "Epoch 9/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0714 - val_accuracy: 0.9785\n",
      "Epoch 10/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0434 - val_accuracy: 0.9875\n",
      "Epoch 11/15\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0368 - val_accuracy: 0.9898\n",
      "Epoch 12/15\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0540 - val_accuracy: 0.9847\n",
      "Epoch 13/15\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0568 - val_accuracy: 0.9859\n",
      "Epoch 14/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0370 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0324 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=15,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0d52f81-0f27-427d-a429-af94a7efc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01075205858796835, 0.9959999918937683]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee2c19-365a-483c-8e75-b71554750319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with RGB images (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2068d1d6-9def-4ee6-a6a2-a531be188444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5b55b6-d23c-4b85-b760-a323576b94ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846cfdad-3fcd-455b-b711-73329d9ad097",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3afc27ad-3b76-4864-a836-ae97e8d9516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781a97f2-971b-4d4c-a63a-252812cac0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 128)       131200    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 724,234\n",
      "Trainable params: 724,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeef213d-968c-41e1-9355-b1d0e76f4ace",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1563/1563 [==============================] - 9s 4ms/step - loss: 1.3294 - accuracy: 0.5302 - val_loss: 1.1875 - val_accuracy: 0.5928\n",
      "Epoch 2/150\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9906 - accuracy: 0.6565 - val_loss: 0.9836 - val_accuracy: 0.6580\n",
      "Epoch 3/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8276 - accuracy: 0.7133 - val_loss: 1.0960 - val_accuracy: 0.6436\n",
      "Epoch 4/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6890 - accuracy: 0.7617 - val_loss: 1.0178 - val_accuracy: 0.6768\n",
      "Epoch 5/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.5602 - accuracy: 0.8035 - val_loss: 1.0697 - val_accuracy: 0.6860\n",
      "Epoch 6/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4489 - accuracy: 0.8430 - val_loss: 1.1083 - val_accuracy: 0.6826\n",
      "Epoch 7/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3623 - accuracy: 0.8753 - val_loss: 1.3299 - val_accuracy: 0.6800\n",
      "Epoch 8/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2927 - accuracy: 0.8981 - val_loss: 1.5026 - val_accuracy: 0.6688\n",
      "Epoch 9/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2400 - accuracy: 0.9160 - val_loss: 1.5898 - val_accuracy: 0.6694\n",
      "Epoch 10/150\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2100 - accuracy: 0.9266 - val_loss: 1.8300 - val_accuracy: 0.6694\n",
      "Epoch 11/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1843 - accuracy: 0.9368 - val_loss: 2.0466 - val_accuracy: 0.6730\n",
      "Epoch 12/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1726 - accuracy: 0.9425 - val_loss: 2.2577 - val_accuracy: 0.6568\n",
      "Epoch 13/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9463 - val_loss: 2.2761 - val_accuracy: 0.6676\n",
      "Epoch 14/150\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1586 - accuracy: 0.9487 - val_loss: 2.1971 - val_accuracy: 0.6612\n",
      "Epoch 15/150\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1468 - accuracy: 0.9535 - val_loss: 2.7433 - val_accuracy: 0.6538\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=150,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16829719-b4f5-459b-b64b-3da72766238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1251 - accuracy: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1250826120376587, 0.6728000044822693]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test # not as impressive as training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec7f89-51e7-4f31-8f38-5907f0aa5e31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbbc860-db78-4799-b3dd-45fc05faaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = handson.rail_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b174a7-6d61-466b-aad0-5c30645bd089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_sequences': False,\n",
       " 'return_state': False,\n",
       " 'go_backwards': False,\n",
       " 'stateful': False,\n",
       " 'unroll': False,\n",
       " 'time_major': False,\n",
       " 'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "  'config': {'gain': 1.0, 'seed': None}},\n",
       " 'recurrent_regularizer': None,\n",
       " 'recurrent_constraint': None,\n",
       " 'dropout': 0.0,\n",
       " 'recurrent_dropout': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.SimpleRNN arguments Dense layer does not have\n",
    "SimpleRNN_args = keras.layers.SimpleRNN(units=32).get_config()\n",
    "Dense_keys = keras.layers.Dense(units=4).get_config().keys()\n",
    "SimpleRNN_args_only = {k: v for k, v in SimpleRNN_args.items() if k not in Dense_keys}\n",
    "SimpleRNN_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00917c15-257e-4aaf-b207-560b7706b057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    keras.layers.Dense(1) # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c03a393-4c91-44d5-9472-a9c11d34088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f44bff-3cec-4cce-b730-0466d541cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d635aca-7f26-4e33-af36-d7ce32f71d59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 4s 22ms/step - loss: 0.0165 - mae: 0.1416 - val_loss: 0.0054 - val_mae: 0.0792\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0025 - val_mae: 0.0492\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0035 - mae: 0.0544 - val_loss: 0.0022 - val_mae: 0.0425\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0511 - val_loss: 0.0020 - val_mae: 0.0380\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0506 - val_loss: 0.0022 - val_mae: 0.0415\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0472 - val_loss: 0.0020 - val_mae: 0.0366\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0023 - val_mae: 0.0441\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0030 - mae: 0.0486 - val_loss: 0.0023 - val_mae: 0.0414\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0465 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0455 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0027 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0398\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0458 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0027 - mae: 0.0441 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0459 - val_loss: 0.0021 - val_mae: 0.0381\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0357\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0027 - mae: 0.0433 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0420 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0022 - val_mae: 0.0399\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0430 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0449 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0478 - val_loss: 0.0021 - val_mae: 0.0390\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0419 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0294\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0412 - val_loss: 0.0022 - val_mae: 0.0420\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0419 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0425 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0027 - mae: 0.0444 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0431 - val_loss: 0.0021 - val_mae: 0.0388\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0428 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0432 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0414 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0410 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0364\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0433 - val_loss: 0.0019 - val_mae: 0.0355\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0020 - val_mae: 0.0342\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0323\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0434 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0407 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0412 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0021 - val_mae: 0.0381\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0411 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0416 - val_loss: 0.0020 - val_mae: 0.0372\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0418 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0346\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0416 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0018 - val_mae: 0.0328\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0018 - val_mae: 0.0302\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0299\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0415 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0426 - val_loss: 0.0021 - val_mae: 0.0379\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0017 - val_mae: 0.0299\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0026 - mae: 0.0449 - val_loss: 0.0020 - val_mae: 0.0387\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0412 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0022 - val_mae: 0.0425\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0414 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0021 - val_mae: 0.0370\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0017 - val_mae: 0.0301\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0428 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0018 - val_mae: 0.0324\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0018 - val_mae: 0.0302\n",
      "Epoch 95/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 96/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0021 - val_mae: 0.0370\n",
      "Epoch 97/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 98/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 99/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 100/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 101/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 102/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 103/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0396 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 104/150\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0399 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 105/150\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae3a781bfa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=valid_ds, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66be1f4-d376-4eec-b569-8c3e435cf60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04409952089190483, 0.2418685108423233]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(test_ds)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9189b1f2-0556-4104-8075-0f4e3ed58c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d267dd01-e29f-4482-8a1c-c1350a463fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(32),\n",
    "    keras.layers.Dense(1) # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a31834-8e5b-4d4d-8d64-2d3abdeb96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe40980-6462-4831-bd38-c533121dbbbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 4s 74ms/step - loss: 0.0628 - mae: 0.2433 - val_loss: 0.0095 - val_mae: 0.1172\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0093 - mae: 0.1088 - val_loss: 0.0075 - val_mae: 0.1030\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0058 - mae: 0.0795 - val_loss: 0.0029 - val_mae: 0.0540\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0052 - mae: 0.0731 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0026 - val_mae: 0.0478\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0055 - val_mae: 0.0859\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0041 - mae: 0.0598 - val_loss: 0.0028 - val_mae: 0.0511\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0042 - val_mae: 0.0705\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0043 - mae: 0.0625 - val_loss: 0.0077 - val_mae: 0.1095\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0039 - mae: 0.0582 - val_loss: 0.0021 - val_mae: 0.0385\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0030 - val_mae: 0.0529\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0035 - mae: 0.0540 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0035 - mae: 0.0536 - val_loss: 0.0026 - val_mae: 0.0472\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0034 - mae: 0.0525 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0023 - val_mae: 0.0408\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0503 - val_loss: 0.0025 - val_mae: 0.0461\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0026 - val_mae: 0.0460\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0034 - mae: 0.0551 - val_loss: 0.0032 - val_mae: 0.0590\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0036 - mae: 0.0570 - val_loss: 0.0023 - val_mae: 0.0408\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0031 - mae: 0.0505 - val_loss: 0.0026 - val_mae: 0.0454\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0031 - mae: 0.0499 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0507 - val_loss: 0.0028 - val_mae: 0.0507\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0524 - val_loss: 0.0048 - val_mae: 0.0799\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0511 - val_loss: 0.0032 - val_mae: 0.0588\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0025 - val_mae: 0.0453\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0476 - val_loss: 0.0022 - val_mae: 0.0402\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0467 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0451 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0030 - mae: 0.0482 - val_loss: 0.0020 - val_mae: 0.0376\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0031 - mae: 0.0502 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0465 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0488 - val_loss: 0.0020 - val_mae: 0.0381\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0467 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0029 - mae: 0.0475 - val_loss: 0.0020 - val_mae: 0.0379\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0457 - val_loss: 0.0026 - val_mae: 0.0479\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0032 - mae: 0.0533 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0022 - val_mae: 0.0418\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0030 - mae: 0.0501 - val_loss: 0.0025 - val_mae: 0.0472\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0475 - val_loss: 0.0026 - val_mae: 0.0471\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0461 - val_loss: 0.0024 - val_mae: 0.0445\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0470 - val_loss: 0.0029 - val_mae: 0.0584\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0472 - val_loss: 0.0026 - val_mae: 0.0480\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0026 - val_mae: 0.0475\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0021 - val_mae: 0.0391\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0019 - val_mae: 0.0366\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0020 - val_mae: 0.0382\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0467 - val_loss: 0.0025 - val_mae: 0.0471\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0477 - val_loss: 0.0020 - val_mae: 0.0385\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0031 - mae: 0.0527 - val_loss: 0.0029 - val_mae: 0.0528\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0477 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0022 - val_mae: 0.0406\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0023 - val_mae: 0.0439\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0020 - val_mae: 0.0371\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0025 - val_mae: 0.0453\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0025 - val_mae: 0.0452\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0029 - mae: 0.0497 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0494 - val_loss: 0.0031 - val_mae: 0.0575\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0500 - val_loss: 0.0022 - val_mae: 0.0391\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0020 - val_mae: 0.0362\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0028 - mae: 0.0470 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0028 - mae: 0.0483 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0447 - val_loss: 0.0030 - val_mae: 0.0552\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0444 - val_loss: 0.0031 - val_mae: 0.0567\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0030 - mae: 0.0499 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0031 - val_mae: 0.0591\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0475 - val_loss: 0.0027 - val_mae: 0.0501\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0485 - val_loss: 0.0030 - val_mae: 0.0552\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0486 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0433 - val_loss: 0.0020 - val_mae: 0.0364\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0474 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0023 - val_mae: 0.0413\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0430 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0417 - val_loss: 0.0023 - val_mae: 0.0415\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0023 - val_mae: 0.0436\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0475 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0416 - val_loss: 0.0021 - val_mae: 0.0375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae3a7819d20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    train_ds, \n",
    "    validation_data=valid_ds, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e4e1d3-477c-4743-a4bb-b501bca8ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04409952089190483, 0.2418685108423233]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_evals = model.evaluate(test_ds)\n",
    "deep_evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce46b19-1835-44f9-8f3e-40ee8ea89de6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09c3cf4-8cfc-4998-b3b0-d2508c4c530d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:491\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    488\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    492\u001b[0m     element,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for                  bus      rail  next_day_type_A  next_day_type_U  \\\ndate                                                               \n2016-01-01  0.303321  0.319835             True            False   \n2016-01-02  0.448859  0.365509            False             True   \n2016-01-03  0.340540  0.287661            False            False   \n2016-01-04  0.829429  0.703185            False            False   \n2016-01-05  0.846789  0.727716            False            False   \n...              ...       ...              ...              ...   \n2018-12-27  0.509948  0.453029            False            False   \n2018-12-28  0.577497  0.493961             True            False   \n2018-12-29  0.394088  0.307105            False             True   \n2018-12-30  0.314550  0.265310            False            False   \n2018-12-31  0.463165  0.386058            False             True   \n\n            next_day_type_W  \ndate                         \n2016-01-01            False  \n2016-01-02            False  \n2016-01-03             True  \n2016-01-04             True  \n2016-01-05             True  \n...                     ...  \n2018-12-27             True  \n2018-12-28            False  \n2018-12-29            False  \n2018-12-30             True  \n2018-12-31            False  \n\n[1096 rows x 5 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m seq2seq_train, seq2seq_valid, seq2seq_test \u001b[38;5;241m=\u001b[39m \u001b[43mhandson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq2seq_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:642\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    641\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gd/projects/handson/scripts/part2/handson.py:606\u001b[0m, in \u001b[0;36mseq2seq_dataset\u001b[0;34m(seq_length, ahead, target_col, batch_size)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# create sequences input and output of data\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 606\u001b[0m     ds \u001b[38;5;241m=\u001b[39m to_windows(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulvar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, ahead \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    607\u001b[0m     ds \u001b[38;5;241m=\u001b[39m to_windows(ds, seq_length)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m S: (S[:, \u001b[38;5;241m0\u001b[39m], S[:, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ind \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:818\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 109\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1627\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1628\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1629\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1633\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1639\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "seq2seq_train, seq2seq_valid, seq2seq_test = handson.seq2seq_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c22beea-cf75-4ad0-85c5-e6c2542b376d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recurrent_activation': 'sigmoid',\n",
       " 'unit_forget_bias': True,\n",
       " 'implementation': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.LSTM arguments SimpleRNN layer does not have\n",
    "LSTM_args = keras.layers.LSTM(units=32).get_config()\n",
    "SimpleRNN_keys = keras.layers.SimpleRNN(units=32).get_config().keys()\n",
    "LSTM_args_only = {k: v for k, v in LSTM_args.items() if k not in SimpleRNN_keys}\n",
    "LSTM_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03f8ab93-d2b3-465f-af2b-b6c60e03c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4125f0bd-30a3-48ed-b5c9-701433322295",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "313015a6-e960-46d2-be99-1703f7aeb6b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 5s 41ms/step - loss: 0.0997 - mae: 0.3681 - val_loss: 0.0254 - val_mae: 0.1842\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0210 - mae: 0.1656 - val_loss: 0.0205 - val_mae: 0.1532\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0190 - mae: 0.1619 - val_loss: 0.0199 - val_mae: 0.1528\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0186 - mae: 0.1611 - val_loss: 0.0195 - val_mae: 0.1516\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0183 - mae: 0.1598 - val_loss: 0.0193 - val_mae: 0.1503\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.1584 - val_loss: 0.0190 - val_mae: 0.1494\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0177 - mae: 0.1573 - val_loss: 0.0187 - val_mae: 0.1483\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 0.1568 - val_loss: 0.0184 - val_mae: 0.1475\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0171 - mae: 0.1552 - val_loss: 0.0182 - val_mae: 0.1462\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.1540 - val_loss: 0.0180 - val_mae: 0.1451\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0166 - mae: 0.1532 - val_loss: 0.0177 - val_mae: 0.1448\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0164 - mae: 0.1525 - val_loss: 0.0175 - val_mae: 0.1438\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.1514 - val_loss: 0.0173 - val_mae: 0.1430\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.1503 - val_loss: 0.0171 - val_mae: 0.1422\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.1493 - val_loss: 0.0170 - val_mae: 0.1413\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0156 - mae: 0.1487 - val_loss: 0.0168 - val_mae: 0.1405\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.1476 - val_loss: 0.0166 - val_mae: 0.1397\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.1469 - val_loss: 0.0165 - val_mae: 0.1390\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0150 - mae: 0.1460 - val_loss: 0.0163 - val_mae: 0.1383\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.1450 - val_loss: 0.0161 - val_mae: 0.1376\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0147 - mae: 0.1446 - val_loss: 0.0160 - val_mae: 0.1369\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0146 - mae: 0.1436 - val_loss: 0.0158 - val_mae: 0.1364\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0144 - mae: 0.1429 - val_loss: 0.0157 - val_mae: 0.1356\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0143 - mae: 0.1420 - val_loss: 0.0155 - val_mae: 0.1349\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.1410 - val_loss: 0.0154 - val_mae: 0.1340\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0140 - mae: 0.1404 - val_loss: 0.0152 - val_mae: 0.1335\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.1395 - val_loss: 0.0151 - val_mae: 0.1330\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.1390 - val_loss: 0.0150 - val_mae: 0.1323\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.1383 - val_loss: 0.0149 - val_mae: 0.1316\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0135 - mae: 0.1372 - val_loss: 0.0147 - val_mae: 0.1310\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.1365 - val_loss: 0.0146 - val_mae: 0.1302\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.1356 - val_loss: 0.0145 - val_mae: 0.1299\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.1352 - val_loss: 0.0144 - val_mae: 0.1291\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.1348 - val_loss: 0.0143 - val_mae: 0.1285\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.1339 - val_loss: 0.0141 - val_mae: 0.1279\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.1328 - val_loss: 0.0140 - val_mae: 0.1274\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0127 - mae: 0.1324 - val_loss: 0.0139 - val_mae: 0.1268\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.1318 - val_loss: 0.0138 - val_mae: 0.1260\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.1307 - val_loss: 0.0137 - val_mae: 0.1255\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.1301 - val_loss: 0.0136 - val_mae: 0.1251\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.1294 - val_loss: 0.0135 - val_mae: 0.1246\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.1288 - val_loss: 0.0134 - val_mae: 0.1240\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.1280 - val_loss: 0.0133 - val_mae: 0.1236\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.1275 - val_loss: 0.0132 - val_mae: 0.1231\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.1273 - val_loss: 0.0131 - val_mae: 0.1227\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.1264 - val_loss: 0.0130 - val_mae: 0.1222\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.1254 - val_loss: 0.0129 - val_mae: 0.1219\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.1253 - val_loss: 0.0129 - val_mae: 0.1213\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.1244 - val_loss: 0.0128 - val_mae: 0.1209\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.1239 - val_loss: 0.0127 - val_mae: 0.1206\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.1233 - val_loss: 0.0126 - val_mae: 0.1202\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0113 - mae: 0.1230 - val_loss: 0.0125 - val_mae: 0.1198\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0113 - mae: 0.1220 - val_loss: 0.0124 - val_mae: 0.1194\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.1218 - val_loss: 0.0124 - val_mae: 0.1190\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.1209 - val_loss: 0.0123 - val_mae: 0.1187\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.1208 - val_loss: 0.0122 - val_mae: 0.1183\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.1204 - val_loss: 0.0121 - val_mae: 0.1180\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.1195 - val_loss: 0.0120 - val_mae: 0.1177\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.1192 - val_loss: 0.0120 - val_mae: 0.1174\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.1187 - val_loss: 0.0119 - val_mae: 0.1170\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.1183 - val_loss: 0.0119 - val_mae: 0.1167\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.1177 - val_loss: 0.0118 - val_mae: 0.1165\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.1176 - val_loss: 0.0117 - val_mae: 0.1162\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.1168 - val_loss: 0.0117 - val_mae: 0.1158\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.1165 - val_loss: 0.0116 - val_mae: 0.1156\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.1161 - val_loss: 0.0115 - val_mae: 0.1153\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1159 - val_loss: 0.0115 - val_mae: 0.1150\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1155 - val_loss: 0.0114 - val_mae: 0.1147\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1152 - val_loss: 0.0114 - val_mae: 0.1145\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0102 - mae: 0.1147 - val_loss: 0.0113 - val_mae: 0.1142\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0102 - mae: 0.1144 - val_loss: 0.0112 - val_mae: 0.1140\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.1140 - val_loss: 0.0112 - val_mae: 0.1137\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.1136 - val_loss: 0.0111 - val_mae: 0.1135\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.1132 - val_loss: 0.0111 - val_mae: 0.1133\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.1130 - val_loss: 0.0110 - val_mae: 0.1130\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.1126 - val_loss: 0.0110 - val_mae: 0.1128\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.1123 - val_loss: 0.0109 - val_mae: 0.1125\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.1120 - val_loss: 0.0109 - val_mae: 0.1123\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0108 - val_mae: 0.1121\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0108 - val_mae: 0.1119\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.1112 - val_loss: 0.0107 - val_mae: 0.1116\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.1107 - val_loss: 0.0107 - val_mae: 0.1114\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.1108 - val_loss: 0.0107 - val_mae: 0.1112\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.1103 - val_loss: 0.0106 - val_mae: 0.1110\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.1100 - val_loss: 0.0106 - val_mae: 0.1108\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.1098 - val_loss: 0.0105 - val_mae: 0.1106\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.1094 - val_loss: 0.0105 - val_mae: 0.1104\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1093 - val_loss: 0.0105 - val_mae: 0.1102\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1090 - val_loss: 0.0104 - val_mae: 0.1100\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1088 - val_loss: 0.0104 - val_mae: 0.1098\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.1085 - val_loss: 0.0104 - val_mae: 0.1096\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.1082 - val_loss: 0.0103 - val_mae: 0.1094\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.1080 - val_loss: 0.0103 - val_mae: 0.1092\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.1078 - val_loss: 0.0102 - val_mae: 0.1090\n",
      "Epoch 95/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.1075 - val_loss: 0.0102 - val_mae: 0.1088\n",
      "Epoch 96/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.1072 - val_loss: 0.0102 - val_mae: 0.1087\n",
      "Epoch 97/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1070 - val_loss: 0.0101 - val_mae: 0.1084\n",
      "Epoch 98/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1068 - val_loss: 0.0101 - val_mae: 0.1083\n",
      "Epoch 99/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1067 - val_loss: 0.0100 - val_mae: 0.1081\n",
      "Epoch 100/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1063 - val_loss: 0.0100 - val_mae: 0.1079\n",
      "Epoch 101/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1062 - val_loss: 0.0100 - val_mae: 0.1077\n",
      "Epoch 102/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1059 - val_loss: 0.0099 - val_mae: 0.1075\n",
      "Epoch 103/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1057 - val_loss: 0.0099 - val_mae: 0.1073\n",
      "Epoch 104/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1055 - val_loss: 0.0099 - val_mae: 0.1072\n",
      "Epoch 105/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1053 - val_loss: 0.0099 - val_mae: 0.1070\n",
      "Epoch 106/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1050 - val_loss: 0.0098 - val_mae: 0.1068\n",
      "Epoch 107/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1049 - val_loss: 0.0098 - val_mae: 0.1067\n",
      "Epoch 108/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1046 - val_loss: 0.0098 - val_mae: 0.1065\n",
      "Epoch 109/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1045 - val_loss: 0.0098 - val_mae: 0.1064\n",
      "Epoch 110/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1042 - val_loss: 0.0097 - val_mae: 0.1062\n",
      "Epoch 111/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1040 - val_loss: 0.0097 - val_mae: 0.1060\n",
      "Epoch 112/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0097 - val_mae: 0.1058\n",
      "Epoch 113/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1037 - val_loss: 0.0096 - val_mae: 0.1057\n",
      "Epoch 114/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0096 - val_mae: 0.1056\n",
      "Epoch 115/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1032 - val_loss: 0.0096 - val_mae: 0.1054\n",
      "Epoch 116/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0096 - val_mae: 0.1052\n",
      "Epoch 117/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1029 - val_loss: 0.0095 - val_mae: 0.1051\n",
      "Epoch 118/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1027 - val_loss: 0.0095 - val_mae: 0.1049\n",
      "Epoch 119/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0095 - val_mae: 0.1048\n",
      "Epoch 120/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0094 - val_mae: 0.1046\n",
      "Epoch 121/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1022 - val_loss: 0.0094 - val_mae: 0.1044\n",
      "Epoch 122/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1019 - val_loss: 0.0094 - val_mae: 0.1043\n",
      "Epoch 123/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1018 - val_loss: 0.0094 - val_mae: 0.1042\n",
      "Epoch 124/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1016 - val_loss: 0.0094 - val_mae: 0.1040\n",
      "Epoch 125/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1015 - val_loss: 0.0093 - val_mae: 0.1038\n",
      "Epoch 126/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1013 - val_loss: 0.0093 - val_mae: 0.1037\n",
      "Epoch 127/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0093 - val_mae: 0.1037\n",
      "Epoch 128/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1009 - val_loss: 0.0093 - val_mae: 0.1034\n",
      "Epoch 129/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0093 - val_mae: 0.1033\n",
      "Epoch 130/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1006 - val_loss: 0.0092 - val_mae: 0.1031\n",
      "Epoch 131/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.1005 - val_loss: 0.0092 - val_mae: 0.1030\n",
      "Epoch 132/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.1002 - val_loss: 0.0092 - val_mae: 0.1029\n",
      "Epoch 133/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.1001 - val_loss: 0.0092 - val_mae: 0.1028\n",
      "Epoch 134/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0999 - val_loss: 0.0092 - val_mae: 0.1026\n",
      "Epoch 135/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0998 - val_loss: 0.0091 - val_mae: 0.1024\n",
      "Epoch 136/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0996 - val_loss: 0.0091 - val_mae: 0.1024\n",
      "Epoch 137/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0091 - val_mae: 0.1022\n",
      "Epoch 138/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0992 - val_loss: 0.0091 - val_mae: 0.1021\n",
      "Epoch 139/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0991 - val_loss: 0.0090 - val_mae: 0.1018\n",
      "Epoch 140/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0991 - val_loss: 0.0090 - val_mae: 0.1018\n",
      "Epoch 141/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0988 - val_loss: 0.0090 - val_mae: 0.1016\n",
      "Epoch 142/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0987 - val_loss: 0.0090 - val_mae: 0.1015\n",
      "Epoch 143/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0985 - val_loss: 0.0090 - val_mae: 0.1014\n",
      "Epoch 144/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0984 - val_loss: 0.0089 - val_mae: 0.1012\n",
      "Epoch 145/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0982 - val_loss: 0.0089 - val_mae: 0.1010\n",
      "Epoch 146/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0980 - val_loss: 0.0089 - val_mae: 0.1010\n",
      "Epoch 147/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0979 - val_loss: 0.0089 - val_mae: 0.1008\n",
      "Epoch 148/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0977 - val_loss: 0.0089 - val_mae: 0.1008\n",
      "Epoch 149/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0975 - val_loss: 0.0088 - val_mae: 0.1006\n",
      "Epoch 150/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0975 - val_loss: 0.0088 - val_mae: 0.1005\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    seq2seq_train, \n",
    "    validation_data=seq2seq_valid, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab959ce-646a-4ed2-a73e-5c3690b8a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.2746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.049832530319690704, 0.2745789587497711]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(seq2seq_test)\n",
    "evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266207b-4772-445d-bc67-c117a1e00684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44a29647-9ea9-4300-b382-ffd018c0f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recurrent_activation': 'sigmoid', 'implementation': 2, 'reset_after': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.GRU arguments SimpleRNN layer does not have\n",
    "GRU_args = keras.layers.GRU(units=32).get_config()\n",
    "SimpleRNN_keys = keras.layers.SimpleRNN(units=32).get_config().keys()\n",
    "GRU_args_only = {k: v for k, v in GRU_args.items() if k not in SimpleRNN_keys}\n",
    "GRU_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472de145-9484-4514-8f1d-dd4792583de7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:104\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:491\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    488\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    492\u001b[0m     element,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for                  bus      rail  next_day_type_A  next_day_type_U  \\\ndate                                                               \n2016-01-01  0.303321  0.319835             True            False   \n2016-01-02  0.448859  0.365509            False             True   \n2016-01-03  0.340540  0.287661            False            False   \n2016-01-04  0.829429  0.703185            False            False   \n2016-01-05  0.846789  0.727716            False            False   \n...              ...       ...              ...              ...   \n2018-12-27  0.509948  0.453029            False            False   \n2018-12-28  0.577497  0.493961             True            False   \n2018-12-29  0.394088  0.307105            False             True   \n2018-12-30  0.314550  0.265310            False            False   \n2018-12-31  0.463165  0.386058            False             True   \n\n            next_day_type_W  \ndate                         \n2016-01-01            False  \n2016-01-02            False  \n2016-01-03             True  \n2016-01-04             True  \n2016-01-05             True  \n...                     ...  \n2018-12-27             True  \n2018-12-28            False  \n2018-12-29            False  \n2018-12-30             True  \n2018-12-31            False  \n\n[1096 rows x 5 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m seq2seq_train, seq2seq_valid, seq2seq_test \u001b[38;5;241m=\u001b[39m \u001b[43mhandson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq2seq_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:642\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    641\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gd/projects/handson/scripts/part2/handson.py:606\u001b[0m, in \u001b[0;36mseq2seq_dataset\u001b[0;34m(seq_length, ahead, target_col, batch_size)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# create sequences input and output of data\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 606\u001b[0m     ds \u001b[38;5;241m=\u001b[39m to_windows(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulvar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, ahead \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    607\u001b[0m     ds \u001b[38;5;241m=\u001b[39m to_windows(ds, seq_length)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m S: (S[:, \u001b[38;5;241m0\u001b[39m], S[:, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ind \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:818\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:109\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 109\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1627\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1628\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1629\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1633\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1636\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1639\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "seq2seq_train, seq2seq_valid, seq2seq_test = handson.seq2seq_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "23862eac-5b84-47fc-944a-23118068c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 5]),\n",
    "tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b9b5535c-ec9e-4e7c-918a-cf9d1b5e0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "895677ad-0708-457c-bfc0-653719a74f1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 4s 31ms/step - loss: 0.1283 - mae: 0.4075 - val_loss: 0.0266 - val_mae: 0.1786\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0198 - mae: 0.1597 - val_loss: 0.0197 - val_mae: 0.1562\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0175 - mae: 0.1570 - val_loss: 0.0186 - val_mae: 0.1518\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.1540 - val_loss: 0.0179 - val_mae: 0.1485\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0161 - mae: 0.1507 - val_loss: 0.0173 - val_mae: 0.1454\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0156 - mae: 0.1478 - val_loss: 0.0167 - val_mae: 0.1430\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.1452 - val_loss: 0.0162 - val_mae: 0.1404\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0146 - mae: 0.1433 - val_loss: 0.0158 - val_mae: 0.1381\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.1405 - val_loss: 0.0154 - val_mae: 0.1358\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.1383 - val_loss: 0.0150 - val_mae: 0.1337\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0135 - mae: 0.1364 - val_loss: 0.0146 - val_mae: 0.1321\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.1347 - val_loss: 0.0143 - val_mae: 0.1303\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.1327 - val_loss: 0.0140 - val_mae: 0.1286\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.1309 - val_loss: 0.0137 - val_mae: 0.1271\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.1292 - val_loss: 0.0134 - val_mae: 0.1256\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.1278 - val_loss: 0.0132 - val_mae: 0.1242\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.1262 - val_loss: 0.0129 - val_mae: 0.1228\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.1249 - val_loss: 0.0127 - val_mae: 0.1216\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.1236 - val_loss: 0.0125 - val_mae: 0.1205\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0113 - mae: 0.1222 - val_loss: 0.0123 - val_mae: 0.1195\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.1213 - val_loss: 0.0121 - val_mae: 0.1184\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.1200 - val_loss: 0.0119 - val_mae: 0.1176\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.1190 - val_loss: 0.0118 - val_mae: 0.1167\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.1179 - val_loss: 0.0116 - val_mae: 0.1158\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.1169 - val_loss: 0.0115 - val_mae: 0.1150\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.1161 - val_loss: 0.0114 - val_mae: 0.1142\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0112 - val_mae: 0.1135\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1145 - val_loss: 0.0111 - val_mae: 0.1129\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0102 - mae: 0.1137 - val_loss: 0.0110 - val_mae: 0.1122\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.1129 - val_loss: 0.0109 - val_mae: 0.1116\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.1122 - val_loss: 0.0108 - val_mae: 0.1111\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.1116 - val_loss: 0.0107 - val_mae: 0.1105\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0107 - val_mae: 0.1100\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.1107 - val_loss: 0.0106 - val_mae: 0.1095\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0105 - val_mae: 0.1090\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.1093 - val_loss: 0.0104 - val_mae: 0.1086\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.1090 - val_loss: 0.0104 - val_mae: 0.1082\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0104 - val_mae: 0.1078\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1080 - val_loss: 0.0103 - val_mae: 0.1074\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0102 - val_mae: 0.1070\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.1073 - val_loss: 0.0101 - val_mae: 0.1067\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.1068 - val_loss: 0.0101 - val_mae: 0.1064\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0101 - val_mae: 0.1060\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0100 - val_mae: 0.1058\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1061 - val_loss: 0.0100 - val_mae: 0.1054\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0099 - val_mae: 0.1052\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0098 - val_mae: 0.1049\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1050 - val_loss: 0.0098 - val_mae: 0.1047\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0098 - val_mae: 0.1044\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0097 - val_mae: 0.1042\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0097 - val_mae: 0.1039\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0097 - val_mae: 0.1038\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0096 - val_mae: 0.1035\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0096 - val_mae: 0.1033\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0096 - val_mae: 0.1031\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0096 - val_mae: 0.1029\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0095 - val_mae: 0.1027\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0095 - val_mae: 0.1025\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0094 - val_mae: 0.1023\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0094 - val_mae: 0.1021\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0094 - val_mae: 0.1019\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0093 - val_mae: 0.1016\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0093 - val_mae: 0.1016\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0093 - val_mae: 0.1013\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0093 - val_mae: 0.1012\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0092 - val_mae: 0.1009\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.1003 - val_loss: 0.0092 - val_mae: 0.1008\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1000 - val_loss: 0.0092 - val_mae: 0.1006\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0092 - val_mae: 0.1005\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0091 - val_mae: 0.1003\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0994 - val_loss: 0.0091 - val_mae: 0.1001\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0992 - val_loss: 0.0091 - val_mae: 0.1001\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0989 - val_loss: 0.0091 - val_mae: 0.0999\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0987 - val_loss: 0.0090 - val_mae: 0.0996\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0986 - val_loss: 0.0090 - val_mae: 0.0995\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0090 - val_mae: 0.0993\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0982 - val_loss: 0.0089 - val_mae: 0.0991\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0089 - val_mae: 0.0989\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0979 - val_loss: 0.0089 - val_mae: 0.0988\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0977 - val_loss: 0.0089 - val_mae: 0.0986\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0975 - val_loss: 0.0089 - val_mae: 0.0985\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0971 - val_loss: 0.0088 - val_mae: 0.0982\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0972 - val_loss: 0.0088 - val_mae: 0.0982\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0969 - val_loss: 0.0087 - val_mae: 0.0978\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0966 - val_loss: 0.0088 - val_mae: 0.0979\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0966 - val_loss: 0.0087 - val_mae: 0.0977\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0963 - val_loss: 0.0087 - val_mae: 0.0976\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0087 - val_mae: 0.0973\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0960 - val_loss: 0.0086 - val_mae: 0.0971\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0959 - val_loss: 0.0086 - val_mae: 0.0970\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0956 - val_loss: 0.0086 - val_mae: 0.0969\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0954 - val_loss: 0.0086 - val_mae: 0.0967\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0086 - val_mae: 0.0965\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0952 - val_loss: 0.0085 - val_mae: 0.0962\n",
      "Epoch 95/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0950 - val_loss: 0.0085 - val_mae: 0.0961\n",
      "Epoch 96/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0947 - val_loss: 0.0085 - val_mae: 0.0961\n",
      "Epoch 97/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0946 - val_loss: 0.0085 - val_mae: 0.0958\n",
      "Epoch 98/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0944 - val_loss: 0.0085 - val_mae: 0.0958\n",
      "Epoch 99/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0943 - val_loss: 0.0084 - val_mae: 0.0955\n",
      "Epoch 100/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0941 - val_loss: 0.0084 - val_mae: 0.0951\n",
      "Epoch 101/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0940 - val_loss: 0.0084 - val_mae: 0.0952\n",
      "Epoch 102/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0938 - val_loss: 0.0083 - val_mae: 0.0948\n",
      "Epoch 103/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0936 - val_loss: 0.0083 - val_mae: 0.0948\n",
      "Epoch 104/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0934 - val_loss: 0.0083 - val_mae: 0.0947\n",
      "Epoch 105/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0932 - val_loss: 0.0083 - val_mae: 0.0945\n",
      "Epoch 106/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0930 - val_loss: 0.0082 - val_mae: 0.0942\n",
      "Epoch 107/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0929 - val_loss: 0.0083 - val_mae: 0.0943\n",
      "Epoch 108/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0082 - val_mae: 0.0939\n",
      "Epoch 109/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0926 - val_loss: 0.0082 - val_mae: 0.0939\n",
      "Epoch 110/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0924 - val_loss: 0.0082 - val_mae: 0.0938\n",
      "Epoch 111/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0922 - val_loss: 0.0082 - val_mae: 0.0935\n",
      "Epoch 112/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0921 - val_loss: 0.0081 - val_mae: 0.0933\n",
      "Epoch 113/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0920 - val_loss: 0.0081 - val_mae: 0.0931\n",
      "Epoch 114/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0917 - val_loss: 0.0081 - val_mae: 0.0931\n",
      "Epoch 115/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0915 - val_loss: 0.0081 - val_mae: 0.0929\n",
      "Epoch 116/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0915 - val_loss: 0.0080 - val_mae: 0.0926\n",
      "Epoch 117/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0913 - val_loss: 0.0080 - val_mae: 0.0925\n",
      "Epoch 118/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0911 - val_loss: 0.0080 - val_mae: 0.0924\n",
      "Epoch 119/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0909 - val_loss: 0.0080 - val_mae: 0.0923\n",
      "Epoch 120/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0908 - val_loss: 0.0080 - val_mae: 0.0920\n",
      "Epoch 121/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0907 - val_loss: 0.0079 - val_mae: 0.0918\n",
      "Epoch 122/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0904 - val_loss: 0.0079 - val_mae: 0.0917\n",
      "Epoch 123/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0904 - val_loss: 0.0079 - val_mae: 0.0916\n",
      "Epoch 124/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0901 - val_loss: 0.0079 - val_mae: 0.0914\n",
      "Epoch 125/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0901 - val_loss: 0.0079 - val_mae: 0.0912\n",
      "Epoch 126/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0899 - val_loss: 0.0078 - val_mae: 0.0910\n",
      "Epoch 127/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0896 - val_loss: 0.0078 - val_mae: 0.0910\n",
      "Epoch 128/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0895 - val_loss: 0.0078 - val_mae: 0.0907\n",
      "Epoch 129/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0894 - val_loss: 0.0078 - val_mae: 0.0905\n",
      "Epoch 130/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0892 - val_loss: 0.0077 - val_mae: 0.0902\n",
      "Epoch 131/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0892 - val_loss: 0.0078 - val_mae: 0.0904\n",
      "Epoch 132/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0888 - val_loss: 0.0077 - val_mae: 0.0901\n",
      "Epoch 133/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0888 - val_loss: 0.0077 - val_mae: 0.0901\n",
      "Epoch 134/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0886 - val_loss: 0.0077 - val_mae: 0.0898\n",
      "Epoch 135/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0886 - val_loss: 0.0077 - val_mae: 0.0895\n",
      "Epoch 136/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0883 - val_loss: 0.0077 - val_mae: 0.0896\n",
      "Epoch 137/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0882 - val_loss: 0.0077 - val_mae: 0.0894\n",
      "Epoch 138/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0879 - val_loss: 0.0076 - val_mae: 0.0892\n",
      "Epoch 139/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0879 - val_loss: 0.0076 - val_mae: 0.0888\n",
      "Epoch 140/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0878 - val_loss: 0.0076 - val_mae: 0.0888\n",
      "Epoch 141/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0876 - val_loss: 0.0076 - val_mae: 0.0886\n",
      "Epoch 142/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0874 - val_loss: 0.0075 - val_mae: 0.0885\n",
      "Epoch 143/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0873 - val_loss: 0.0075 - val_mae: 0.0883\n",
      "Epoch 144/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0872 - val_loss: 0.0075 - val_mae: 0.0881\n",
      "Epoch 145/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0870 - val_loss: 0.0075 - val_mae: 0.0879\n",
      "Epoch 146/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0075 - val_mae: 0.0879\n",
      "Epoch 147/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0867 - val_loss: 0.0074 - val_mae: 0.0876\n",
      "Epoch 148/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0865 - val_loss: 0.0074 - val_mae: 0.0877\n",
      "Epoch 149/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0864 - val_loss: 0.0074 - val_mae: 0.0875\n",
      "Epoch 150/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0863 - val_loss: 0.0074 - val_mae: 0.0873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    seq2seq_train, \n",
    "    validation_data=seq2seq_valid, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "66a8dd90-ea05-4f56-926b-93b48abfbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0466 - mae: 0.2618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04661950841546059, 0.2617809772491455]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(seq2seq_test)\n",
    "evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bacfb8-a471-4f14-b118-75ae53255c13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ModelCheckpoint, Logging, and Early Stopping on accuracy difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14829b5c-3e7f-4fe4-906f-8b74e9b311f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "025a867b-dfbc-40a1-92af-aef6d026a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb432ee9-0c8f-46c2-85f7-0e6aa1f06fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function for CSV log file\n",
    "\n",
    "hours = 14 # hours to delay timestamp for log info (remote system might have different time)\n",
    "timestamp = (datetime.datetime.now() + datetime.timedelta(hours=hours))\n",
    "timestamp = timestamp.strftime('%Y-%m-%d~%I:%M:%S%p')\n",
    "\n",
    "# create log file directory path and file name\n",
    "log_dir = Path('./models.CSV.log')\n",
    "log_dir.mkdir()\n",
    "file_name = 'LOG.'+timestamp+'.csv'\n",
    "\n",
    "# save log file of training output\n",
    "csv_logger = keras.callbacks.CSVLogger(log_dir / file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bc13183-f1e1-4445-9dfa-32970b219e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model whenever there is an improvement in accuracy over the previous best accuracy\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./cifar_10_model.hdf5',\n",
    "    monitor=\"val_accuracy\", # it could be any other monitoring metrics. Make sure put val_\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, # it should be false. See below comments\n",
    "    verbose=1 # 0, 1, or 2. It just specifies how much information is output during training\n",
    ")\n",
    "\n",
    "# save_weights_only=False saves the entire architecture of the neural network, including \n",
    "# the model's layers, their configuration, the optimizer used during training, and the weights \n",
    "# learned during training. save_weights_only=True saves only the learned weights of the model, \n",
    "# without any information about the model's architecture or the optimizer used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44c4e07f-cf25-4931-924f-84488162d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stops training when training accuracy is greater than validation accuracy by 0.1\n",
    "class StopOnAccuracyDiff(keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        super(StopOnAccuracyDiff, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        train_acc = logs.get('accuracy')\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if train_acc is not None and val_acc is not None:\n",
    "            acc_diff = abs(train_acc - val_acc)\n",
    "            if acc_diff > self.threshold:\n",
    "                print(f'Training stopped because of accuracy difference ({acc_diff:.3f})')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "early_stopping_cb = StopOnAccuracyDiff(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "588057ec-b8e7-42c8-baf0-09be5c6d755f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.8264 - accuracy: 0.7154\n",
      "Epoch 1: val_accuracy improved from 0.66560 to 0.67220, saving model to ./cifar_10_model.hdf5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8262 - accuracy: 0.7155 - val_loss: 0.9706 - val_accuracy: 0.6722\n",
      "Epoch 2/150\n",
      "1545/1563 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.7594\n",
      "Epoch 2: val_accuracy improved from 0.67220 to 0.69120, saving model to ./cifar_10_model.hdf5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6913 - accuracy: 0.7594 - val_loss: 1.0048 - val_accuracy: 0.6912\n",
      "Epoch 3/150\n",
      "1545/1563 [============================>.] - ETA: 0s - loss: 0.5620 - accuracy: 0.8043\n",
      "Epoch 3: val_accuracy did not improve from 0.69120\n",
      "Training stopped because of accuracy difference (0.119)\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.5622 - accuracy: 0.8043 - val_loss: 1.0752 - val_accuracy: 0.6856\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=150,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        checkpoint_callback, \n",
    "        csv_logger,\n",
    "        early_stopping_cb] # called after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9d4c75c-f51c-4337-919a-332900b95f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0246 - accuracy: 0.6784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0245752334594727, 0.6783999800682068]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('cifar_10_model.hdf5')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "acc_test = loaded_model.evaluate(X_test, y_test)\n",
    "acc_test # not as impressive as training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3a779-a58d-43b4-bbd0-be7b9d14b138",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaba1b3-dd88-4817-a146-99b334076a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc663c30-54d8-45c4-a590-019ce9555c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = mods.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4bb57b-49c7-4d29-9f23-eb4bd11862c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.profiler.experimental.start(logdir='profiler.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067b2774-ebd8-451b-9abe-17d3be4746d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf86ff7-5250-4a25-aa3a-82ae417da715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories in which to save logs\n",
    "\n",
    "hours = 14 # hours to delay timestamp for log info (remote system might have different time)\n",
    "timestamp = (datetime.datetime.now() + datetime.timedelta(hours=hours))\n",
    "timestamp = timestamp.strftime('%Y-%m-%d~%I:%M:%S%p')\n",
    "\n",
    "# create directory\n",
    "parent_dir = Path('./models.tensorboard.log')\n",
    "sub_dir = parent_dir / timestamp\n",
    "sub_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2fa530b-436f-4d0c-96ec-ae13fead93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=str(sub_dir), histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19dbcc0-0cde-44d8-8777-15a7bb63fb18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 10s 4ms/step - loss: 1.3406 - accuracy: 0.5282 - val_loss: 1.0838 - val_accuracy: 0.6254\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9814 - accuracy: 0.6610 - val_loss: 0.9691 - val_accuracy: 0.6696\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8255 - accuracy: 0.7139 - val_loss: 0.9792 - val_accuracy: 0.6788\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6770 - accuracy: 0.7655 - val_loss: 1.0280 - val_accuracy: 0.6768\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5449 - accuracy: 0.8111 - val_loss: 1.0733 - val_accuracy: 0.6808\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4255 - accuracy: 0.8516 - val_loss: 1.2229 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3386 - accuracy: 0.8818 - val_loss: 1.3908 - val_accuracy: 0.6758\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2749 - accuracy: 0.9030 - val_loss: 1.5739 - val_accuracy: 0.6772\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9197 - val_loss: 1.8920 - val_accuracy: 0.6612\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1982 - accuracy: 0.9326 - val_loss: 1.9243 - val_accuracy: 0.6660\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1799 - accuracy: 0.9398 - val_loss: 2.1036 - val_accuracy: 0.6676\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1615 - accuracy: 0.9467 - val_loss: 2.3060 - val_accuracy: 0.6624\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1681 - accuracy: 0.9456 - val_loss: 2.4544 - val_accuracy: 0.6656\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1541 - accuracy: 0.9508 - val_loss: 2.4042 - val_accuracy: 0.6586\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9535 - val_loss: 2.7331 - val_accuracy: 0.6572\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_cb, tensorboard_callback] # called after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11007f6f-9913-4dc2-8119-fde5a617c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41985182-48b2-4188-8ec3-f70922c256a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38617d9-9142-4507-9eb8-59ab4b5da558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.profiler.trace.Trace"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.profiler.experimental.Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce938c3-f4c7-4f2a-9255-fd7ff1d0245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Start profiling TensorFlow performance.\n",
       "\n",
       "Args:\n",
       "  logdir: Profiling results log directory.\n",
       "  options: `ProfilerOptions` namedtuple to specify miscellaneous profiler\n",
       "    options. See example usage below.\n",
       "\n",
       "Raises:\n",
       "  AlreadyExistsError: If a profiling session is already running.\n",
       "\n",
       "Example usage:\n",
       "```python\n",
       "options = tf.profiler.experimental.ProfilerOptions(host_tracer_level = 3,\n",
       "                                                   python_tracer_level = 1,\n",
       "                                                   device_tracer_level = 1)\n",
       "tf.profiler.experimental.start('logdir_path', options = options)\n",
       "# Training code here\n",
       "tf.profiler.experimental.stop()\n",
       "```\n",
       "\n",
       "To view the profiling results, launch TensorBoard and point it to `logdir`.\n",
       "Open your browser and go to `localhost:6006/#profile` to view profiling\n",
       "results.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/profiler/profiler_v2.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.profiler.experimental.start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10523047-8d9a-48d2-a1ea-1ed6c2e87e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.summary_ops_v2.trace_export(name, step=None, profiler_outdir=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.trace_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc54f3-4f5f-43d0-8b54-d58047800fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
