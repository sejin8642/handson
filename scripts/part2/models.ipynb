{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815da4d2-7426-4243-984b-bd4522de38ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## load modules and configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7d6c62-a4a0-439f-b77c-ab25b7dd3043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f7c372-80f5-4b00-8d86-989a185ebfea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_path = str(Path.home()/'gd'/'projects')\n",
    "\n",
    "sys.path.insert(0, project_path + '/ftnmr/scripts')\n",
    "sys.path.insert(0, project_path + '/projnmr/scripts')\n",
    "sys.path.insert(0, project_path + '/handson/scripts/part2')\n",
    "sys.path.insert(0, project_path + '/mods/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91040b55-0159-48ba-8f9e-bbf6b2d7f263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ftnmr\n",
    "import projnmr\n",
    "import handson\n",
    "import mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "076bdc0e-0897-41af-922a-6ab04e918d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import random\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sympy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69489b61-cf83-4dff-976f-c018d86d4c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# for error \"not creating xla devices tf_xla_enable_xla_devices not set\"\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "#TF_XLA_FLAGS is an environment variable used by TensorFlow's XLA (Accelerated Linear Algebra) \n",
    "#compiler to control its behavior. In this case, setting TF_XLA_FLAGS to \n",
    "#--tf_xla_enable_xla_devices enables the XLA compiler to use all available XLA devices, \n",
    "#such as GPUs or TPUs, for faster execution of TensorFlow computations.\n",
    "\n",
    "# for error \"Successfully opened dynamic library libcudart.so.10.1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e641b883-5dec-4722-aea7-14f6113a476a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to os.environ['TF_XLA_FLAGS'], but preferred way to enable XLA\n",
    "tf.config.optimizer.set_jit(True) \n",
    "\n",
    "tf.__version__ # TF version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da975d28-9400-4098-bcc8-78e4285ed055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/physical_device:CPU:0\n",
      "/physical_device:XLA_CPU:0\n",
      "/physical_device:GPU:0\n",
      "/physical_device:XLA_GPU:0\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.get_visible_devices()\n",
    "for dev in devices:\n",
    "    print(dev.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f37a21f-0c8c-4f7a-ace7-fedf5ec83951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e94d197-ab48-4036-9742-6b15bf58614c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Total memory: 32768.0 MB\n",
      "       Free memory: 32497.375 MB\n"
     ]
    }
   ],
   "source": [
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "gpus = pynvml.nvmlDeviceGetCount()\n",
    "for i in range(gpus):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU {i}: Total memory: {info.total / (1024**2)} MB\")\n",
    "    print(f\"       Free memory: {info.free / (1024**2)} MB\")\n",
    "\n",
    "pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2cc9c-c1d4-4d93-a7dd-aa10a4aaf0f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## fully connected model with flatten input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14c87d0-cc56-48a0-9e63-a8f81b9e7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d127b31-98d7-4fcb-a371-5adff6a31ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # add flatten layer to the model first\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # add dense layer with 300 neurons second\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # third\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # last, which is output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c268ced8-7dae-441e-961b-5d6bd867e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495c9c41-dfee-4e31-b141-dd44dd4429c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'weight_decay': None,\n",
       " 'clipnorm': None,\n",
       " 'global_clipnorm': None,\n",
       " 'clipvalue': None,\n",
       " 'use_ema': False,\n",
       " 'ema_momentum': 0.99,\n",
       " 'ema_overwrite_frequency': None,\n",
       " 'jit_compile': True,\n",
       " 'is_legacy_optimizer': False,\n",
       " 'learning_rate': 0.01,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Keras, compile() is a method used to configure the learning process of a model. \n",
    "# This method defines the loss function, optimizer, and metrics for training\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", # sparse when categories are in integers\n",
    "    optimizer=\"sgd\", # Stochastic Gradient Descent\n",
    "    metrics=[\"accuracy\"]) # performance metrics for each epoch on validataion dataset\n",
    "\n",
    "# An optimizer is an gradient descent method algorithm to update the weights and biases\n",
    "model.optimizer.get_config() # default mini batch size for SGD is 32 in keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b3b795-479a-4501-8a5f-32f122c0051f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7192 - accuracy: 0.7661 - val_loss: 0.5073 - val_accuracy: 0.8338\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4900 - accuracy: 0.8295 - val_loss: 0.4574 - val_accuracy: 0.8430\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4446 - accuracy: 0.8453 - val_loss: 0.4217 - val_accuracy: 0.8572\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4177 - accuracy: 0.8527 - val_loss: 0.3932 - val_accuracy: 0.8634\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3976 - accuracy: 0.8601 - val_loss: 0.3940 - val_accuracy: 0.8612\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3805 - accuracy: 0.8664 - val_loss: 0.3911 - val_accuracy: 0.8618\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3661 - accuracy: 0.8708 - val_loss: 0.3672 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3543 - accuracy: 0.8744 - val_loss: 0.3567 - val_accuracy: 0.8758\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3428 - accuracy: 0.8784 - val_loss: 0.3549 - val_accuracy: 0.8740\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.8808 - val_loss: 0.3582 - val_accuracy: 0.8690\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3253 - accuracy: 0.8834 - val_loss: 0.3329 - val_accuracy: 0.8828\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3178 - accuracy: 0.8856 - val_loss: 0.3359 - val_accuracy: 0.8800\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3100 - accuracy: 0.8881 - val_loss: 0.3271 - val_accuracy: 0.8798\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3033 - accuracy: 0.8913 - val_loss: 0.3213 - val_accuracy: 0.8850\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2977 - accuracy: 0.8931 - val_loss: 0.3273 - val_accuracy: 0.8778\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2911 - accuracy: 0.8955 - val_loss: 0.3150 - val_accuracy: 0.8854\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2849 - accuracy: 0.8960 - val_loss: 0.3196 - val_accuracy: 0.8840\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2806 - accuracy: 0.8988 - val_loss: 0.3103 - val_accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2751 - accuracy: 0.8998 - val_loss: 0.3142 - val_accuracy: 0.8848\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2692 - accuracy: 0.9024 - val_loss: 0.3340 - val_accuracy: 0.8772\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2656 - accuracy: 0.9050 - val_loss: 0.3062 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2608 - accuracy: 0.9062 - val_loss: 0.3009 - val_accuracy: 0.8890\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2560 - accuracy: 0.9079 - val_loss: 0.2997 - val_accuracy: 0.8942\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2521 - accuracy: 0.9087 - val_loss: 0.3011 - val_accuracy: 0.8892\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2482 - accuracy: 0.9107 - val_loss: 0.3017 - val_accuracy: 0.8912\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2441 - accuracy: 0.9116 - val_loss: 0.2951 - val_accuracy: 0.8942\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2409 - accuracy: 0.9131 - val_loss: 0.2992 - val_accuracy: 0.8918\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2365 - accuracy: 0.9155 - val_loss: 0.3016 - val_accuracy: 0.8892\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2330 - accuracy: 0.9164 - val_loss: 0.2991 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2291 - accuracy: 0.9183 - val_loss: 0.2974 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid)) # fit method initiates training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce9478-42b7-4f80-a074-80509293e386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## basic keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2f5c5fc7-4e01-4896-a377-c47c02d877f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractRNNCell          Activation               ActivityRegularization   Add                      AdditiveAttention        AlphaDropout             Attention                Average                  AveragePooling1D         AveragePooling2D         AveragePooling3D         AvgPool1D                AvgPool2D                AvgPool3D                BatchNormalization       Bidirectional            CategoryEncoding         CenterCrop               Concatenate              Conv1D                   Conv1DTranspose          Conv2D                   Conv2DTranspose          Conv3D                   Conv3DTranspose          ConvLSTM1D               ConvLSTM2D               ConvLSTM3D               Convolution1D            Convolution1DTranspose   Convolution2D            Convolution2DTranspose   Convolution3D            Convolution3DTranspose   Cropping1D               Cropping2D               Cropping3D               Dense                    DenseFeatures            DepthwiseConv1D          DepthwiseConv2D          Discretization           Dot                      Dropout                  ELU                      EinsumDense              Embedding                Flatten                  GRU                      GRUCell                  GaussianDropout          GaussianNoise            GlobalAveragePooling1D   GlobalAveragePooling2D   GlobalAveragePooling3D   GlobalAvgPool1D          GlobalAvgPool2D          GlobalAvgPool3D          GlobalMaxPool1D          GlobalMaxPool2D          GlobalMaxPool3D          GlobalMaxPooling1D       GlobalMaxPooling2D       GlobalMaxPooling3D       Hashing                  InputLayer               IntegerLookup            LSTM                     LSTMCell                 Lambda                   Layer                    LayerNormalization       LeakyReLU                LocallyConnected1D       LocallyConnected2D       Masking                  MaxPool1D                MaxPool2D                MaxPool3D                MaxPooling1D             MaxPooling2D             MaxPooling3D             Maximum                  Minimum                  MultiHeadAttention       Multiply                 Normalization            PReLU                    Permute                  RNN                      RandomBrightness         RandomContrast           RandomCrop               RandomFlip               RandomHeight             RandomRotation           RandomTranslation        RandomWidth              RandomZoom               ReLU                     RepeatVector             Rescaling                Reshape                  Resizing                 SeparableConv1D          SeparableConv2D          SeparableConvolution1D   SeparableConvolution2D   SimpleRNN                SimpleRNNCell            Softmax                  SpatialDropout1D         SpatialDropout2D         SpatialDropout3D         StackedRNNCells          StringLookup             Subtract                 TextVectorization        ThresholdedReLU          TimeDistributed          UnitNormalization        UpSampling1D             UpSampling2D             UpSampling3D             Wrapper                  ZeroPadding1D            ZeroPadding2D            ZeroPadding3D            "
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.layers.pooling.average_pooling3d.AveragePooling3D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AveragePooling3D\n"
     ]
    }
   ],
   "source": [
    "# list of laysers in keras (ignore Layer method below)\n",
    "layers = mods.list_attr('layers')\n",
    "\n",
    "# randomly select a layer name\n",
    "rand_layer = random.choice(layers) # randomly select an layer name\n",
    "\n",
    "# layer class with the above layer name with 300 neurons\n",
    "rand_layer = getattr(keras.layers, rand_layer)\n",
    "display(rand_layer)\n",
    "\n",
    "# get the name of the chosen layer \n",
    "layer_name = rand_layer.__name__\n",
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb160f-ca66-4a9c-b878-a3110928a3f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## basic keras layer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816e2236-20e6-4403-ad87-dea942db822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units: This specifies the number of neurons in the layer\n",
    "# use_bias: This specifies whether to include a bias term in the layer (default True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "507dfb1b-b008-4d86-87ec-04de356eecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elu                 exponential         gelu                hard_sigmoid        linear              relu                selu                sigmoid             softmax             softplus            softsign            swish               tanh                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function keras.activations.linear(x)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n"
     ]
    }
   ],
   "source": [
    "# activation: This specifies the activation function to be used in the layer.\n",
    "\n",
    "# the below code lists activation functions (ignore deserialize, get, and serialize methods)\n",
    "activations = []\n",
    "for act in dir(keras.activations):\n",
    "    if not act.startswith('_') and act not in ['deserialize', 'get', 'serialize']:\n",
    "        activations.append(act)\n",
    "        print(act.ljust(20), end='')\n",
    "\n",
    "# randomly select an activation function name\n",
    "rand_act = random.choice(activations) \n",
    "\n",
    "# dense layer instantiation with the above activation name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, activation=rand_act)\n",
    "display(dense_layer.activation)\n",
    "\n",
    "# get the name of the activation function from the above layer \n",
    "act_name = dense_layer.activation.__name__\n",
    "print(act_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fac56e50-747d-47a2-8824-ad8aff992eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all activation functions on one figure\n",
    "# Define the x values\n",
    "x = tf.linspace(-5., 5., 200)\n",
    "\n",
    "# Define the activation functions with out exponential\n",
    "activation_functions = [\n",
    "    tf.nn.elu, \n",
    "    tf.nn.gelu, \n",
    "    tf.nn.relu, \n",
    "    tf.nn.selu, \n",
    "    tf.nn.sigmoid, \n",
    "    tf.nn.softmax, \n",
    "    tf.nn.softplus, \n",
    "    tf.nn.softsign, \n",
    "    tf.nn.swish, \n",
    "    tf.nn.tanh]\n",
    "\n",
    "# Plot the activation functions\n",
    "for activation in activation_functions[:]: # select the ones you want to plot\n",
    "    with tf.compat.v1.Session().as_default():\n",
    "        plt.plot(x, activation(tf.constant(x)).numpy(), label=activation.__name__)\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Activation functions')\n",
    "plt.legend(loc='best', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "30064ee5-d4f2-4b20-b8c4-88223a8a5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant                 GlorotNormal             GlorotUniform            HeNormal                 HeUniform                Identity                 Initializer              LecunNormal              LecunUniform             Ones                     Orthogonal               RandomNormal             RandomUniform            TruncatedNormal          VarianceScaling          Zeros                    "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.initializers.initializers_v2.Constant at 0x15435aa276d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant\n"
     ]
    }
   ],
   "source": [
    "# kernel_initializer: This specifies the method for initializing the weights of the layer\n",
    "# bias_initializer is for biases\n",
    "\n",
    "# list of kernel initializers in keras (ignore Initializer method below)\n",
    "initializers = handson.list_attr('initializers')\n",
    "\n",
    "# randomly select an kernel initializer name\n",
    "rand_init = random.choice(initializers) \n",
    "\n",
    "# dense layer instantiation with the above kernel initializer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_initializer=rand_init)\n",
    "display(dense_layer.kernel_initializer)\n",
    "\n",
    "# get the name of the kernel initializer from the above layer \n",
    "init_name = dense_layer.kernel_initializer.__class__.__name__\n",
    "print(init_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "542d30c2-6ec6-47db-a408-de941d8991e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1                       L1L2                     L2                       OrthogonalRegularizer    Regularizer              "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1 at 0x15435aa24940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n"
     ]
    }
   ],
   "source": [
    "# kernel_regularizer: This specifies the regularization method to be applied to the weights \n",
    "# of the layer. bias_regularizer is for biases\n",
    "\n",
    "# list of kernel regularizers in keras (ignore Regularizer method below)\n",
    "kernel_regularizer = handson.list_attr('regularizers')\n",
    "# randomly select a kernel regularizer name\n",
    "rand_reg = random.choice(kernel_regularizer) \n",
    "\n",
    "# dense layer instantiation with the above kernel regularizer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_regularizer=rand_reg)\n",
    "display(dense_layer.kernel_regularizer)\n",
    "\n",
    "# get the name of the kernel regularizer from the above layer \n",
    "reg_name = dense_layer.kernel_regularizer.__class__.__name__\n",
    "print(reg_name)\n",
    "\n",
    "# activity_regularizer: regularization method applied to the output of the layer\n",
    "# same regularizers from kernel regularizations can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e8d15c15-5a88-4cba-94a8-62e88f479183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint               MaxNorm                  MinMaxNorm               NonNeg                   RadialConstraint         UnitNorm                 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.constraints.RadialConstraint at 0x15435aa26b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadialConstraint\n"
     ]
    }
   ],
   "source": [
    "# kernel_constraint: This specifies the constraint to be applied to the weights of the layer.\n",
    "# bias_constraint is for biases\n",
    "# kernel constraints enforce constraints directly on the weights of the neural network.\n",
    "# whereas kernel regularizers add a penalty term to the loss function \n",
    "\n",
    "# list of kernel constraints in keras (ignore Constraint method below)\n",
    "kernel_constraints = handson.list_attr('constraints')\n",
    "\n",
    "# randomly select a kernel constraints name\n",
    "rand_con = random.choice(kernel_constraints) \n",
    "\n",
    "# dense layer instantiation with the above kernel regularizer name with 300 neurons\n",
    "dense_layer = keras.layers.Dense(units=300, kernel_constraint=rand_con)\n",
    "display(dense_layer.kernel_constraint)\n",
    "\n",
    "# get the name of the kernel regularizer from the above layer \n",
    "con_name = dense_layer.kernel_constraint.__class__.__name__\n",
    "print(con_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe858618-6083-4c73-86d2-91b4728ff81e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## loss functions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2d0bc2be-9155-4209-a61f-6a0040c05476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryCrossentropy                                          BinaryFocalCrossentropy                                     CategoricalCrossentropy                                     CategoricalHinge                                            CosineSimilarity                                            Hinge                                                       Huber                                                       KLD                                                         KLDivergence                                                LogCosh                                                     Loss                                                        MAE                                                         MAPE                                                        MSE                                                         MSLE                                                        MeanAbsoluteError                                           MeanAbsolutePercentageError                                 MeanSquaredError                                            MeanSquaredLogarithmicError                                 Poisson                                                     Reduction                                                   SparseCategoricalCrossentropy                               SquaredHinge                                                binary_crossentropy                                         binary_focal_crossentropy                                   categorical_crossentropy                                    categorical_hinge                                           cosine_similarity                                           hinge                                                       huber                                                       kl_divergence                                               kld                                                         kullback_leibler_divergence                                 log_cosh                                                    logcosh                                                     mae                                                         mape                                                        mean_absolute_error                                         mean_absolute_percentage_error                              mean_squared_error                                          mean_squared_logarithmic_error                              mse                                                         msle                                                        poisson                                                     sparse_categorical_crossentropy                             squared_hinge                                               \n",
      "huber\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'huber'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss: This specifies the loss function (or cost function) to be used in the layer.\n",
    "\n",
    "# the below code lists loss functions (ignore deserialize, get, and serialize methods)\n",
    "losses = []\n",
    "for loss in dir(keras.losses):\n",
    "    if not loss.startswith('_') and loss not in ['deserialize', 'get', 'serialize']:\n",
    "        losses.append(loss)\n",
    "        print(loss.ljust(60), end='')\n",
    "\n",
    "# randomly select an loss function name\n",
    "rand_loss = random.choice(losses) # randomly select an activation function name\n",
    "print()\n",
    "print(rand_loss)\n",
    "\n",
    "# load pretrained VGG16 model\n",
    "model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# compile the model with the randomly chosen loss function\n",
    "model.compile(loss=rand_loss)\n",
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cc8705f6-5af0-46bb-b64e-4c5f9d02bd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC                                               Accuracy                                          BinaryAccuracy                                    BinaryCrossentropy                                BinaryIoU                                         CategoricalAccuracy                               CategoricalCrossentropy                           CategoricalHinge                                  CosineSimilarity                                  FalseNegatives                                    FalsePositives                                    Hinge                                             IoU                                               KLDivergence                                      LogCoshError                                      Mean                                              MeanAbsoluteError                                 MeanAbsolutePercentageError                       MeanIoU                                           MeanMetricWrapper                                 MeanRelativeError                                 MeanSquaredError                                  MeanSquaredLogarithmicError                       MeanTensor                                        Metric                                            OneHotIoU                                         OneHotMeanIoU                                     Poisson                                           Precision                                         PrecisionAtRecall                                 Recall                                            RecallAtPrecision                                 RootMeanSquaredError                              SensitivityAtSpecificity                          SparseCategoricalAccuracy                         SparseCategoricalCrossentropy                     SparseTopKCategoricalAccuracy                     SpecificityAtSensitivity                          SquaredHinge                                      Sum                                               TopKCategoricalAccuracy                           TrueNegatives                                     TruePositives                                     \n",
      "OneHotMeanIoU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of metrics in keras (ignore Metric method below)\n",
    "metrics = handson.list_attr('metrics', 50)\n",
    "print()\n",
    "\n",
    "# randomly select a metric name\n",
    "rand_metric = random.choice(metrics) # randomly select an activation function name\n",
    "\n",
    "# load pretrained VGG16 model\n",
    "model = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# compile the model with the randomly chosen metric\n",
    "model.compile(metrics=[rand_metric])\n",
    "\n",
    "print(rand_metric)\n",
    "model.metrics # it will return an empty list since the model is never trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ea8d0-aa77-403d-aaa1-ea3695ad39e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model history and evaluation (previous model training needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc0f932-b283-49b5-b095-9e5fb2a618ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6e3d05a-8b38-4bd8-93df-b88d80a793d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys(), end='\\n\\n')\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(range(len(val_accuracy)), val_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4ca71e4-7298-4c20-b51e-b6b04e62116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 992us/step - loss: 60.1161 - accuracy: 0.8503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[60.116050720214844, 0.8503000140190125]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bb6f4-28ad-45cf-905b-f1b2c971a261",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93caeec1-a726-40ba-a23f-f55aac57430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee7d6aea-377f-4688-92e8-be5bce1a2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba6902b9-74b4-424a-9b70-be9814de5d76",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8334 - val_loss: 0.6144\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.4973\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4847\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9033 - val_loss: 0.5254\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7038 - val_loss: 0.4664\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.4346\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4142\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4094\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4020\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3954\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3977\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3592 - val_loss: 0.3903\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3900\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3845\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3848\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3840\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3821\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3829\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3721\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3731\n",
      "162/162 [==============================] - 0s 786us/step - loss: 0.3539\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c36818d-0311-4d29-b1ca-171b79491a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353873074054718"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d382d2-d256-4101-a9fd-b2d4752379cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with hidden concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a61bf2-8dea-4a64-894c-32a9987b64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2856f740-b95d-4580-b77c-dafbd125cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c29ab04-4cc5-4c2c-bbc5-2ee819b014d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7307 - val_loss: 3.7913\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# it does not work well\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3b55-cd29-47a4-81e4-9dc6d8a46a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## two inputs model with concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f332dd-7cef-49d1-8835-a12ee8b711b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15f61c67-d27e-44f3-828c-0f5ff6511b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9340c31c-c01a-4296-8ee5-dbf1ef9c58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d895d54c-a784-467d-971e-3a3a45e474c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3)) \n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbe126c3-01a9-4324-8886-8b3ef93c9e61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2099 - val_loss: 0.9340\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8194 - val_loss: 0.7372\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7093 - val_loss: 0.6811\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6663 - val_loss: 0.6494\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6383 - val_loss: 0.6266\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6059\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.5857\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.5707\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5546\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5515 - val_loss: 0.5409\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.5288\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.5194\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5097\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.5017\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5010 - val_loss: 0.4955\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.4889\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4946 - val_loss: 0.4863\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4891 - val_loss: 0.4800\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4850\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4734\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), \n",
    "    y_train, \n",
    "    epochs=20,\n",
    "    validation_data=((X_valid_A, X_valid_B),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a758b4d8-5a45-40b0-a73c-56041085bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 865us/step - loss: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.486760675907135"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7917f9-f80d-4cad-a5bf-c0eb5c647879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## two inputs and two outputs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbafc9a-24bf-4d52-bb92-522bfe4b06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01fe8dd5-dc1f-4519-8c58-41ac22b74bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f35cca9d-bcc1-4610-893e-73d5fd9ad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07ae7f2a-9181-48a2-81b6-2368ca4766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first output is more important, so more weight is assigned on it for loss function\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1e79fb0-3bc6-43a7-bce1-990f9d1f90c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9012 - main_output_loss: 0.7970 - aux_output_loss: 1.8398 - val_loss: 1.0476 - val_main_output_loss: 1.0383 - val_aux_output_loss: 1.1313\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6920 - main_output_loss: 0.6541 - aux_output_loss: 1.0333 - val_loss: 0.6091 - val_main_output_loss: 0.5581 - val_aux_output_loss: 1.0682\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5399 - main_output_loss: 0.4935 - aux_output_loss: 0.9581 - val_loss: 0.6482 - val_main_output_loss: 0.6223 - val_aux_output_loss: 0.8817\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5700 - main_output_loss: 0.5435 - aux_output_loss: 0.8091 - val_loss: 0.5049 - val_main_output_loss: 0.4736 - val_aux_output_loss: 0.7862\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - main_output_loss: 0.4484 - aux_output_loss: 0.7354 - val_loss: 0.4858 - val_main_output_loss: 0.4574 - val_aux_output_loss: 0.7415\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4670 - main_output_loss: 0.4418 - aux_output_loss: 0.6933 - val_loss: 0.4743 - val_main_output_loss: 0.4475 - val_aux_output_loss: 0.7160\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4493 - main_output_loss: 0.4253 - aux_output_loss: 0.6655 - val_loss: 0.4676 - val_main_output_loss: 0.4415 - val_aux_output_loss: 0.7029\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4402 - main_output_loss: 0.4171 - aux_output_loss: 0.6479 - val_loss: 0.4542 - val_main_output_loss: 0.4309 - val_aux_output_loss: 0.6636\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4301 - main_output_loss: 0.4081 - aux_output_loss: 0.6281 - val_loss: 0.4458 - val_main_output_loss: 0.4229 - val_aux_output_loss: 0.6525\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4251 - main_output_loss: 0.4042 - aux_output_loss: 0.6136 - val_loss: 0.4437 - val_main_output_loss: 0.4219 - val_aux_output_loss: 0.6395\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4185 - main_output_loss: 0.3982 - aux_output_loss: 0.6009 - val_loss: 0.4390 - val_main_output_loss: 0.4155 - val_aux_output_loss: 0.6504\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4102 - main_output_loss: 0.3903 - aux_output_loss: 0.5891 - val_loss: 0.4310 - val_main_output_loss: 0.4101 - val_aux_output_loss: 0.6191\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4041 - main_output_loss: 0.3850 - aux_output_loss: 0.5765 - val_loss: 0.4403 - val_main_output_loss: 0.4217 - val_aux_output_loss: 0.6078\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3996 - main_output_loss: 0.3810 - aux_output_loss: 0.5665 - val_loss: 0.5035 - val_main_output_loss: 0.4946 - val_aux_output_loss: 0.5831\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3958 - main_output_loss: 0.3777 - aux_output_loss: 0.5588 - val_loss: 0.4358 - val_main_output_loss: 0.4200 - val_aux_output_loss: 0.5783\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3907 - main_output_loss: 0.3729 - aux_output_loss: 0.5511 - val_loss: 0.4124 - val_main_output_loss: 0.3947 - val_aux_output_loss: 0.5721\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3866 - main_output_loss: 0.3695 - aux_output_loss: 0.5404 - val_loss: 0.4053 - val_main_output_loss: 0.3882 - val_aux_output_loss: 0.5593\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3819 - main_output_loss: 0.3649 - aux_output_loss: 0.5348 - val_loss: 0.4802 - val_main_output_loss: 0.4722 - val_aux_output_loss: 0.5524\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - main_output_loss: 0.3652 - aux_output_loss: 0.5281 - val_loss: 0.3991 - val_main_output_loss: 0.3829 - val_aux_output_loss: 0.5453\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - main_output_loss: 0.3593 - aux_output_loss: 0.5226 - val_loss: 0.4125 - val_main_output_loss: 0.3965 - val_aux_output_loss: 0.5567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], \n",
    "    [y_train, y_train], \n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fd740b9-dad4-461b-97c8-6844fcdcbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3910 - main_output_loss: 0.3742 - aux_output_loss: 0.5421\n",
      "0.39098742604255676 0.37419408559799194 0.5421300530433655\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "print(total_loss, main_loss, aux_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e88b5-1e4b-4843-b3bd-47824e2b128c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e832a0b-8542-42c1-914a-a5d6895728ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75ddd879-49c2-4684-94e9-d5d05d63e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint is a callback function in Keras that saves the model weights during training. \n",
    "# It allows you to save the best model observed during training based on a specified metric, \n",
    "# such as validation loss or accuracy.\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.hdf5\", save_best_only=True)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9f26f80-4712-4ee9-b03e-8f9cbb5cf745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0102 - val_loss: 1.0858\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6909 - val_loss: 0.4760\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4251\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4208\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3999\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4053\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3985\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4004\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4031\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.4025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    validation_data=(X_valid, y_valid), \n",
    "    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9aa11136-5296-4b39-a244-ee10290c107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.hdf5\") # roll back to best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d79eb-6b30-4e0b-bfb5-9f2f656e1568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64c7626c-68dd-4c18-a773-4737928be829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f9ec7f48-5c78-4e70-8060-af4a99081c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping is a callback in Keras that can be used during training to automatically stop \n",
    "# training when a monitored metric stops improving. It is designed to prevent overfitting and \n",
    "# reduce training time by stopping the training process early when further training is unlikely\n",
    "# to improve the model's performance.\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# In early stopping, \"patience\" is a hyperparameter that determines the number of epochs \n",
    "# the model can undergo without improvement in the monitored quantity before stopping the \n",
    "# training process. \n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "b7085dab-2f76-434e-96f3-d9d24b8e0b85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2088 - val_loss: 7.5077\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7584 - val_loss: 0.5632\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4733\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4236\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4147\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4266\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4127\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4273\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4150\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3880\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.3834\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3795\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.3836\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3771\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3776\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3681\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3705\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3690\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3701\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3662\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3676\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3671\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3586\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3547\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3582\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3583\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3569\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3567\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3537\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3523\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3487\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.3437\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3441\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3412\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3505\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3483\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3420\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3408\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.3390\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3385\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3900\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3361\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3327\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3318\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3501\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.3335\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3325\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3361\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3741\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3312\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3250\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4395\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3283\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3269\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3336\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3291\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3770\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3272\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3290\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3270\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3265\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "cc4c6138-b48e-467f-b3f1-b02f726baf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 764us/step - loss: 0.3466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34658145904541016"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72763e0-dfb9-4e5c-a5ed-79bb7f7d3d4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with batch normalization layers and kernal initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61488ecc-aee4-4139-8cdf-fdd25f908da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1b810a4-2da7-4b23-9264-a1c7fcfc0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization normalizes intermediate vectors between layers. The benefits are:\n",
    "# 1. Improved training speed \n",
    "# 2. Better generalization\n",
    "# 3. Less sensitivity to weight initialization\n",
    "# 4. High tolerance on higher learning rates\n",
    "# 5. Regularization\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(15, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b79cd569-250e-4b41-bf7e-1fa1ef7c8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25aa0b53-6a2b-4c3a-b81a-ac091bb5bd54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6945 - val_loss: 0.6429\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4921 - val_loss: 0.8938\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4671 - val_loss: 1.5521\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 2.7702\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 4.2075\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 2.2570\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 4.9916\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 1.6127\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4442 - val_loss: 2.9564\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 5.1739\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4385 - val_loss: 1.9035\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4303 - val_loss: 1.5764\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 1.0910\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 3.1749\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 8.6971\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 4.1409\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 6.8884\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 1.0653\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 2.4973\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4305 - val_loss: 1.3900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38a387ab-0d3a-41c8-88ce-d5d56b47ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 927us/step - loss: 0.5709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5708961486816406"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4fbfad-0663-42f1-bd6c-cf6b6fe83f7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## transfer learning (skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2673d03-42fb-42c0-8427-02683ebbaced",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model with dropout layers and functools.partial application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "decaf251-f309-4884-99e9-1463ae55864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.fashion_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "949116ca-d4b4-4196-8ae8-008697de29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dropout layer is a regularization layer that helps to prevent overfitting in deep \n",
    "# learning models. It works by randomly dropping out (i.e., setting to zero) a fraction of \n",
    "# the input units during training. This forces the network to learn more robust features and \n",
    "# reduces the likelihood of the network relying too heavily on any one input feature, which \n",
    "# can lead to overfitting. During inference or prediction, the dropout layer is typically \n",
    "# turned off, and the weights of the remaining neurons are scaled accordingly to ensure that \n",
    "# the expected output of the layer remains the same.\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05f1652e-8392-416c-8173-1419ad3b085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense = partial(\n",
    "    keras.layers.Dense,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "882bc711-c668-4cd0-aad1-7555a44d1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    Dense(300),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    Dense(100),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f601854-8d3c-459d-a117-d46415faadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db73bdd8-f111-4770-9aec-e4a43ea7ccc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7738 - accuracy: 0.7190 - val_loss: 0.5017 - val_accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5798 - accuracy: 0.7908 - val_loss: 0.4600 - val_accuracy: 0.8378\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5366 - accuracy: 0.8061 - val_loss: 0.4331 - val_accuracy: 0.8488\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5130 - accuracy: 0.8144 - val_loss: 0.4166 - val_accuracy: 0.8546\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4986 - accuracy: 0.8192 - val_loss: 0.4083 - val_accuracy: 0.8548\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4846 - accuracy: 0.8239 - val_loss: 0.4106 - val_accuracy: 0.8550\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4746 - accuracy: 0.8278 - val_loss: 0.3903 - val_accuracy: 0.8616\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4674 - accuracy: 0.8297 - val_loss: 0.3988 - val_accuracy: 0.8592\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4612 - accuracy: 0.8315 - val_loss: 0.3830 - val_accuracy: 0.8642\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4532 - accuracy: 0.8344 - val_loss: 0.3775 - val_accuracy: 0.8646\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4485 - accuracy: 0.8355 - val_loss: 0.3765 - val_accuracy: 0.8666\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4452 - accuracy: 0.8367 - val_loss: 0.3689 - val_accuracy: 0.8684\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4411 - accuracy: 0.8380 - val_loss: 0.3666 - val_accuracy: 0.8686\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4330 - accuracy: 0.8402 - val_loss: 0.3663 - val_accuracy: 0.8706\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4345 - accuracy: 0.8405 - val_loss: 0.3598 - val_accuracy: 0.8704\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4292 - accuracy: 0.8425 - val_loss: 0.3561 - val_accuracy: 0.8720\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4248 - accuracy: 0.8451 - val_loss: 0.3567 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4211 - accuracy: 0.8449 - val_loss: 0.3523 - val_accuracy: 0.8712\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4235 - accuracy: 0.8436 - val_loss: 0.3557 - val_accuracy: 0.8718\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4158 - accuracy: 0.8462 - val_loss: 0.3475 - val_accuracy: 0.8752\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4146 - accuracy: 0.8465 - val_loss: 0.3475 - val_accuracy: 0.8734\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4118 - accuracy: 0.8491 - val_loss: 0.3441 - val_accuracy: 0.8768\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4058 - accuracy: 0.8501 - val_loss: 0.3448 - val_accuracy: 0.8748\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4060 - accuracy: 0.8506 - val_loss: 0.3407 - val_accuracy: 0.8746\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4073 - accuracy: 0.8497 - val_loss: 0.3406 - val_accuracy: 0.8724\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4023 - accuracy: 0.8512 - val_loss: 0.3389 - val_accuracy: 0.8768\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3986 - accuracy: 0.8533 - val_loss: 0.3395 - val_accuracy: 0.8762\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3963 - accuracy: 0.8527 - val_loss: 0.3324 - val_accuracy: 0.8792\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3980 - accuracy: 0.8514 - val_loss: 0.3338 - val_accuracy: 0.8770\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3948 - accuracy: 0.8532 - val_loss: 0.3312 - val_accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b8d24db-8a58-4161-a127-c354b8cb1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37001723051071167, 0.8640000224113464]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d6a50-92c5-4db4-95e4-20129be03d40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## adding normalization layer to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b18d47-487a-444e-96bb-81dd4f52fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sejinnam/.conda/envs/TF/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfa046c-c7b8-4e21-8c0a-a70d073f523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple fully connected model with normalization layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Normalization(mean=0.0, variance=1.0),\n",
    "    keras.layers.Dense(32, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24f8317-7d8a-4792-8678-fbe482979eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = tf.keras.layers.Normalization() # create normalization layer\n",
    "norm_layer.adapt(X_train) # assign the layer mean and variance to those of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce216f4-9cf1-485f-9f85-7249f7d4e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final model that takes data that is not normalized\n",
    "final_model = tf.keras.Sequential([norm_layer, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f44f21b-0529-477e-8332-3a8cab359d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6be95b5-dd65-4960-a34e-048064de3329",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 2s 1ms/step - loss: 1.5499 - val_loss: 1.4351\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 3.0645 - val_loss: 1.3190\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3854 - val_loss: 1.3231\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3701 - val_loss: 1.2854\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3680 - val_loss: 1.3853\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3608 - val_loss: 1.3142\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3589 - val_loss: 1.2936\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3588 - val_loss: 1.2879\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3584 - val_loss: 1.2817\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3583 - val_loss: 1.2988\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3566 - val_loss: 1.2791\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3540 - val_loss: 1.2850\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3550 - val_loss: 1.2888\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3555 - val_loss: 1.2970\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3535 - val_loss: 1.2852\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3530 - val_loss: 1.2865\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3508 - val_loss: 1.2877\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3508 - val_loss: 1.2795\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3518 - val_loss: 1.2900\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3528 - val_loss: 1.2949\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b709ea-aaa9-42d8-ae2b-b785e330c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2976197004318237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = final_model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4792622-90a5-4612-ab9e-2c375c8b5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 8)                17        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1)                 2689      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,706\n",
      "Trainable params: 2,689\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e210c-65e8-454a-a2ae-9761e9b7e348",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## faster optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2a9e72-ac9c-4e5e-bd43-e2e668a8966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "c120010b-259c-4006-93e8-d14461cad036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model without specifying an optimizer (compile is needed)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "e271ff94-6370-4725-8abb-e1eb8cfcc1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SGD (Stochastic Gradient Descent)\n",
    "optimizer = keras.optimizers.SGD()\n",
    "\n",
    "# default configuration of SGD\n",
    "display(optimizer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "9347d2e2-0202-4412-a210-d0a7a4f23b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorter way to execute the above code\n",
    "getattr(keras.optimizers, 'SGD')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "2c38533a-3aa4-4ad8-afc0-f644dafc3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adagrad',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'initial_accumulator_value': 0.1,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaGrad optimizer default configuration\n",
    "getattr(keras.optimizers, 'Adagrad')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "99cfd405-a92a-4017-9dff-b10c0474edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'RMSprop',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'rho': 0.9,\n",
       " 'momentum': 0.0,\n",
       " 'epsilon': 1e-07,\n",
       " 'centered': False}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSprop optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'RMSprop')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "dfb79de5-6f15-4443-b4ed-73ad8514d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adam optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Adam')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "edeb0d2b-f467-4d21-8c40-99f378c794a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adamax',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adamax optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Adamax')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "89d10d22-9449-4f12-a6c8-bf99c75046f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nadam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.004,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nadam optimizer default onfiguration\n",
    "getattr(keras.optimizers, 'Nadam')().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "567fcfdd-5ab9-4540-8cb9-44125ed92500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adadelta                 Adagrad                  Adam                     Adamax                   Ftrl                     Nadam                    Optimizer                RMSprop                  SGD                      \n",
      "Adamax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Adamax'"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of optimizers in keras (ignore Optimizer method below)\n",
    "optimizers = mods.list_attr('optimizers')\n",
    "\n",
    "# randomly select an kernel initializer name\n",
    "rand_opt = random.choice(optimizers)\n",
    "print()\n",
    "print(rand_opt)\n",
    "\n",
    "# model compile with the chosen optimizer\n",
    "model.compile(loss='mse', optimizer=rand_opt)\n",
    "model.optimizer.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7533383f-e97c-46a2-8ca9-08cc2af94995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3300\n",
      "Epoch 2/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.9098\n",
      "Epoch 3/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3651\n",
      "Epoch 4/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3376\n",
      "Epoch 5/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3503\n",
      "Epoch 6/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3351\n",
      "Epoch 7/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3337\n",
      "Epoch 8/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3336\n",
      "Epoch 9/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3304\n",
      "Epoch 10/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3281\n",
      "Epoch 11/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3396\n",
      "Epoch 12/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3308\n",
      "Epoch 13/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3300\n",
      "Epoch 14/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3351\n",
      "Epoch 15/15\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba0f664b9d0>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          epochs=15,\n",
    "          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172197c-2858-4d99-beb1-2d91f447c975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## learning rate schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00844f1-c621-4e3e-8ff8-1b053c8361f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "3c750e25-4803-486e-a584-57e715fbdc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "e79c67dc-cb05-45d1-b21f-7b3d9dcf4f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineDecay              CosineDecayRestarts      ExponentialDecay         InverseTimeDecay         PiecewiseConstantDecay   PolynomialDecay          "
     ]
    }
   ],
   "source": [
    "# A learning rate schedule is a way to adapt the learning rate during training\n",
    "# the below code lists keras builtin schedules \n",
    "schedules = []\n",
    "ignore = ['deserialize', 'LearningRateSchedule', 'serialize']\n",
    "\n",
    "for schedule in dir(keras.optimizers.schedules):\n",
    "    if not schedule.startswith('_') and schedule not in ignore:\n",
    "        schedules.append(schedule)\n",
    "        print(schedule.ljust(25), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "eafd7d47-34e6-483f-888b-0216f6c0db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay learning rate scheduler\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.05,\n",
    "    decay_rate = 0.1,\n",
    "    decay_steps = 5000)\n",
    "\n",
    "# RMSprop optimizer with the above lr_scheduler\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_scheduler)\n",
    "\n",
    "# model compile with mse loss and RMSprop optimizer\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "7cd7dce0-d50c-4a83-80e0-b55d78f0490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6544 - val_loss: 0.4351\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 5.6052\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.5103\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.6161\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4282\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3988\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3761\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3722\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3676\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3665\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3664\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3644\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3656\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3645\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3638\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3623\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3629\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3621\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3621\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3632\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3618\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3620\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3618\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3614\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3614\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3611\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3612\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3612\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3613\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba0c55a2b60>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training with expoential decay learning rate scheduler\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe1899-3d70-4e88-860e-e60ae2542e79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple convolution neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259d47da-6d02-4163-b1a8-226ba645c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520. 564. 502. 510. 482. 436. 496. 516. 485. 489.]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_784()\n",
    "print(np.sum(y_test, axis=0)) # check the test set target (one-hot encoding) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "039b9d00-6dee-447c-ba2b-954a418270b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_format', 'kernel_size', 'groups', 'dilation_rate', 'padding', 'strides', 'filters']\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.Conv2D arguments Dense layer does not have\n",
    "Conv2D_args = keras.layers.Conv2D(filters=4, kernel_size=5).get_config()\n",
    "Dense_args = keras.layers.Dense(units=4).get_config()\n",
    "Conv2D_args_only = list(set(Conv2D_args.keys()) - set(Dense_args.keys()))\n",
    "print(Conv2D_args_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc867071-0aaf-498c-9fa7-f5a239a95176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(8, 1), input_shape=[28, 28, 1]),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(1, 8), activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, strides=3, activation='relu'),\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=7, groups=1, activation='relu'),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 10) to 10\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0185304e-8dfe-48a0-8abd-7d3c8d4df954",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028e91c6-db87-4cb5-90ff-a4c4573be93b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1719/1719 [==============================] - 7s 2ms/step - loss: 0.2100 - accuracy: 0.9370 - val_loss: 0.0998 - val_accuracy: 0.9697\n",
      "Epoch 2/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0688 - accuracy: 0.9798 - val_loss: 0.0607 - val_accuracy: 0.9807\n",
      "Epoch 3/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.0607 - val_accuracy: 0.9827\n",
      "Epoch 4/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0525 - val_accuracy: 0.9843\n",
      "Epoch 5/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0532 - val_accuracy: 0.9846\n",
      "Epoch 6/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
      "Epoch 7/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0656 - val_accuracy: 0.9828\n",
      "Epoch 8/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0544 - val_accuracy: 0.9862\n",
      "Epoch 9/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0612 - val_accuracy: 0.9871\n",
      "Epoch 10/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0615 - val_accuracy: 0.9865\n",
      "Epoch 11/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0805 - val_accuracy: 0.9835\n",
      "Epoch 12/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0704 - val_accuracy: 0.9852\n",
      "Epoch 13/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0972 - val_accuracy: 0.9815\n",
      "Epoch 14/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0669 - val_accuracy: 0.9863\n",
      "Epoch 15/15\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0790 - val_accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=15,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb5674b-b2c7-4df0-be4e-6369dd2bb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03647341579198837, 0.9922000169754028]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfc972-dc62-46ec-b3e4-f6bb75a2d30c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN model with pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c6a20d-519f-4f3b-b6e2-c749250e6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520. 564. 502. 510. 482. 436. 496. 516. 485. 489.]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.mnist_784()\n",
    "print(np.sum(y_test, axis=0)) # check the test set target (one-hot encoding) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb99c006-3724-40c6-ad81-e2aa7a6064ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'max_pooling2d',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'pool_size': (2, 2),\n",
       " 'padding': 'valid',\n",
       " 'strides': (2, 2),\n",
       " 'data_format': 'channels_last'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.MaxPool2D().get_config() # Pooling layer has no trainable weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc60d426-8234-4ec1-adf2-d514a9989c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN model with pooling layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=9, input_shape=[28, 28, 1]),\n",
    "    keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=3, padding='same', activation='relu'), \n",
    "    keras.layers.GlobalAveragePooling2D(), # spatial dimensions collapse\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 10) to 10\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad0dfedb-a3a9-4266-8690-a14ff54f168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f7681a-27a1-472e-93f7-793eca373d50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4784 - accuracy: 0.8431 - val_loss: 0.1633 - val_accuracy: 0.9549\n",
      "Epoch 2/15\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1355 - accuracy: 0.9602 - val_loss: 0.1385 - val_accuracy: 0.9586\n",
      "Epoch 3/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0948 - accuracy: 0.9719 - val_loss: 0.0871 - val_accuracy: 0.9733\n",
      "Epoch 4/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.0700 - val_accuracy: 0.9793\n",
      "Epoch 5/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0633 - accuracy: 0.9807 - val_loss: 0.0531 - val_accuracy: 0.9849\n",
      "Epoch 6/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
      "Epoch 7/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0592 - val_accuracy: 0.9830\n",
      "Epoch 8/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.0490 - val_accuracy: 0.9841\n",
      "Epoch 9/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0714 - val_accuracy: 0.9785\n",
      "Epoch 10/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0434 - val_accuracy: 0.9875\n",
      "Epoch 11/15\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0368 - val_accuracy: 0.9898\n",
      "Epoch 12/15\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0540 - val_accuracy: 0.9847\n",
      "Epoch 13/15\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0568 - val_accuracy: 0.9859\n",
      "Epoch 14/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0370 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0324 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=15,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0d52f81-0f27-427d-a429-af94a7efc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01075205858796835, 0.9959999918937683]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee2c19-365a-483c-8e75-b71554750319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with RGB images (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2068d1d6-9def-4ee6-a6a2-a531be188444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f5b55b6-d23c-4b85-b760-a323576b94ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846cfdad-3fcd-455b-b711-73329d9ad097",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3afc27ad-3b76-4864-a836-ae97e8d9516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef213d-968c-41e1-9355-b1d0e76f4ace",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16829719-b4f5-459b-b64b-3da72766238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1251 - accuracy: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1250826120376587, 0.6728000044822693]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = model.evaluate(X_test, y_test)\n",
    "acc_test # not as impressive as training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec7f89-51e7-4f31-8f38-5907f0aa5e31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## simple recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "afbbc860-db78-4799-b3dd-45fc05faaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = handson.rail_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "20b174a7-6d61-466b-aad0-5c30645bd089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_sequences': False,\n",
       " 'return_state': False,\n",
       " 'go_backwards': False,\n",
       " 'stateful': False,\n",
       " 'unroll': False,\n",
       " 'time_major': False,\n",
       " 'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "  'config': {'gain': 1.0, 'seed': None}},\n",
       " 'recurrent_regularizer': None,\n",
       " 'recurrent_constraint': None,\n",
       " 'dropout': 0.0,\n",
       " 'recurrent_dropout': 0.0}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.SimpleRNN arguments Dense layer does not have\n",
    "SimpleRNN_args = keras.layers.SimpleRNN(units=32).get_config()\n",
    "Dense_keys = keras.layers.Dense(units=4).get_config().keys()\n",
    "SimpleRNN_args_only = {k: v for k, v in SimpleRNN_args.items() if k not in Dense_keys}\n",
    "SimpleRNN_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "00917c15-257e-4aaf-b207-560b7706b057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    keras.layers.Dense(1) # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3c03a393-4c91-44d5-9472-a9c11d34088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "96f44bff-3cec-4cce-b730-0466d541cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d635aca-7f26-4e33-af36-d7ce32f71d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 28ms/step - loss: 0.0196 - mae: 0.1538 - val_loss: 0.0037 - val_mae: 0.0631\n"
     ]
    }
   ],
   "source": [
    "log = model.fit(\n",
    "    train_ds, \n",
    "    validation_data=valid_ds, \n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a66be1f4-d376-4eec-b569-8c3e435cf60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0431 - mae: 0.2382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.043077584356069565, 0.23815713822841644]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(test_ds)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9189b1f2-0556-4104-8075-0f4e3ed58c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d267dd01-e29f-4482-8a1c-c1350a463fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(32),\n",
    "    keras.layers.Dense(1) # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a31834-8e5b-4d4d-8d64-2d3abdeb96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe40980-6462-4831-bd38-c533121dbbbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 4s 74ms/step - loss: 0.0628 - mae: 0.2433 - val_loss: 0.0095 - val_mae: 0.1172\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0093 - mae: 0.1088 - val_loss: 0.0075 - val_mae: 0.1030\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0058 - mae: 0.0795 - val_loss: 0.0029 - val_mae: 0.0540\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0052 - mae: 0.0731 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0026 - val_mae: 0.0478\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0055 - val_mae: 0.0859\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0041 - mae: 0.0598 - val_loss: 0.0028 - val_mae: 0.0511\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0042 - val_mae: 0.0705\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0043 - mae: 0.0625 - val_loss: 0.0077 - val_mae: 0.1095\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0039 - mae: 0.0582 - val_loss: 0.0021 - val_mae: 0.0385\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0030 - val_mae: 0.0529\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0035 - mae: 0.0540 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0035 - mae: 0.0536 - val_loss: 0.0026 - val_mae: 0.0472\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0034 - mae: 0.0525 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0023 - val_mae: 0.0408\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0503 - val_loss: 0.0025 - val_mae: 0.0461\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0026 - val_mae: 0.0460\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0034 - mae: 0.0551 - val_loss: 0.0032 - val_mae: 0.0590\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0036 - mae: 0.0570 - val_loss: 0.0023 - val_mae: 0.0408\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0031 - mae: 0.0505 - val_loss: 0.0026 - val_mae: 0.0454\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0031 - mae: 0.0499 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0507 - val_loss: 0.0028 - val_mae: 0.0507\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0524 - val_loss: 0.0048 - val_mae: 0.0799\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0511 - val_loss: 0.0032 - val_mae: 0.0588\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0025 - val_mae: 0.0453\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0476 - val_loss: 0.0022 - val_mae: 0.0402\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0467 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0451 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0030 - mae: 0.0482 - val_loss: 0.0020 - val_mae: 0.0376\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0031 - mae: 0.0502 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0465 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0488 - val_loss: 0.0020 - val_mae: 0.0381\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0467 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0029 - mae: 0.0475 - val_loss: 0.0020 - val_mae: 0.0379\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0457 - val_loss: 0.0026 - val_mae: 0.0479\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0032 - mae: 0.0533 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0022 - val_mae: 0.0418\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0030 - mae: 0.0501 - val_loss: 0.0025 - val_mae: 0.0472\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0475 - val_loss: 0.0026 - val_mae: 0.0471\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0461 - val_loss: 0.0024 - val_mae: 0.0445\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0470 - val_loss: 0.0029 - val_mae: 0.0584\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0472 - val_loss: 0.0026 - val_mae: 0.0480\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0026 - val_mae: 0.0475\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0021 - val_mae: 0.0391\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0019 - val_mae: 0.0366\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0020 - val_mae: 0.0382\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0467 - val_loss: 0.0025 - val_mae: 0.0471\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0477 - val_loss: 0.0020 - val_mae: 0.0385\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0031 - mae: 0.0527 - val_loss: 0.0029 - val_mae: 0.0528\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0477 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0022 - val_mae: 0.0406\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0023 - val_mae: 0.0439\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0020 - val_mae: 0.0371\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0025 - val_mae: 0.0453\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0025 - val_mae: 0.0452\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0029 - mae: 0.0497 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0029 - mae: 0.0494 - val_loss: 0.0031 - val_mae: 0.0575\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0500 - val_loss: 0.0022 - val_mae: 0.0391\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0020 - val_mae: 0.0362\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.0028 - mae: 0.0470 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 2s 69ms/step - loss: 0.0028 - mae: 0.0483 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0447 - val_loss: 0.0030 - val_mae: 0.0552\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0444 - val_loss: 0.0031 - val_mae: 0.0567\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0030 - mae: 0.0499 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0028 - mae: 0.0473 - val_loss: 0.0031 - val_mae: 0.0591\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0475 - val_loss: 0.0027 - val_mae: 0.0501\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0028 - mae: 0.0485 - val_loss: 0.0030 - val_mae: 0.0552\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0027 - mae: 0.0486 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0025 - mae: 0.0433 - val_loss: 0.0020 - val_mae: 0.0364\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0026 - mae: 0.0474 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0414 - val_loss: 0.0023 - val_mae: 0.0413\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 2s 67ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0430 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0417 - val_loss: 0.0023 - val_mae: 0.0415\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0023 - val_mae: 0.0436\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0027 - mae: 0.0475 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0024 - mae: 0.0416 - val_loss: 0.0021 - val_mae: 0.0375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ae3a7819d20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    train_ds, \n",
    "    validation_data=valid_ds, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e4e1d3-477c-4743-a4bb-b501bca8ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04409952089190483, 0.2418685108423233]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_evals = model.evaluate(test_ds)\n",
    "deep_evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce46b19-1835-44f9-8f3e-40ee8ea89de6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a09c3cf4-8cfc-4998-b3b0-d2508c4c530d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq2seq_train, seq2seq_valid, seq2seq_test = handson.seq2seq_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c22beea-cf75-4ad0-85c5-e6c2542b376d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recurrent_activation': 'sigmoid',\n",
       " 'unit_forget_bias': True,\n",
       " 'implementation': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.LSTM arguments SimpleRNN layer does not have\n",
    "LSTM_args = keras.layers.LSTM(units=32).get_config()\n",
    "SimpleRNN_keys = keras.layers.SimpleRNN(units=32).get_config().keys()\n",
    "LSTM_args_only = {k: v for k, v in LSTM_args.items() if k not in SimpleRNN_keys}\n",
    "LSTM_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f8ab93-d2b3-465f-af2b-b6c60e03c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4125f0bd-30a3-48ed-b5c9-701433322295",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313015a6-e960-46d2-be99-1703f7aeb6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 8s 139ms/step - loss: 0.0968 - mae: 0.3719 - val_loss: 0.0252 - val_mae: 0.1903\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 0.0208 - mae: 0.1662 - val_loss: 0.0204 - val_mae: 0.1519\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0188 - mae: 0.1608 - val_loss: 0.0197 - val_mae: 0.1525\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.1607 - val_loss: 0.0194 - val_mae: 0.1514\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.1594 - val_loss: 0.0191 - val_mae: 0.1501\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.1581 - val_loss: 0.0188 - val_mae: 0.1494\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.1570 - val_loss: 0.0186 - val_mae: 0.1483\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.1566 - val_loss: 0.0183 - val_mae: 0.1474\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.1550 - val_loss: 0.0181 - val_mae: 0.1461\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.1538 - val_loss: 0.0180 - val_mae: 0.1450\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.1530 - val_loss: 0.0177 - val_mae: 0.1446\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.1523 - val_loss: 0.0175 - val_mae: 0.1436\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.1511 - val_loss: 0.0173 - val_mae: 0.1427\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.1500 - val_loss: 0.0171 - val_mae: 0.1419\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.1490 - val_loss: 0.0169 - val_mae: 0.1410\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.1483 - val_loss: 0.0168 - val_mae: 0.1401\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.1472 - val_loss: 0.0166 - val_mae: 0.1392\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.1464 - val_loss: 0.0164 - val_mae: 0.1385\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.1455 - val_loss: 0.0163 - val_mae: 0.1378\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.1445 - val_loss: 0.0161 - val_mae: 0.1370\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.1441 - val_loss: 0.0160 - val_mae: 0.1363\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.1430 - val_loss: 0.0158 - val_mae: 0.1357\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.1423 - val_loss: 0.0157 - val_mae: 0.1349\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.1414 - val_loss: 0.0155 - val_mae: 0.1342\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.1404 - val_loss: 0.0154 - val_mae: 0.1333\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0140 - mae: 0.1399 - val_loss: 0.0153 - val_mae: 0.1329\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.1389 - val_loss: 0.0151 - val_mae: 0.1323\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.1384 - val_loss: 0.0150 - val_mae: 0.1316\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.1377 - val_loss: 0.0149 - val_mae: 0.1309\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.1366 - val_loss: 0.0148 - val_mae: 0.1303\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.1359 - val_loss: 0.0147 - val_mae: 0.1296\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.1351 - val_loss: 0.0145 - val_mae: 0.1292\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.1347 - val_loss: 0.0144 - val_mae: 0.1285\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.1343 - val_loss: 0.0143 - val_mae: 0.1279\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.1334 - val_loss: 0.0142 - val_mae: 0.1274\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.1323 - val_loss: 0.0141 - val_mae: 0.1269\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.1319 - val_loss: 0.0140 - val_mae: 0.1263\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.1314 - val_loss: 0.0139 - val_mae: 0.1256\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.1303 - val_loss: 0.0138 - val_mae: 0.1252\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.1297 - val_loss: 0.0137 - val_mae: 0.1248\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.1291 - val_loss: 0.0136 - val_mae: 0.1242\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.1285 - val_loss: 0.0135 - val_mae: 0.1237\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.1278 - val_loss: 0.0134 - val_mae: 0.1232\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.1274 - val_loss: 0.0133 - val_mae: 0.1229\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.1272 - val_loss: 0.0132 - val_mae: 0.1224\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.1263 - val_loss: 0.0131 - val_mae: 0.1220\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.1254 - val_loss: 0.0130 - val_mae: 0.1216\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.1253 - val_loss: 0.0130 - val_mae: 0.1211\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.1244 - val_loss: 0.0129 - val_mae: 0.1208\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.1240 - val_loss: 0.0128 - val_mae: 0.1204\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.1235 - val_loss: 0.0127 - val_mae: 0.1200\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.1231 - val_loss: 0.0126 - val_mae: 0.1196\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.1223 - val_loss: 0.0125 - val_mae: 0.1192\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.1220 - val_loss: 0.0125 - val_mae: 0.1189\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.1212 - val_loss: 0.0124 - val_mae: 0.1185\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.1211 - val_loss: 0.0123 - val_mae: 0.1181\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.1207 - val_loss: 0.0122 - val_mae: 0.1178\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.1199 - val_loss: 0.0122 - val_mae: 0.1176\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.1196 - val_loss: 0.0121 - val_mae: 0.1172\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.1191 - val_loss: 0.0120 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1187 - val_loss: 0.0120 - val_mae: 0.1166\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1181 - val_loss: 0.0119 - val_mae: 0.1164\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.1180 - val_loss: 0.0118 - val_mae: 0.1160\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.1172 - val_loss: 0.0118 - val_mae: 0.1157\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.1170 - val_loss: 0.0117 - val_mae: 0.1154\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1165 - val_loss: 0.0116 - val_mae: 0.1152\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1163 - val_loss: 0.0116 - val_mae: 0.1149\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1159 - val_loss: 0.0115 - val_mae: 0.1146\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1156 - val_loss: 0.0115 - val_mae: 0.1143\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1151 - val_loss: 0.0114 - val_mae: 0.1141\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1147 - val_loss: 0.0114 - val_mae: 0.1138\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.1143 - val_loss: 0.0113 - val_mae: 0.1136\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.1139 - val_loss: 0.0113 - val_mae: 0.1133\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.1134 - val_loss: 0.0112 - val_mae: 0.1131\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.1133 - val_loss: 0.0112 - val_mae: 0.1128\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.1128 - val_loss: 0.0111 - val_mae: 0.1126\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.1125 - val_loss: 0.0110 - val_mae: 0.1124\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.1121 - val_loss: 0.0110 - val_mae: 0.1121\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.1121 - val_loss: 0.0109 - val_mae: 0.1118\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.1117 - val_loss: 0.0109 - val_mae: 0.1116\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.1113 - val_loss: 0.0109 - val_mae: 0.1114\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.1107 - val_loss: 0.0108 - val_mae: 0.1112\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.1108 - val_loss: 0.0108 - val_mae: 0.1109\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.1103 - val_loss: 0.0107 - val_mae: 0.1107\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.1099 - val_loss: 0.0107 - val_mae: 0.1105\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.1098 - val_loss: 0.0106 - val_mae: 0.1103\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0106 - val_mae: 0.1101\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.1091 - val_loss: 0.0105 - val_mae: 0.1099\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.1087 - val_loss: 0.0105 - val_mae: 0.1097\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.1086 - val_loss: 0.0105 - val_mae: 0.1094\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.1082 - val_loss: 0.0104 - val_mae: 0.1092\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.1078 - val_loss: 0.0104 - val_mae: 0.1091\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.1076 - val_loss: 0.0103 - val_mae: 0.1088\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.1074 - val_loss: 0.0103 - val_mae: 0.1086\n",
      "Epoch 95/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.1071 - val_loss: 0.0102 - val_mae: 0.1084\n",
      "Epoch 96/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.1067 - val_loss: 0.0102 - val_mae: 0.1083\n",
      "Epoch 97/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.1066 - val_loss: 0.0102 - val_mae: 0.1080\n",
      "Epoch 98/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.1063 - val_loss: 0.0102 - val_mae: 0.1079\n",
      "Epoch 99/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1061 - val_loss: 0.0101 - val_mae: 0.1077\n",
      "Epoch 100/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1058 - val_loss: 0.0100 - val_mae: 0.1075\n",
      "Epoch 101/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1057 - val_loss: 0.0100 - val_mae: 0.1073\n",
      "Epoch 102/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1054 - val_loss: 0.0100 - val_mae: 0.1071\n",
      "Epoch 103/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.1051 - val_loss: 0.0100 - val_mae: 0.1070\n",
      "Epoch 104/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.1048 - val_loss: 0.0099 - val_mae: 0.1068\n",
      "Epoch 105/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.1046 - val_loss: 0.0099 - val_mae: 0.1067\n",
      "Epoch 106/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.1044 - val_loss: 0.0098 - val_mae: 0.1065\n",
      "Epoch 107/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.1042 - val_loss: 0.0098 - val_mae: 0.1063\n",
      "Epoch 108/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0098 - val_mae: 0.1061\n",
      "Epoch 109/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0098 - val_mae: 0.1060\n",
      "Epoch 110/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0098 - val_mae: 0.1059\n",
      "Epoch 111/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.1032 - val_loss: 0.0097 - val_mae: 0.1057\n",
      "Epoch 112/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0097 - val_mae: 0.1055\n",
      "Epoch 113/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.1030 - val_loss: 0.0096 - val_mae: 0.1053\n",
      "Epoch 114/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.1027 - val_loss: 0.0096 - val_mae: 0.1053\n",
      "Epoch 115/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0096 - val_mae: 0.1051\n",
      "Epoch 116/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.1023 - val_loss: 0.0096 - val_mae: 0.1049\n",
      "Epoch 117/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.1021 - val_loss: 0.0095 - val_mae: 0.1048\n",
      "Epoch 118/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.1019 - val_loss: 0.0095 - val_mae: 0.1046\n",
      "Epoch 119/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0095 - val_mae: 0.1045\n",
      "Epoch 120/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.1016 - val_loss: 0.0094 - val_mae: 0.1042\n",
      "Epoch 121/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.1014 - val_loss: 0.0094 - val_mae: 0.1041\n",
      "Epoch 122/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.1011 - val_loss: 0.0094 - val_mae: 0.1041\n",
      "Epoch 123/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0094 - val_mae: 0.1039\n",
      "Epoch 124/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0093 - val_mae: 0.1037\n",
      "Epoch 125/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0093 - val_mae: 0.1035\n",
      "Epoch 126/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0093 - val_mae: 0.1034\n",
      "Epoch 127/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.1002 - val_loss: 0.0093 - val_mae: 0.1034\n",
      "Epoch 128/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.1001 - val_loss: 0.0092 - val_mae: 0.1031\n",
      "Epoch 129/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0999 - val_loss: 0.0092 - val_mae: 0.1030\n",
      "Epoch 130/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0997 - val_loss: 0.0092 - val_mae: 0.1027\n",
      "Epoch 131/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0996 - val_loss: 0.0092 - val_mae: 0.1027\n",
      "Epoch 132/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0993 - val_loss: 0.0092 - val_mae: 0.1026\n",
      "Epoch 133/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0992 - val_loss: 0.0091 - val_mae: 0.1025\n",
      "Epoch 134/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0990 - val_loss: 0.0091 - val_mae: 0.1023\n",
      "Epoch 135/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0990 - val_loss: 0.0091 - val_mae: 0.1020\n",
      "Epoch 136/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0987 - val_loss: 0.0091 - val_mae: 0.1021\n",
      "Epoch 137/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0986 - val_loss: 0.0090 - val_mae: 0.1019\n",
      "Epoch 138/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0984 - val_loss: 0.0090 - val_mae: 0.1018\n",
      "Epoch 139/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0982 - val_loss: 0.0090 - val_mae: 0.1014\n",
      "Epoch 140/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0982 - val_loss: 0.0090 - val_mae: 0.1014\n",
      "Epoch 141/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0979 - val_loss: 0.0089 - val_mae: 0.1012\n",
      "Epoch 142/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0978 - val_loss: 0.0089 - val_mae: 0.1012\n",
      "Epoch 143/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0976 - val_loss: 0.0089 - val_mae: 0.1010\n",
      "Epoch 144/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0975 - val_loss: 0.0089 - val_mae: 0.1008\n",
      "Epoch 145/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0973 - val_loss: 0.0088 - val_mae: 0.1006\n",
      "Epoch 146/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0971 - val_loss: 0.0088 - val_mae: 0.1006\n",
      "Epoch 147/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0970 - val_loss: 0.0088 - val_mae: 0.1003\n",
      "Epoch 148/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0968 - val_loss: 0.0088 - val_mae: 0.1004\n",
      "Epoch 149/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0966 - val_loss: 0.0088 - val_mae: 0.1002\n",
      "Epoch 150/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0965 - val_loss: 0.0088 - val_mae: 0.1000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    seq2seq_train, \n",
    "    validation_data=seq2seq_valid, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab959ce-646a-4ed2-a73e-5c3690b8a1ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.2746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.049832530319690704, 0.2745789587497711]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(seq2seq_test)\n",
    "evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266207b-4772-445d-bc67-c117a1e00684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44a29647-9ea9-4300-b382-ffd018c0f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recurrent_activation': 'sigmoid', 'implementation': 2, 'reset_after': True}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default keras.layers.GRU arguments SimpleRNN layer does not have\n",
    "GRU_args = keras.layers.GRU(units=32).get_config()\n",
    "SimpleRNN_keys = keras.layers.SimpleRNN(units=32).get_config().keys()\n",
    "GRU_args_only = {k: v for k, v in GRU_args.items() if k not in SimpleRNN_keys}\n",
    "GRU_args_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "472de145-9484-4514-8f1d-dd4792583de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq2seq_train, seq2seq_valid, seq2seq_test = handson.seq2seq_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23862eac-5b84-47fc-944a-23118068c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 5]),\n",
    "tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9b5535c-ec9e-4e7c-918a-cf9d1b5e0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mae\",\n",
    "    patience=50, \n",
    "    restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "895677ad-0708-457c-bfc0-653719a74f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 4s 60ms/step - loss: 0.1129 - mae: 0.3910 - val_loss: 0.0255 - val_mae: 0.1743\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0203 - mae: 0.1599 - val_loss: 0.0203 - val_mae: 0.1552\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.1573 - val_loss: 0.0190 - val_mae: 0.1512\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.1530 - val_loss: 0.0182 - val_mae: 0.1471\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.1495 - val_loss: 0.0175 - val_mae: 0.1439\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.1463 - val_loss: 0.0168 - val_mae: 0.1413\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.1436 - val_loss: 0.0163 - val_mae: 0.1387\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.1417 - val_loss: 0.0158 - val_mae: 0.1365\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.1388 - val_loss: 0.0154 - val_mae: 0.1343\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.1367 - val_loss: 0.0150 - val_mae: 0.1324\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.1349 - val_loss: 0.0146 - val_mae: 0.1311\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.1333 - val_loss: 0.0143 - val_mae: 0.1294\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.1315 - val_loss: 0.0141 - val_mae: 0.1281\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.1300 - val_loss: 0.0138 - val_mae: 0.1269\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.1286 - val_loss: 0.0136 - val_mae: 0.1257\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.1275 - val_loss: 0.0134 - val_mae: 0.1247\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.1262 - val_loss: 0.0132 - val_mae: 0.1238\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.1252 - val_loss: 0.0130 - val_mae: 0.1230\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.1242 - val_loss: 0.0128 - val_mae: 0.1223\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.1232 - val_loss: 0.0127 - val_mae: 0.1216\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.1226 - val_loss: 0.0125 - val_mae: 0.1209\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.1216 - val_loss: 0.0124 - val_mae: 0.1204\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.1209 - val_loss: 0.0122 - val_mae: 0.1197\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.1201 - val_loss: 0.0121 - val_mae: 0.1191\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.1192 - val_loss: 0.0120 - val_mae: 0.1184\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.1186 - val_loss: 0.0119 - val_mae: 0.1179\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.1179 - val_loss: 0.0117 - val_mae: 0.1174\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.1173 - val_loss: 0.0116 - val_mae: 0.1168\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.1167 - val_loss: 0.0115 - val_mae: 0.1162\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.1159 - val_loss: 0.0114 - val_mae: 0.1156\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.1153 - val_loss: 0.0113 - val_mae: 0.1151\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.1146 - val_loss: 0.0112 - val_mae: 0.1145\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.1141 - val_loss: 0.0111 - val_mae: 0.1140\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.1136 - val_loss: 0.0110 - val_mae: 0.1133\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.1129 - val_loss: 0.0109 - val_mae: 0.1128\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.1122 - val_loss: 0.0108 - val_mae: 0.1123\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.1117 - val_loss: 0.0108 - val_mae: 0.1117\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.1112 - val_loss: 0.0107 - val_mae: 0.1111\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0106 - val_mae: 0.1107\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.1099 - val_loss: 0.0105 - val_mae: 0.1102\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.1094 - val_loss: 0.0105 - val_mae: 0.1096\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.1088 - val_loss: 0.0104 - val_mae: 0.1091\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0103 - val_mae: 0.1086\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.1078 - val_loss: 0.0102 - val_mae: 0.1081\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.1075 - val_loss: 0.0102 - val_mae: 0.1075\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.1068 - val_loss: 0.0101 - val_mae: 0.1071\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0100 - val_mae: 0.1066\n",
      "Epoch 48/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.1059 - val_loss: 0.0100 - val_mae: 0.1061\n",
      "Epoch 49/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0099 - val_mae: 0.1057\n",
      "Epoch 50/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0098 - val_mae: 0.1052\n",
      "Epoch 51/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0098 - val_mae: 0.1048\n",
      "Epoch 52/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0097 - val_mae: 0.1042\n",
      "Epoch 53/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0097 - val_mae: 0.1039\n",
      "Epoch 54/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0096 - val_mae: 0.1035\n",
      "Epoch 55/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0096 - val_mae: 0.1031\n",
      "Epoch 56/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0095 - val_mae: 0.1026\n",
      "Epoch 57/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0095 - val_mae: 0.1022\n",
      "Epoch 58/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0094 - val_mae: 0.1018\n",
      "Epoch 59/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0094 - val_mae: 0.1015\n",
      "Epoch 60/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0094 - val_mae: 0.1011\n",
      "Epoch 61/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.1005 - val_loss: 0.0093 - val_mae: 0.1007\n",
      "Epoch 62/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0092 - val_mae: 0.1004\n",
      "Epoch 63/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0092 - val_mae: 0.1000\n",
      "Epoch 64/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0092 - val_mae: 0.0998\n",
      "Epoch 65/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0091 - val_mae: 0.0994\n",
      "Epoch 66/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0091 - val_mae: 0.0990\n",
      "Epoch 67/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0986 - val_loss: 0.0091 - val_mae: 0.0987\n",
      "Epoch 68/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0090 - val_mae: 0.0984\n",
      "Epoch 69/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0090 - val_mae: 0.0981\n",
      "Epoch 70/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0977 - val_loss: 0.0090 - val_mae: 0.0978\n",
      "Epoch 71/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0974 - val_loss: 0.0089 - val_mae: 0.0976\n",
      "Epoch 72/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0971 - val_loss: 0.0089 - val_mae: 0.0974\n",
      "Epoch 73/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0089 - val_mae: 0.0971\n",
      "Epoch 74/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0088 - val_mae: 0.0967\n",
      "Epoch 75/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0964 - val_loss: 0.0088 - val_mae: 0.0966\n",
      "Epoch 76/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0088 - val_mae: 0.0963\n",
      "Epoch 77/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0087 - val_mae: 0.0960\n",
      "Epoch 78/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0087 - val_mae: 0.0958\n",
      "Epoch 79/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0087 - val_mae: 0.0955\n",
      "Epoch 80/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0086 - val_mae: 0.0953\n",
      "Epoch 81/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0086 - val_mae: 0.0951\n",
      "Epoch 82/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0086 - val_mae: 0.0949\n",
      "Epoch 83/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0947 - val_loss: 0.0086 - val_mae: 0.0947\n",
      "Epoch 84/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0085 - val_mae: 0.0944\n",
      "Epoch 85/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0085 - val_mae: 0.0943\n",
      "Epoch 86/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0085 - val_mae: 0.0941\n",
      "Epoch 87/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0085 - val_mae: 0.0939\n",
      "Epoch 88/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0935 - val_loss: 0.0084 - val_mae: 0.0936\n",
      "Epoch 89/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0933 - val_loss: 0.0084 - val_mae: 0.0934\n",
      "Epoch 90/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0084 - val_mae: 0.0932\n",
      "Epoch 91/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0084 - val_mae: 0.0931\n",
      "Epoch 92/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0083 - val_mae: 0.0929\n",
      "Epoch 93/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0083 - val_mae: 0.0927\n",
      "Epoch 94/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0924 - val_loss: 0.0083 - val_mae: 0.0924\n",
      "Epoch 95/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0082 - val_mae: 0.0923\n",
      "Epoch 96/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0082 - val_mae: 0.0923\n",
      "Epoch 97/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0082 - val_mae: 0.0919\n",
      "Epoch 98/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0916 - val_loss: 0.0082 - val_mae: 0.0918\n",
      "Epoch 99/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0915 - val_loss: 0.0082 - val_mae: 0.0916\n",
      "Epoch 100/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0913 - val_loss: 0.0081 - val_mae: 0.0913\n",
      "Epoch 101/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0081 - val_mae: 0.0913\n",
      "Epoch 102/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0910 - val_loss: 0.0081 - val_mae: 0.0910\n",
      "Epoch 103/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0081 - val_mae: 0.0910\n",
      "Epoch 104/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0906 - val_loss: 0.0080 - val_mae: 0.0908\n",
      "Epoch 105/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0080 - val_mae: 0.0907\n",
      "Epoch 106/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0080 - val_mae: 0.0905\n",
      "Epoch 107/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0901 - val_loss: 0.0080 - val_mae: 0.0904\n",
      "Epoch 108/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0080 - val_mae: 0.0901\n",
      "Epoch 109/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0898 - val_loss: 0.0079 - val_mae: 0.0901\n",
      "Epoch 110/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0896 - val_loss: 0.0079 - val_mae: 0.0900\n",
      "Epoch 111/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0894 - val_loss: 0.0079 - val_mae: 0.0898\n",
      "Epoch 112/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0893 - val_loss: 0.0079 - val_mae: 0.0895\n",
      "Epoch 113/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0892 - val_loss: 0.0079 - val_mae: 0.0894\n",
      "Epoch 114/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0890 - val_loss: 0.0079 - val_mae: 0.0894\n",
      "Epoch 115/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0888 - val_loss: 0.0078 - val_mae: 0.0891\n",
      "Epoch 116/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0887 - val_loss: 0.0078 - val_mae: 0.0890\n",
      "Epoch 117/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0078 - val_mae: 0.0889\n",
      "Epoch 118/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0884 - val_loss: 0.0078 - val_mae: 0.0887\n",
      "Epoch 119/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0882 - val_loss: 0.0078 - val_mae: 0.0887\n",
      "Epoch 120/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0077 - val_mae: 0.0884\n",
      "Epoch 121/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0077 - val_mae: 0.0883\n",
      "Epoch 122/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0877 - val_loss: 0.0077 - val_mae: 0.0883\n",
      "Epoch 123/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0877 - val_loss: 0.0077 - val_mae: 0.0881\n",
      "Epoch 124/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0874 - val_loss: 0.0076 - val_mae: 0.0879\n",
      "Epoch 125/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0874 - val_loss: 0.0076 - val_mae: 0.0877\n",
      "Epoch 126/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0076 - val_mae: 0.0877\n",
      "Epoch 127/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0870 - val_loss: 0.0076 - val_mae: 0.0877\n",
      "Epoch 128/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0869 - val_loss: 0.0076 - val_mae: 0.0874\n",
      "Epoch 129/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0076 - val_mae: 0.0873\n",
      "Epoch 130/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0866 - val_loss: 0.0075 - val_mae: 0.0871\n",
      "Epoch 131/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0866 - val_loss: 0.0075 - val_mae: 0.0870\n",
      "Epoch 132/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0075 - val_mae: 0.0870\n",
      "Epoch 133/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0075 - val_mae: 0.0869\n",
      "Epoch 134/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0860 - val_loss: 0.0075 - val_mae: 0.0867\n",
      "Epoch 135/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0860 - val_loss: 0.0074 - val_mae: 0.0864\n",
      "Epoch 136/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0857 - val_loss: 0.0075 - val_mae: 0.0865\n",
      "Epoch 137/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0856 - val_loss: 0.0074 - val_mae: 0.0864\n",
      "Epoch 138/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0854 - val_loss: 0.0074 - val_mae: 0.0863\n",
      "Epoch 139/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0853 - val_loss: 0.0074 - val_mae: 0.0859\n",
      "Epoch 140/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0853 - val_loss: 0.0074 - val_mae: 0.0859\n",
      "Epoch 141/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0851 - val_loss: 0.0073 - val_mae: 0.0857\n",
      "Epoch 142/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0073 - val_mae: 0.0857\n",
      "Epoch 143/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0848 - val_loss: 0.0073 - val_mae: 0.0855\n",
      "Epoch 144/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0073 - val_mae: 0.0854\n",
      "Epoch 145/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0846 - val_loss: 0.0073 - val_mae: 0.0853\n",
      "Epoch 146/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0844 - val_loss: 0.0073 - val_mae: 0.0853\n",
      "Epoch 147/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0072 - val_mae: 0.0850\n",
      "Epoch 148/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0841 - val_loss: 0.0072 - val_mae: 0.0851\n",
      "Epoch 149/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0839 - val_loss: 0.0072 - val_mae: 0.0849\n",
      "Epoch 150/150\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0838 - val_loss: 0.0072 - val_mae: 0.0848\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    seq2seq_train, \n",
    "    validation_data=seq2seq_valid, \n",
    "    epochs=150,\n",
    "    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a8dd90-ea05-4f56-926b-93b48abfbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0451 - mae: 0.2583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04511779546737671, 0.2582501173019409]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = model.evaluate(seq2seq_test)\n",
    "evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bacfb8-a471-4f14-b118-75ae53255c13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ModelCheckpoint, Logging, and Early Stopping on accuracy difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14829b5c-3e7f-4fe4-906f-8b74e9b311f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = handson.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "025a867b-dfbc-40a1-92af-aef6d026a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb432ee9-0c8f-46c2-85f7-0e6aa1f06fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function for CSV log file\n",
    "\n",
    "hours = 14 # hours to delay timestamp for log info (remote system might have different time)\n",
    "timestamp = (datetime.datetime.now() + datetime.timedelta(hours=hours))\n",
    "timestamp = timestamp.strftime('%Y-%m-%d~%I:%M:%S%p')\n",
    "\n",
    "# create log file directory path and file name\n",
    "log_dir = Path('./models.CSV.log')\n",
    "log_dir.mkdir()\n",
    "file_name = 'LOG.'+timestamp+'.csv'\n",
    "\n",
    "# save log file of training output\n",
    "csv_logger = keras.callbacks.CSVLogger(log_dir / file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bc13183-f1e1-4445-9dfa-32970b219e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model whenever there is an improvement in accuracy over the previous best accuracy\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./cifar_10_model.hdf5',\n",
    "    monitor=\"val_accuracy\", # it could be any other monitoring metrics. Make sure put val_\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, # it should be false. See below comments\n",
    "    verbose=1 # 0, 1, or 2. It just specifies how much information is output during training\n",
    ")\n",
    "\n",
    "# save_weights_only=False saves the entire architecture of the neural network, including \n",
    "# the model's layers, their configuration, the optimizer used during training, and the weights \n",
    "# learned during training. save_weights_only=True saves only the learned weights of the model, \n",
    "# without any information about the model's architecture or the optimizer used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44c4e07f-cf25-4931-924f-84488162d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stops training when training accuracy is greater than validation accuracy by 0.1\n",
    "class StopOnAccuracyDiff(keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        super(StopOnAccuracyDiff, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        train_acc = logs.get('accuracy')\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if train_acc is not None and val_acc is not None:\n",
    "            acc_diff = abs(train_acc - val_acc)\n",
    "            if acc_diff > self.threshold:\n",
    "                print(f'Training stopped because of accuracy difference ({acc_diff:.3f})')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "early_stopping_cb = StopOnAccuracyDiff(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "588057ec-b8e7-42c8-baf0-09be5c6d755f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.8264 - accuracy: 0.7154\n",
      "Epoch 1: val_accuracy improved from 0.66560 to 0.67220, saving model to ./cifar_10_model.hdf5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8262 - accuracy: 0.7155 - val_loss: 0.9706 - val_accuracy: 0.6722\n",
      "Epoch 2/150\n",
      "1545/1563 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.7594\n",
      "Epoch 2: val_accuracy improved from 0.67220 to 0.69120, saving model to ./cifar_10_model.hdf5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6913 - accuracy: 0.7594 - val_loss: 1.0048 - val_accuracy: 0.6912\n",
      "Epoch 3/150\n",
      "1545/1563 [============================>.] - ETA: 0s - loss: 0.5620 - accuracy: 0.8043\n",
      "Epoch 3: val_accuracy did not improve from 0.69120\n",
      "Training stopped because of accuracy difference (0.119)\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.5622 - accuracy: 0.8043 - val_loss: 1.0752 - val_accuracy: 0.6856\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=150,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        checkpoint_callback, \n",
    "        csv_logger,\n",
    "        early_stopping_cb] # called after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9d4c75c-f51c-4337-919a-332900b95f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0246 - accuracy: 0.6784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0245752334594727, 0.6783999800682068]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('cifar_10_model.hdf5')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "acc_test = loaded_model.evaluate(X_test, y_test)\n",
    "acc_test # not as impressive as training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3a779-a58d-43b4-bbd0-be7b9d14b138",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaba1b3-dd88-4817-a146-99b334076a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc663c30-54d8-45c4-a590-019ce9555c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = mods.cifar_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4bb57b-49c7-4d29-9f23-eb4bd11862c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.profiler.experimental.start(logdir='profiler.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067b2774-ebd8-451b-9abe-17d3be4746d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model that will yield 10 CNN features at the last layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, input_shape=[32, 32, 3]),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=4, activation='selu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # changes the shape from (None, 1, 1, 64) to 64\n",
    "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=10, activation=\"softmax\") \n",
    "])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(clipvalue=0.5, learning_rate=0.001)\n",
    "\n",
    "# categorical_crossentropy if the output is one-hot encoding\n",
    "# sparse_categorical_crossentropy if the output is integer\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf86ff7-5250-4a25-aa3a-82ae417da715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories in which to save logs\n",
    "\n",
    "hours = 14 # hours to delay timestamp for log info (remote system might have different time)\n",
    "timestamp = (datetime.datetime.now() + datetime.timedelta(hours=hours))\n",
    "timestamp = timestamp.strftime('%Y-%m-%d~%I:%M:%S%p')\n",
    "\n",
    "# create directory\n",
    "parent_dir = Path('./models.tensorboard.log')\n",
    "sub_dir = parent_dir / timestamp\n",
    "sub_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2fa530b-436f-4d0c-96ec-ae13fead93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=str(sub_dir), histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19dbcc0-0cde-44d8-8777-15a7bb63fb18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 10s 4ms/step - loss: 1.3406 - accuracy: 0.5282 - val_loss: 1.0838 - val_accuracy: 0.6254\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9814 - accuracy: 0.6610 - val_loss: 0.9691 - val_accuracy: 0.6696\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8255 - accuracy: 0.7139 - val_loss: 0.9792 - val_accuracy: 0.6788\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6770 - accuracy: 0.7655 - val_loss: 1.0280 - val_accuracy: 0.6768\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5449 - accuracy: 0.8111 - val_loss: 1.0733 - val_accuracy: 0.6808\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4255 - accuracy: 0.8516 - val_loss: 1.2229 - val_accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3386 - accuracy: 0.8818 - val_loss: 1.3908 - val_accuracy: 0.6758\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2749 - accuracy: 0.9030 - val_loss: 1.5739 - val_accuracy: 0.6772\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9197 - val_loss: 1.8920 - val_accuracy: 0.6612\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1982 - accuracy: 0.9326 - val_loss: 1.9243 - val_accuracy: 0.6660\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1799 - accuracy: 0.9398 - val_loss: 2.1036 - val_accuracy: 0.6676\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1615 - accuracy: 0.9467 - val_loss: 2.3060 - val_accuracy: 0.6624\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1681 - accuracy: 0.9456 - val_loss: 2.4544 - val_accuracy: 0.6656\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1541 - accuracy: 0.9508 - val_loss: 2.4042 - val_accuracy: 0.6586\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9535 - val_loss: 2.7331 - val_accuracy: 0.6572\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_cb, tensorboard_callback] # called after every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11007f6f-9913-4dc2-8119-fde5a617c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f161d985-11e7-4c4f-bfc2-af7436c13f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc130d-2f28-4f57-b320-92d00310a7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a10b24-fb45-4e12-b99b-a5baa40fffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41985182-48b2-4188-8ec3-f70922c256a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20cc54f3-4f5f-43d0-8b54-d58047800fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator and its implementation in tf.data.Dataset\n",
    "def data_generator(size, std):\n",
    "    t = np.linspace(-2*np.pi, 2*np.pi, size)\n",
    "    \n",
    "    while True:\n",
    "        A, B, C = np.random.uniform(0.5, 2*np.pi, size=3)\n",
    "        y = A*np.sin(B*t + C)\n",
    "        x = y + np.random.normal(0, std, size)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "975b6aeb-e112-4dd1-91e5-dc3a91e817d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=254>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data generator arguments as tf.Tensors that are fed into tf.data.Dataset.from_generator\n",
    "size = 254\n",
    "batch_size = 32\n",
    "std = 0.5\n",
    "args = [size, std]\n",
    "args = tuple(tf.constant(x) for x in args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32d23d5e-c949-4836-955f-6f0caacdb5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset from generator\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    args=args,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(size,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(size,), dtype=tf.float32)))\n",
    "\n",
    "dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    args=args,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(size,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(size,), dtype=tf.float32)))\n",
    "\n",
    "validation_dataset = validation_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c11964-cd7a-40ce-9e1c-d4ee90c14dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(\n",
    "        64, \n",
    "        activation=\"selu\", \n",
    "        name='hidden_layer_1', \n",
    "        input_shape=(size, )),\n",
    "    keras.layers.Dense(64, activation=\"selu\", name='hidden_layer_2'),\n",
    "    keras.layers.Dense(size, name='output_layer', activation=\"linear\")],\n",
    "    name='sequential_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e11c5fa-4ab6-46ae-ae54-21b42eb29354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"mae\",\n",
    "    patience=30, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25ddd7f6-ae06-4e07-8fa5-c550ac55ef7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c4ab70-7b6d-4a98-be11-4954394cf6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "512/512 [==============================] - 3s 4ms/step - loss: 0.7930 - mae: 1.1683 - val_loss: 0.2067 - val_mae: 0.5079\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.1520 - mae: 0.4302 - val_loss: 0.1163 - val_mae: 0.3771\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.1002 - mae: 0.3502 - val_loss: 0.0893 - val_mae: 0.3302\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0837 - mae: 0.3194 - val_loss: 0.0773 - val_mae: 0.3073\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0741 - mae: 0.3003 - val_loss: 0.0707 - val_mae: 0.2930\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.0686 - mae: 0.2884 - val_loss: 0.0666 - val_mae: 0.2845\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.0639 - mae: 0.2781 - val_loss: 0.0646 - val_mae: 0.2784\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0606 - mae: 0.2703 - val_loss: 0.0605 - val_mae: 0.2690\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0576 - mae: 0.2633 - val_loss: 0.0567 - val_mae: 0.2612\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0551 - mae: 0.2575 - val_loss: 0.0529 - val_mae: 0.2516\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0535 - mae: 0.2533 - val_loss: 0.0521 - val_mae: 0.2504\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0511 - mae: 0.2479 - val_loss: 0.0499 - val_mae: 0.2445\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0498 - mae: 0.2448 - val_loss: 0.0494 - val_mae: 0.2442\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0479 - mae: 0.2400 - val_loss: 0.0471 - val_mae: 0.2390\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0467 - mae: 0.2374 - val_loss: 0.0458 - val_mae: 0.2352\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0452 - mae: 0.2335 - val_loss: 0.0448 - val_mae: 0.2333\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0441 - mae: 0.2312 - val_loss: 0.0442 - val_mae: 0.2307\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0428 - mae: 0.2278 - val_loss: 0.0416 - val_mae: 0.2247\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0419 - mae: 0.2254 - val_loss: 0.0408 - val_mae: 0.2228\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0411 - mae: 0.2231 - val_loss: 0.0405 - val_mae: 0.2219\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0405 - mae: 0.2216 - val_loss: 0.0405 - val_mae: 0.2210\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0393 - mae: 0.2183 - val_loss: 0.0386 - val_mae: 0.2164\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0390 - mae: 0.2175 - val_loss: 0.0380 - val_mae: 0.2148\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0383 - mae: 0.2156 - val_loss: 0.0378 - val_mae: 0.2142\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0374 - mae: 0.2132 - val_loss: 0.0382 - val_mae: 0.2154\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0372 - mae: 0.2124 - val_loss: 0.0374 - val_mae: 0.2131\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0366 - mae: 0.2109 - val_loss: 0.0361 - val_mae: 0.2096\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0360 - mae: 0.2092 - val_loss: 0.0349 - val_mae: 0.2059\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0361 - mae: 0.2092 - val_loss: 0.0351 - val_mae: 0.2065\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0354 - mae: 0.2073 - val_loss: 0.0351 - val_mae: 0.2067\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0348 - mae: 0.2054 - val_loss: 0.0345 - val_mae: 0.2049\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0345 - mae: 0.2047 - val_loss: 0.0346 - val_mae: 0.2052\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0338 - mae: 0.2028 - val_loss: 0.0336 - val_mae: 0.2026\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0335 - mae: 0.2017 - val_loss: 0.0350 - val_mae: 0.2060\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0332 - mae: 0.2008 - val_loss: 0.0332 - val_mae: 0.2010\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0329 - mae: 0.2000 - val_loss: 0.0326 - val_mae: 0.1989\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0325 - mae: 0.1987 - val_loss: 0.0325 - val_mae: 0.1989\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0320 - mae: 0.1974 - val_loss: 0.0312 - val_mae: 0.1951\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0319 - mae: 0.1971 - val_loss: 0.0312 - val_mae: 0.1950\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0313 - mae: 0.1952 - val_loss: 0.0311 - val_mae: 0.1943\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0312 - mae: 0.1948 - val_loss: 0.0307 - val_mae: 0.1934\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0311 - mae: 0.1944 - val_loss: 0.0305 - val_mae: 0.1928\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0307 - mae: 0.1932 - val_loss: 0.0303 - val_mae: 0.1924\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0302 - mae: 0.1919 - val_loss: 0.0303 - val_mae: 0.1918\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0299 - mae: 0.1909 - val_loss: 0.0296 - val_mae: 0.1899\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0295 - mae: 0.1897 - val_loss: 0.0303 - val_mae: 0.1918\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0295 - mae: 0.1895 - val_loss: 0.0287 - val_mae: 0.1872\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0289 - mae: 0.1877 - val_loss: 0.0293 - val_mae: 0.1885\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0289 - mae: 0.1876 - val_loss: 0.0280 - val_mae: 0.1851\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0285 - mae: 0.1863 - val_loss: 0.0288 - val_mae: 0.1876\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0284 - mae: 0.1860 - val_loss: 0.0278 - val_mae: 0.1841\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0278 - mae: 0.1842 - val_loss: 0.0286 - val_mae: 0.1867\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0280 - mae: 0.1848 - val_loss: 0.0278 - val_mae: 0.1840\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0275 - mae: 0.1832 - val_loss: 0.0265 - val_mae: 0.1801\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0274 - mae: 0.1826 - val_loss: 0.0275 - val_mae: 0.1833\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0271 - mae: 0.1821 - val_loss: 0.0273 - val_mae: 0.1823\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0268 - mae: 0.1809 - val_loss: 0.0269 - val_mae: 0.1817\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0267 - mae: 0.1807 - val_loss: 0.0265 - val_mae: 0.1800\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0265 - mae: 0.1801 - val_loss: 0.0258 - val_mae: 0.1778\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0264 - mae: 0.1796 - val_loss: 0.0261 - val_mae: 0.1783\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0262 - mae: 0.1788 - val_loss: 0.0266 - val_mae: 0.1801\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0258 - mae: 0.1776 - val_loss: 0.0259 - val_mae: 0.1781\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0257 - mae: 0.1774 - val_loss: 0.0253 - val_mae: 0.1759\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0258 - mae: 0.1775 - val_loss: 0.0250 - val_mae: 0.1747\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0254 - mae: 0.1763 - val_loss: 0.0250 - val_mae: 0.1745\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0254 - mae: 0.1763 - val_loss: 0.0253 - val_mae: 0.1754\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0250 - mae: 0.1748 - val_loss: 0.0257 - val_mae: 0.1768\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0247 - mae: 0.1738 - val_loss: 0.0243 - val_mae: 0.1725\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0248 - mae: 0.1740 - val_loss: 0.0244 - val_mae: 0.1727\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0246 - mae: 0.1734 - val_loss: 0.0247 - val_mae: 0.1737\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0244 - mae: 0.1726 - val_loss: 0.0243 - val_mae: 0.1727\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0242 - mae: 0.1722 - val_loss: 0.0238 - val_mae: 0.1711\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0242 - mae: 0.1721 - val_loss: 0.0236 - val_mae: 0.1702\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0238 - mae: 0.1706 - val_loss: 0.0232 - val_mae: 0.1687\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0237 - mae: 0.1704 - val_loss: 0.0242 - val_mae: 0.1716\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0237 - mae: 0.1704 - val_loss: 0.0235 - val_mae: 0.1694\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0233 - mae: 0.1691 - val_loss: 0.0234 - val_mae: 0.1693\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0232 - mae: 0.1686 - val_loss: 0.0231 - val_mae: 0.1682\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0233 - mae: 0.1691 - val_loss: 0.0229 - val_mae: 0.1680\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0229 - mae: 0.1677 - val_loss: 0.0229 - val_mae: 0.1678\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0228 - mae: 0.1673 - val_loss: 0.0228 - val_mae: 0.1670\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0229 - mae: 0.1675 - val_loss: 0.0224 - val_mae: 0.1658\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0225 - mae: 0.1663 - val_loss: 0.0225 - val_mae: 0.1662\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0225 - mae: 0.1661 - val_loss: 0.0225 - val_mae: 0.1662\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0224 - mae: 0.1657 - val_loss: 0.0222 - val_mae: 0.1653\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0224 - mae: 0.1655 - val_loss: 0.0220 - val_mae: 0.1645\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0220 - mae: 0.1643 - val_loss: 0.0221 - val_mae: 0.1644\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0221 - mae: 0.1645 - val_loss: 0.0220 - val_mae: 0.1643\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0218 - mae: 0.1638 - val_loss: 0.0219 - val_mae: 0.1640\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0218 - mae: 0.1635 - val_loss: 0.0222 - val_mae: 0.1649\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0217 - mae: 0.1634 - val_loss: 0.0217 - val_mae: 0.1630\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0216 - mae: 0.1628 - val_loss: 0.0211 - val_mae: 0.1611\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0216 - mae: 0.1629 - val_loss: 0.0212 - val_mae: 0.1612\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0212 - mae: 0.1615 - val_loss: 0.0211 - val_mae: 0.1613\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0212 - mae: 0.1616 - val_loss: 0.0214 - val_mae: 0.1625\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0210 - mae: 0.1607 - val_loss: 0.0217 - val_mae: 0.1633\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0212 - mae: 0.1613 - val_loss: 0.0210 - val_mae: 0.1606\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0211 - mae: 0.1612 - val_loss: 0.0207 - val_mae: 0.1598\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0209 - mae: 0.1603 - val_loss: 0.0209 - val_mae: 0.1606\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.0209 - mae: 0.1606 - val_loss: 0.0206 - val_mae: 0.1595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1487f8130160>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset, \n",
    "    validation_data=validation_dataset, \n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    steps_per_epoch=512,\n",
    "    validation_steps=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cc3ea2d-df4f-4062-8ac7-65de29289453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyqUlEQVR4nO3dfZBU1Z3/8U/3EAfGMCPDFEZlYEaCUYtKgcNIFKKiFImVP3YNxcZaoApKKacyPiB/xLCkCnQtp7K4G0ZDiEjVmMTSWCmWjZvoRkZRA8iDoMY1P2UeYAdBQ2ZGp9nAjsz0/f2B3fY03T39dPuec+/7VUXJNA197D59zud+z7n3hhzHcQQAAOCBsNcNAAAAwUUQAQAAniGIAAAAzxBEAACAZwgiAADAMwQRAADgGYIIAADwDEEEAAB4ZozXDcgkGo3qxIkTGj9+vEKhkNfNAQAAWXAcR6dOndKll16qcDhzzcPoIHLixAnV1tZ63QwAAJCHY8eOafLkyRmfY3QQGT9+vKRz/yOVlZUetwYAAGQjEomotrY2Po9nYnQQiS3HVFZWEkQAALBMNtsq2KwKAAA8QxABAACeIYgAAADPEEQAAIBnCCIAAMAzrgeR48ePa+nSpZo4caIqKio0c+ZMHTx40O2XBQAAFnD19N1PPvlEc+fO1fz58/Xiiy9q0qRJ6urq0kUXXeTmywIAAEu4GkR+/OMfq7a2Vm1tbfHH6urq3HxJAABgEVeXZp5//nnNnj1bixcv1qRJkzRr1iw9+eSTaZ8/ODioSCQy4hcAAPAvV4NId3e3Nm/erOnTp+sPf/iDmpqadO+99+qXv/xlyue3tLSoqqoq/ov7zAAA4G8hx3Ect/7xCy64QLNnz9aePXvij9177706cOCA3njjjfOePzg4qMHBwfjPsWvVDwwMcIl3AAAsEYlEVFVVldX87eoekUsuuURXX331iMeuuuoqbdu2LeXzy8vLVV5e7maTAmloOKpNO7t04Gi/Guuq1Tx/msaUceY2AMB7rgaRuXPn6oMPPhjx2OHDhzV16lQ3XxZJNu3s0sb2w3Ik7e7slSTdt2C6t40CAEAu7xG5//77tXfvXj3yyCPq7OzUM888oy1btqi5udnNl0WSA0f7FVt/cz7/GQAAE7gaRBobG7V9+3Y9++yzmjFjhv75n/9ZGzdu1JIlS9x8WSRprKtW7EbMoc9/BgDABK5uVi1ULptdkB57RAAApWTMZlWYYUxZmD0hAAAjEUQAAEVHJRbZIogAAIqOs/WQLeIpAKDoOFsP2SKIAACKjrP1kC2WZgAARdc8f5okjdgjAqRCEAEAFB1n6yFbLM0AAADPUBEBUBScrgkgHwQRIOCyCRDZPIfTNQHkgyACBFw2ASKb53C6JtKhWoZMCCIBxuAAKbsAkc1zGuuqtbuzV444XRMjUS1DJgSRAGNwgJRdgEh8jiT19J9Wa3vHiPDK6ZpIh2oZMiGIBBiDA6TsAkTssW2HPlRP/2n19J/WxvbDkr4Ir5yuiXSoliETgkiAMThAGhkg0i3XxZ5z4Gi/evpPSzoXXrcd+pAlPYyKahkyIYj4XKZ9IAwOSDbacl1jXbV2ff64dG6J5vGXOxUOh9hrhLSoliETgojPZZpYGByQbLTluub50+LLMzHb3z6uY/2n2WsEIC8ctvgc+0CQi9FuVDamLKxF10we8RxJ9DEAeaMi4nPJZzsMRx0t3bqvoAtXwU7ZfLa5bFyNPSfqRPXYy53sNQKQF4KIT8Umnf1H+vSNyycqHJKijrS3u6/gC1fBTtl8ttks1yU/Z2g4qnAozF4jAHkhiPhU4qQTkrRqwRVFu3AV7JT82e4/0qfWdhVc/WKvERIlVt4apkyQQo4O/s+nVFiRFkHEp1IFilQXpfrJS4dHDBQNUy/ilF6fSj5dO+qI6heKLvEgKPEMq3R9jOVgEER8KtU1QlJdlKr1lY7439nd2at7b54er55QZveX5L0d+4/0Uf1C0SUeBCVK18dYDgZBxKdSbTpMdVGqRI6kgz2f6Ok755S4tSiF5CWU1nZpT1cf1S8UVXLlNSZdH2M5GAQRn8q0bp/rQAF/Sg6rd91Qr9b2jvOqYZTNkYvEfpVqj0gyrvAMgoiFCl1TzXWggD+dXyHpOK9ELrGPBLnJdfMyV3gGQcRCha6pcpYDUklXIqdsDjcxHoEaq4WSJ4y23UfU2t6hoeGoK683NBxVa3uHlm7d5+rrwFuprqo62pVWAaBQVEQslLzH49MzZ/WT9sPa292nX91xbdHX8NnVHgyZSuSUzQG4hSBiodhk0Lb7iD49czb++Bvdfdq0s6voIYFd7cGQrkSeS3/imhAAckUQsVDihPGT9sMj/syNkMCudmSL6hmAXBFELNY8f5r2dvfpje4+Se6FBHa1I1tUz4KByheKiSBisTFlYf3qjmvPGxDceB2OapENqmf+lBw8Eu+4vKuzV3u7+1QWDhFKkBeCiOUICTAJ1TN/Sl5yq62uGHFBxFhVluU45IMgAknpS62UYJELgrE/JS+5pRO7nICkjGMF4woSEUQgKf0mQzYfAkhecrtt5mXa/vbxlPes+vTMWW38fBN9urGCcQWJCCKQlH6TIZsPAaRacguHQ/EwIUljx4T1f0PnLnY42ljBuIJEBBGfybfkmW6TIZsPAaRacksOJ4kbWEcbKxrrqrUr4X5Gw1FHQ8NRlmcCiiDiE7EAsu3Qh/FyaS4lz3SbDNl8CCCV5HAyNBxVOBTOaqxIvvTAXpcuxgg7EER8InHNNSaXkmeqQSXxlvBPrWjkaAVAWrlsVB5TFlZZOBT/meWZYCOI+ETimmtMIUspbCYD4CaWfRFDEPGJ5BvhTamu0KJrJue9lMJmsmDj9Eq4jWVfxBBEfCLVl7qQiYOjlWDLpiJGWEEhRlvKoX8FB0HEJ4p9ISmOVoItm4oYy3dwE/0rOAgiSIkrZAZbNhUxlu+Qq1yqHPSv4ChZnaulpUWhUEirVq0q1UsCyFPz/GlateAKzftqjVYtuCJlRayxrlqx8x5YvkM2YlWOXZ292th+WJt2dqV9Lv0rOEpSETlw4IC2bNmir3/966V4OQAFyqYixvKdv5RiT0YuVQ76V3C4HkT+93//V0uWLNGTTz6phx9+2O2XA1AiLN/5Syn2ZOSyCZ7+FRyuB5Hm5mZ95zvf0YIFC0YNIoODgxocHIz/HIlE3G4eEDicjYBUSrEngyoHUnE1iPz617/WoUOHdODAgaye39LSogcffNDNJgGBx9kISKUUp+xT5UAqrgWRY8eO6b777tNLL72ksWPHZvV31qxZo9WrV8d/jkQiqq2tdauJQCBxNgJSoVoBr7gWRA4ePKiTJ0+qoaEh/tjw8LBef/11/fSnP9Xg4KDKyspG/J3y8nKVl5e71SQgMDItv5TyYnUsA5kv+TPivlIoNdeCyC233KJ33313xGMrVqzQlVdeqQceeOC8EAKgeDItv5TyyJdlIPOZ8hkRWoPLtSAyfvx4zZgxY8RjF154oSZOnHje4wCKK9PySynX6VkGMl/yZ7T/SJ9a24t3u4hsmRKIUHrETYsMDUfV2t6hpVv3qbW9Q0PDUa+bBEOZcjEoU9qB9JI/o6ijrC86VkyE1uAq6SXeX3311VK+nO9wxIBsmbLx0JR2IL3kz2j/kT5PAgE32gwu7jVjEY4YkC1TTpM0pR1IL/kzam2X9nR9EUaGo46Wbt3n+jINoTW4CCIW4YgB+WIjILKVGAiGo472dveVpApLaA0ugohFOGJAvljWQ7YSA8HSrfuowsJ1BBGLcMSAfLGsh3xQhUUpEESAAGBCQT6Sq7B33VCv1vYOlvhQVAQRC7C+j0KxrId8nL+RtYMlPhQdQcQCpqzvE4jsxbIeioElPriBIGIBU778pgQipEdYhJtKscRHHw4egogFTFnfNyUQIT3CItxUiiU++nDwEEQMNzQcVTTqqLa6QpJ026xLPVvfNyUQIT3TwyJHu3YrxRKf6X0YxUcQMdymnV167JWO+OQfDoU9G7jZ8Gg+08MiR7sYjel9GMVHEDGcSUcHbHg0n+lh0aT+DDOZ3odRfAQRw3F0gFyYHhbpzxiN6X0YxUcQMRxHB7BR8l6Qu26o1xOvH9H+I336xuUTFQ5J19ZPpD8DIIiYjqMD2Ch5L8je7r74zdNCklYtuIJ+DUCSxHZ1AEWXvBfk/30UYW8IgJQIIgCKrrGuWqHPfx+SdNUllSN+Zm8IgBiWZlAwrg2BZKlulvbE60fY6wTgPAQRFIxrQyBZqr1N9AkAqRBEUDCuDWEuqlUATEcQQcG4NoS5qFYBMB1BBDlLdY0IiWudmIhqFfJhWiXNtPaguAgihjL5i8dRtj2oViEfpn3HTWsPiosgYiiTv3gcZduDK/MiH6Z9x01rD4qLIGIok794HGXbgyvzIh+mfcdNaw+KiyBiKJO/eBxloxAmLzviHNO+46a1B8UVchzHGf1p3ohEIqqqqtLAwIAqKyu9bk5JMVjDr1rbO+LLjtx3BvCnXOZvKiKGoqQOvzJ52RFm4YAsGAgiAErK5GVHmMXkTfsoHoIIgJJivd8MNlQbqJ4FA0EEQEmx7GgGG6oNVM+CgSACAAFkQ7Uh1V2cW9s7jK7iIHcEEQAIIBuqDcnVs8Qzrkyt4iB3BBHkzYY1ZgCp2bhXx4YqDnJHEEHebFhjBpCajXt1Eqs4kjQcdbR06z4OhCxHEEHeODpBMVBZQ7YSqzjDUUd7u/s4EPIBgohhbBqUbVhjhvmorCFbiVWcpVv3cSDkEwQRw9g0KNu4xgzzUFlDPjgQ8g+CiGFsGpRtXGOGeZhQkA8OhPyDIGIYBmUEDRMK8sGBkH8QRAzDoIygYUIBgo0gYhgGZWTLpo3NAJAOQQSwTCyAbDv0oXr6T0syf2MzvEVohckIIoBlEs+sijF9YzNKKzl4RJ2oHnu504qz8RA8BBHAMolnVsX4YWMzR+3Fk3wZgNrqCmvOxssGfcVfCCKAZZIvcz2lukKLrpls/Z1JbbqGjumSLwNwMvJ/8T/zQ2ilr/iLq0GkpaVF//7v/673339f48aN0/XXX68f//jH+trXvubmywK+lurMqjFlYevvTGrTNXRMlxxW/28oKumL0Gr72Xj0FX9xNYi89tpram5uVmNjo4aGhrR27VotXLhQf/7zn3XhhRe6+dLWoMSIXKU7s8r2wZlr6BRPLGi07T6iT8+cjT8+pbrCqnCaDn3FX1wNIv/1X/814ue2tjZNmjRJBw8e1A033ODmS1vDLyVGApX3bB+cuYZO8SSG1dj4YmOfSIe+4i8l3SMyMDAgSaquTv1lGBwc1ODgYPznSCRSknZ5ZWg4qm2HPrT6KDbGL4HKZrYNzqnCK32muNL1CdsPHLjekr+ULIg4jqPVq1dr3rx5mjFjRsrntLS06MEHHyxVkzy3aWdX/DoQMbYesdi+LOAHtg3OhFf3pesTvPcwScki8N13360//elPevbZZ9M+Z82aNRoYGIj/OnbsWKma54nkybpq3Je0/0ifWts7NDQc9ahV+Wmsq1bo89/7qQQM9xBevcN7D5OUpCJyzz336Pnnn9frr7+uyZMnp31eeXm5ysvLS9EkIyTvbB84c1a7u/q0p6tPkl1HKLYtC8B7tu9psRnvPUziahBxHEf33HOPtm/frldffVX19fVuvpx1Eifvnv7T8WUaG49QbFsWgPcIr97hvYdJXA0izc3NeuaZZ/Tb3/5W48eP18cffyxJqqqq0rhx49x8aSskTt6J14DgCAVBQHj1Du89TBJyHCf5atHF+8dDoZSPt7W1afny5aP+/UgkoqqqKg0MDKiysrLIrTOL7bvYY/zy/2Ea3lcUA/0IpZLL/O360gyy45cjFHbju4P3FcVAP4KJuNcMiord+O7I9L5ylIts8f2EiRitUFScxuuOTO9r7Ch3V2evNrYf1qadXZ60Eebj+wkTURFBUSXvxrf9jrCmyHSWA0e5yBZny8BEBBEUVfJeF9vvCGuKTHuIuCYEsuWXvWjwF4KIB4K0ps/Ruvs4ygVgM4KIB4K0c52jdfdxlAvAZgQRDwSpSsDROgAgE4KIB4JUJeBoHQCQCUHEA0GoEgRpHwwA7zHm2Isg4oEgVAmCtA8GgPcYc+xFXIQrgrQPBoD3GHPsRUUErgjSPhgUT6y8vv9In6KOFA5J19ZPpMyOUTHm2IsgAlcEYR8Mii+xvB6zp6tPEmV2ZMaYYy+CCFwRhH0wKL7E8noMZXZkgzHHXtQ6ARgj8aZsMZTZAX+jIgJYIginJ8bK6an2iACpBOF74XcEEcASQTg98Yvyur/+v+CeIHwv/I7YCFiC0xOB8/G9sB9BBLBE4v4J9k0A5/C9sB9LM3Ada7jFwemJwPn4XtiPIALXsYZbHJyeCJyP74X9OCyF61jDBQCkQxCB61jDBQCkw9IMXMcaLgAgHYIIXMcaLgAgHZZmAACAZ6iIAAbj1GcAfkcQAQwW9FOfCWKA/xFEAIMF/dTnoAcxIAgIIiXE0R1y1VhXrd2dvXIUzFOfgx7EADeYNhcRREqIozvkKuinPgc9iAFuMG0uIoiUEEd3yFXQT30OehAD3GDaXEQQKSGO7oDcBD2IAW4wbS4iiJQQR3cAAK+ZNheFHMdxRn+aNyKRiKqqqjQwMKDKykqvmwMAMJxpGzGDKpf5m4oISoYBAig+vlcjmbYRE6MjiKBkEgeIXZ292nboQy26ZnLgB06gEEy8I5m2EROjY/RHySQOEJLU039aG9sPa9POLs/aBNiOiXekxrpqhT7/vQkbMTE6KiIlQOn0nMSd2jGOpLbdRyQpsO8LUIjkMyAapkxQa3tHYMcb0zZiYnQEkRKgdHpObEDYduhD9fSfjj/+6Zmz2th+WFIw3xegEMkTb9SJamN7R2DHG075tg9BpAQonZ4TGyCa50/Tpp1datt9RJ+eOSsp2O8LUIjkiXfp1n2MN7BKcOp1HmLNcqTYwLlibj3vC1BkjDewDRWREmDNMjXeF6D4+F7BNlzQDADgS5wo4B0uaAbAV5hQkA9OFLBDSb7JP/vZz1RfX6+xY8eqoaFBf/zjH0vxsoC1hoajam3v0NKt+9Ta3qGh4ajXTfJUbELZ1dnLtWeQNU4UsIPrQeS5557TqlWrtHbtWr311lv65je/qVtvvVU9PT1uvzRgLSbekZhQkA827trB9SDyb//2b7rjjjt055136qqrrtLGjRtVW1urzZs3u/3SgLWYeEdiQkGuhoajikYd1VZXaEp1he695ats3DWUq3tEPvvsMx08eFA//OEPRzy+cOFC7dmz57znDw4OanBwMP5zJBJxs3mAsZKvlhn0iZczQZCrTTu79NgrHfHvUDgUZl+RoVwNIr29vRoeHtbFF1884vGLL75YH3/88XnPb2lp0YMPPuhmkwArMPGOFLv2TGzT6vK2A2xaRUbJVcVthz5ks7OhSnLWTCgUGvGz4zjnPSZJa9as0erVq+M/RyIR1dbWut4+wDRcpjo1zoJAtpLvbdXTf1o9/afpNwZyNYjU1NSorKzsvOrHyZMnz6uSSFJ5ebnKy8vdbBIAi7F3BtlKrCrGQohEvzGRq7WpCy64QA0NDdqxY8eIx3fs2KHrr7/ezZcG4ENsWkW2YlXFp++co0XXTKbfGMz1pZnVq1dr2bJlmj17tq677jpt2bJFPT09ampqcvulAfgMe2fO4QJvuaHfmM31IPK9731PfX19euihh/TRRx9pxowZeuGFFzR16lS3XxqAz7B35hz2yuSGfmO2kmxW/f73v6/vf//7pXgpAPA99srAT6jlAYBl2CsDP+GmdwBgGfY8wE8IIgBgGfY8wE9YmgEAAJ4hiAAAAM+wNAN4hGtBoJjoT7AVQQTwCNeCQCGSg0fUieqxlzvpT7AOQQTwSKprQXBUm72gv1fJQba2uoJri8BKBBGXBH2QxOgS7w4auxYEVZLsBf29Sg6y0rl+lNifABsQRFwS9EESo0t1LYjlbQc4qs1S0K8umhxkb5t5mcLhENcWgXUIIgVKV/lIHiTbdh+RJCojiEt1LYhUVRKkFvT3KlWQZWyBjQgiBUpX+UgcJCXp0zNntbH9cPzPgVS4YuboYuF//5E+fePyiQqHpGvrJwbuveKiZvALgkiB0pWHY4Ni2+4j+vTM2fP+HEiFyWV0ieE/JGnVgit4z4AM0lXuTdnLSBApULrycOKEkjhoBq18DBRb0PeGALlKV7k3ZS8jQaRAo5XSKbUDxRX0vSFArtKFd1NCPUGkQKOV0im1I1umlElNR7gHcpMuvJsS6gkigCFMKZOajnAP5CZdeDcl1BNEAEOYUiYF4C/pwrspoZ66L2CIxrpqhT7/PXsfAAQFFRF4bmg4qsdf7tT2t49Lkm6bdanuuXl64PZHmFImBeBPpu5DI4jAc5t2dqn1lY74z60vdyocMqNkWEqmlElhLlMnEtjB1H1oBBF4LtVeCPZHIFdBmKRNnUhgB1P3ofnrWworpdoLwf4I5Co2Se/q7NXG9sPatLPL6yYVnakTCexg6j40KiLwXPP8aYpGnRF7RNgfgVwFYZI25boPtgpC1SwTU/ehEUTguTFlYd2/8Ardv/AKr5sCiwVhkjZ1IrFF0Je2TN2HRhAB4AtBmKRNnUhsEYSqmY0IIgB8gUkaowlC1cxGBBEAQCAEoWpmI4JIkcQ2Qe0/0qeoI4VD0rX1EwO3GQoATJVcNRsajqq1vSOwm1dNQRApksRNUDF7uvokBWszFADYIuibV01B9CuSxE1QMWyGAgBzsXnVDASRIkm8UEwMm6EAwFymXuAraFiaKZLYpqdUe0QQXEG/gBJgMjavmiHkOE7yioIxIpGIqqqqNDAwoMrKSq+bA+Sstb0jvgYdkrRqwRWsQQPwvVzmbw7NABexBg0AmRFEYLTY6XVLt+5Ta3uHhoajXjcpJ6xBA0Bm7BGB0Ww/vY41aADIjCACo9m+tMFlx93HhmDAbgQRGI17Q2A0tlfNgKAjiMBoLG1gNLZXzQA32VAxJIjAaCxtYDRUzZArGybnYrGhYkgQgZGCNFCgMFTNkCsbJudisaFiSBCBkYI0UKAwVM2QKxsm50LFDuZ6+k/HHzO1YkgQgVFiX5623Ud8P1AA2aJCWFxBWM5LviP8lOoKLbpmspEVQ4IIjJL85ZH8O1AA2aJCWFxBWM5LviP8lOoKY/uMa5H66NGjuuOOO1RfX69x48Zp2rRpWrdunT777DO3XhI+kPzluWjcl7RqwRW+HCiAbAVhKaGUYst5T985R/ctmO7L6pJNV3V2rSLy/vvvKxqN6oknntBXv/pV/fd//7dWrlypv/3tb3r00UfdellYLrlkumJuvbEpHiiVICwloLhsqvqU9O67GzZs0ObNm9Xd3Z3V87n7bvCwFg6cj+8FbJPL/F3SPSIDAwOqrk6f5AcHBzU4OBj/ORKJlKJZMAhnQADn43sBPytZpO7q6tLjjz+upqamtM9paWlRVVVV/FdtbW2pmgcAADyQcxBZv369QqFQxl9vvvnmiL9z4sQJffvb39bixYt15513pv2316xZo4GBgfivY8eO5f5/BAAArJHzHpHe3l719vZmfE5dXZ3Gjh0r6VwImT9/vubMmaOnnnpK4XD22cfUPSKs1wLm4vsJeM/VPSI1NTWqqanJ6rnHjx/X/Pnz1dDQoLa2tpxCiMk4px+5yjQ5MnEWF99PwC6ubVY9ceKEbrrpJk2ZMkWPPvqo/vrXv8b/7Ctf+YpbL1sSnNOPXCVOjrs6e7W3u09l4ZAa66oVdaJ67OVOJs4i4fuJXHAg4D3XgshLL72kzs5OdXZ2avLkySP+rIRnDLuCc/qRq+QLtb3R3SfpXPCora5g4iwivp/IBRU077kWRJYvX67ly5e79c97yqYLxcAMiZNjotjPoc9/z8RZuOb50xSNOtr+9nFJUtSJamg4ylEuUvJbBc3GCg/3mskD5/QjV4nhdTjqaG93Xzx43DbzMoXDIYJtkYwpCyscDulY/2k5kh57uVPhkF3fWRsnE1v5rYJmY4WHIAK4INVEEhsMmGTcZ+NRbmK/SAyrtkwmtvJbhdvGvk8QKQATCtLJdFRCRc19Nh7lprrztGTPZGIrv30fbez7BJEC2FgCQ2nYeFTiJzYe5SZvaI6xZTKBGWzs+wSRAjDZIB0bj0r8xMaj3OQNzdddPjF+ircNk4nt/FLhtrHvE0QKwGSDdGw8KoG3UvUZGydCW1Hh9g5BpABMNkjHxqMSeIs+4y0q3N4hiBSAgQMA/IEKt3cIIgB8yy/r/nAfFW7vEETSYAAD7Me6P7JFhds7BJE0GMAA+9m47s9BEIKGIJKGjQMYgJFsXPfnIAhBQxBJw8YBDMBINq77cxCEoCGIpGHjAAZgJBvX/TkIMgfLZKVBEEnDxgEMZmNQQzY4CDIHy2SlQRABSoRBDdlIPAgivHrLpmUym/sKQQQoEZsGNZiB8OotG5bJYgFk26EP1dN/WpJ9fYUgApSIDYMazEJ49ZYNy2SJYTXGtr5CEIE1bC49SnYMan5la98hvHrLhr2CiWE1xra+QhCBNWwvU9swqPmVrX2H8IrRJIZVSZpSXaFF10y2qq8QRGANytTIl619h/DqHVuqaKnCqontzIQgAmtQpka+6DvIlS1VND+EVYIIrEGZGvmi7yBXtlbRbEQQgTX8kPzhDfoOckUVrXQIIgAAJKGKVjoEEQAAklBFKx2CCAB4yJazMwC3EERgHQZu+IktZ2eAscctBBFYh4EbfsLZGfZg7HEHUS4HQ8NRtbZ3aOnWfWpt79DQcNTrJgUSAzf8pLGuWqHPf8/ZGWZj7HEHFZEMkstwUSeqx17uJA2XWPLn0DD1Ik6rg29wdoZZMi2/cEqvOwgiGSSX4WqrK0jDHkj+HO69ebpWLbiCgRu+wNkZZsm0/EJodAdBJIPkMpx0LgWThksr+XM42POJnr5zjpdNAuBTmZZfCI3uIIhkkFyGu23mZQqHQ6ThEqMcCqBUbBhv/Hb2DkEkg1jQ2H+kT1FHevN/+nVt/UQ9taLR6g/dNunKoX77MiJY6L9msmH5xW9n7xBEMoiV4VrbFf/Q93T1SbL7Q7dNunKo376MCBb6r5nyXX4pZbBMXj5q231EkqwNswSRLHDKlpn4XJAPUyoR9F9/KUWwjPXdnv7TIx7/9MxZbWw/7MprloJ90ckDnOdvJj4X5CM2Yezq7NXG9sPatLPLk3bQf/2lFMEy1ndjQWTsmC+mcJvDLBWRLNiwZhhEJn0uphxlY3SmVCJM6r8oXCk2uSb2XUmaVDlWx/pPG72xNhsEkSTpJhQby11+l/i5eB0EWO+3hylnRTCu+EspgqVfz+QkiCRhQrGT15+bKUfZGB2VCLjBzWAZO9Daf6RP37h8osIh6dr6ib6pvBJEkjCh2KmQz60Y1RRTjrIxOioRsE3igVZI0qoFV/iqDxNEkjCh2KmQz60Y1RSOsgG4xe8HyASRJEwodirkcyvGl5yjbDt4vZcIyIffD5AJIkmYUOxUyOdWzC85E53ZvN5LBOTD7wfIBBEEXrZf8mxCBhOd2fxe4oY/+f0AuSRBZHBwUHPmzNE777yjt956SzNnzizFywIjpAsS2X7JswkZTHRm83uJG7BRSYLID37wA1166aV65513SvFyQEqFViuyCRlMdGbze4kbpcVSbHG4HkRefPFFvfTSS9q2bZtefPFFt18ub3Qo/yu0WpFNyGCiM5vfS9woLZZii8PVIPKXv/xFK1eu1H/8x3+ooqJi1OcPDg5qcHAw/nMkEnGzeSPQofyv0GpFNiGDiQ4IDpZii8O1IOI4jpYvX66mpibNnj1bR48eHfXvtLS06MEHH3SrSRnRofyv0GoFIQNAIpZiiyPnILJ+/fpRw8KBAwe0Z88eRSIRrVmzJut/e82aNVq9enX850gkotra2lybmBc6lP8RJADkI93SvRtLsUHcJhByHMcZ/Wlf6O3tVW9vb8bn1NXV6fbbb9d//ud/KhQKxR8fHh5WWVmZlixZol/84hejvlYkElFVVZUGBgZUWVmZSzNzFsQPH/mhr/hD4v07oo5yvn8H/SA4Wts7SnaJ9VK+lptymb9zrojU1NSopqZm1Oc99thjevjhh+M/nzhxQt/61rf03HPPac6cObm+rOs4WrZXqScE9hP5Q+LnGLOnq09Sdp8n/SA43Fq6TzV2BXGbgGt7RKZMmTLi5y9/+cuSpGnTpmny5MluvSwCqNQTQhAHCj9K/Bxjsvk8Y5NH2+4j9IOAcGvpPtXYFcRtAlxZFdZLFQzcrJIEcaDwo8TPMSabzzNVJWW0v8cyjt3cOi0/1dj11IpGV17LZCULInV1dcpxOwqQlVTBwM0qCdcK8YfY55Zqj0gmyZWUi8Z9SSvm1mf8e4n9cVdnr/Z296ksHCKUWMKtpfvkMDwcdbS87YAa66r11IrGwPSLQFdEOErxh1TBYHnbgaKWzVP3FfYD2OyLySW3zzE5+K6YWz/qJJUcXt7oPrcXhb0lwZY4dg1HHe3t7gvknqNABxE2m/lD4tFKLDD09J+O/3kxlk/oK4jJpyKWahlIYm9J0CWOXUu37gvsnqNABxE2HfpP8vr9lOoKLbpmcsHLJ5n6CpW1YMmnTB/rf9sOfTgiJEvsMbJdsb7/Qd57FuggEuQP3q+SS+BTqiuKUrlI1VdiA1Di5EK1xN/ynXRi4eXA0f4RQWRKdQV7jCxXrGppkPeeBTqIBPmD9yu3wmWqvpLq7Akqa/5W6KST3D8XXTOZ6pnlsqmsZxNgg3wtq0AHkSB/8H5VaLhMN2Ck6iuprkNBZc3fcl3OTe5Pd91QH/93OPjxh2wOfgoJsEFY+g10EIH/FBoucxkwkjcgFms/CsyRPAk0TL0op4obm5z9L5uDn0L2IwahDxFEEAjZHlXkMmCkGoD8dqQSdMmTwL03T9eqBVdkXdFgQ7z/ZXPwU8iScRD6EEEEgZDtUUVylaOn/7Ra2ztY0w2o5EngYM8nevrO7O+VxYZ4SPktGbt1KQITEUTga7neFyT5NMue/tPa2H5Ykv/KoRhdoUGCDfGQMh+0pKvWunUpAhMRROBrme4Lkm4ASD7N0q/lUIwu3yCR3LeCdLlu5CZdtdatSxGYiCACX8t0X5BMyzWU1CHlv/wWhA2GKI50e0CCNAYRROBrme4LkmkTGCV1FCIIGwxRHOkCR5DGIIIIfC3TlznTEQcbUZGrxOWY4aijkBSIo1lkL9VycLoxKkhjEEEEvpbpyxykIw6MrtALRyXvR7ru8okqC4foW4hLt2QXlMCRTuCDSBCuWofUgnTEgdEVuq8jeT9SWTiU06m+sEe+8wZLdqkFfsaNDT67Onu1sf2wNu3s8rpJADxQ6CTRWFet0Oe/ZznG3/KdNxL7iPTFdYqGhqPuNNQSgayIJKbZnv7TJNSAoQqGVIp1zZD9R/oUdc79t7Vd9C8fyje0cp2i1AIZRFJdW0LiKCYoOLUSqSTuGWqYMkFRJ6qlW/dlHVZjS32t7Yr3rz1dfZLoX36Tb2jlOkWpBTKIpLpQzJTqCjaVBQTrtEglcc9Qa3uHNrZ35BVW6V/+V+hG9yBdIyQbgQwiyZ1g0TWTOWIJEAYBjKaQMEH/8r98LtmeiDP2RgpkEKETBBufP0ZTSJigfwVb4tLvrs5e7e3uG3Ea95iyMGfsJQk5jpO8VcIYkUhEVVVVGhgYUGVlpdfNQQCxsTWY+NyRr6Vb92nX58t5iUKSVi24IjABJJf5O5AVESBbbGwNpuQj1qHhqFrbOwgmGFViNS0R+4XSI4gAGbDxEBKBFNlLXJobjjra293HfqFREESADNh4CIlAiuwlVtNSLfHhfAQRQOn3BLDxEFLmQMp+EqTDptTsEEQApS+9M5BAynwmDMs2QGEIIoAovSOzTIGUvgMUhvohIG5YhvzRd4DCUBEBxEWokD/6DlAYLmgGAACKKpf5m6UZAADgGYIIAADwDHtEAAAoMq4vkz2CCAAARcb1ZbJHPAMAoMi4vkz2CCIAABQZ15fJHkszAAAUGdeXyR5BBACAIuM+VdljaQYAAHiGIAIAADxDEAEAAJ4hiAAAAM8QRAAAgGdcDyK///3vNWfOHI0bN041NTX67ne/6/ZLAgAAS7h6+u62bdu0cuVKPfLII7r55pvlOI7effddN18SAABYxLUgMjQ0pPvuu08bNmzQHXfcEX/8a1/7mlsvCQAALOPa0syhQ4d0/PhxhcNhzZo1S5dccoluvfVWvffee2n/zuDgoCKRyIhfAADAv1wLIt3d3ZKk9evX60c/+pF+97vfacKECbrxxhvV35/65j8tLS2qqqqK/6qtrXWreQCQ0tBwVK3tHVq6dZ9a2zs0NBz1ukmAr+UcRNavX69QKJTx15tvvqlo9NyXd+3atVq0aJEaGhrU1tamUCik3/zmNyn/7TVr1mhgYCD+69ixY4X93wFAjmK3b9/V2auN7Ye1aWeX100CfC3nPSJ33323br/99ozPqaur06lTpyRJV199dfzx8vJyXX755erp6Un598rLy1VeXp5rkwCgaLh9O1BaOQeRmpoa1dTUjPq8hoYGlZeX64MPPtC8efMkSWfPntXRo0c1derU3FsKACXQWFet3Z29csTt24FScO2smcrKSjU1NWndunWqra3V1KlTtWHDBknS4sWL3XpZACgIt28HSsvV64hs2LBBY8aM0bJly3TmzBnNmTNHr7zyiiZMmODmywJA3rh9O1BaIcdxnNGf5o1IJKKqqioNDAyosrLS6+YAAIAs5DJ/c68ZAADgGYIIAADwDEEEAAB4hiACAAA8QxABAACeIYgAAADPEEQAAIBnCCIAAMAzBBEAAOAZgggAAPAMQQQAAHjG1ZveFSp2G5xIJOJxSwAAQLZi83Y2t7MzOoicOnVKklRbW+txSwAAQK5OnTqlqqqqjM8x+u670WhUJ06c0Pjx4xUKhTxpQyQSUW1trY4dO8YdgFPg/UmP9yYz3p/MeH8y4/3JzOv3x3EcnTp1SpdeeqnC4cy7QIyuiITDYU2ePNnrZkiSKisr6ewZ8P6kx3uTGe9PZrw/mfH+ZObl+zNaJSSGzaoAAMAzBBEAAOAZgsgoysvLtW7dOpWXl3vdFCPx/qTHe5MZ709mvD+Z8f5kZtP7Y/RmVQAA4G9URAAAgGcIIgAAwDMEEQAA4BmCCAAA8AxBJEe///3vNWfOHI0bN041NTX67ne/63WTjDM4OKiZM2cqFArp7bff9ro5Rjh69KjuuOMO1dfXa9y4cZo2bZrWrVunzz77zOumeeZnP/uZ6uvrNXbsWDU0NOiPf/yj100yQktLixobGzV+/HhNmjRJf//3f68PPvjA62YZqaWlRaFQSKtWrfK6KcY4fvy4li5dqokTJ6qiokIzZ87UwYMHvW5WRgSRHGzbtk3Lli3TihUr9M4772j37t36x3/8R6+bZZwf/OAHuvTSS71uhlHef/99RaNRPfHEE3rvvff0k5/8RD//+c/1T//0T143zRPPPfecVq1apbVr1+qtt97SN7/5Td16663q6enxummee+2119Tc3Ky9e/dqx44dGhoa0sKFC/W3v/3N66YZ5cCBA9qyZYu+/vWve90UY3zyySeaO3euvvSlL+nFF1/Un//8Z/3rv/6rLrroIq+blpmDrJw9e9a57LLLnK1bt3rdFKO98MILzpVXXum89957jiTnrbfe8rpJxvqXf/kXp76+3utmeOLaa691mpqaRjx25ZVXOj/84Q89apG5Tp486UhyXnvtNa+bYoxTp04506dPd3bs2OHceOONzn333ed1k4zwwAMPOPPmzfO6GTmjIpKlQ4cO6fjx4wqHw5o1a5YuueQS3XrrrXrvvfe8bpox/vKXv2jlypX61a9+pYqKCq+bY7yBgQFVV1d73YyS++yzz3Tw4EEtXLhwxOMLFy7Unj17PGqVuQYGBiQpkH0lnebmZn3nO9/RggULvG6KUZ5//nnNnj1bixcv1qRJkzRr1iw9+eSTXjdrVASRLHV3d0uS1q9frx/96Ef63e9+pwkTJujGG29Uf3+/x63znuM4Wr58uZqamjR79myvm2O8rq4uPf7442pqavK6KSXX29ur4eFhXXzxxSMev/jii/Xxxx971CozOY6j1atXa968eZoxY4bXzTHCr3/9ax06dEgtLS1eN8U43d3d2rx5s6ZPn64//OEPampq0r333qtf/vKXXjcto8AHkfXr1ysUCmX89eabbyoajUqS1q5dq0WLFqmhoUFtbW0KhUL6zW9+4/H/hXuyfX8ef/xxRSIRrVmzxusml1S270+iEydO6Nvf/rYWL16sO++806OWey8UCo342XGc8x4Lurvvvlt/+tOf9Oyzz3rdFCMcO3ZM9913n55++mmNHTvW6+YYJxqN6pprrtEjjzyiWbNm6a677tLKlSu1efNmr5uW0RivG+C1u+++W7fffnvG59TV1enUqVOSpKuvvjr+eHl5uS6//HJfb7DL9v15+OGHtXfv3vPuazB79mwtWbJEv/jFL9xspmeyfX9iTpw4ofnz5+u6667Tli1bXG6dmWpqalRWVnZe9ePkyZPnVUmC7J577tHzzz+v119/XZMnT/a6OUY4ePCgTp48qYaGhvhjw8PDev311/XTn/5Ug4ODKisr87CF3rrkkktGzFGSdNVVV2nbtm0etSg7gQ8iNTU1qqmpGfV5DQ0NKi8v1wcffKB58+ZJks6ePaujR49q6tSpbjfTM9m+P4899pgefvjh+M8nTpzQt771LT333HOaM2eOm030VLbvj3TutLr58+fHq2nhcDALkhdccIEaGhq0Y8cO3XbbbfHHd+zYob/7u7/zsGVmcBxH99xzj7Zv365XX31V9fX1XjfJGLfccovefffdEY+tWLFCV155pR544IFAhxBJmjt37nmneh8+fNj4OSrwQSRblZWVampq0rp161RbW6upU6dqw4YNkqTFixd73DrvTZkyZcTPX/7ylyVJ06ZN42hO54LZTTfdpClTpujRRx/VX//61/iffeUrX/GwZd5YvXq1li1bptmzZ8erQz09PYHcM5OsublZzzzzjH77299q/Pjx8cpRVVWVxo0b53HrvDV+/Pjz9spceOGFmjhxIntoJN1///26/vrr9cgjj+gf/uEftH//fm3ZssX46itBJAcbNmzQmDFjtGzZMp05c0Zz5szRK6+8ogkTJnjdNBjupZdeUmdnpzo7O88LZk4Ab4D9ve99T319fXrooYf00UcfacaMGXrhhReMP3Irhdh6/k033TTi8ba2Ni1fvrz0DYI1GhsbtX37dq1Zs0YPPfSQ6uvrtXHjRi1ZssTrpmUUcoI4CgIAACMEc5EaAAAYgSACAAA8QxABAACeIYgAAADPEEQAAIBnCCIAAMAzBBEAAOAZgggAAPAMQQQAAHiGIAIAADxDEAEAAJ4hiAAAAM/8f25StOgrToNPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(-2*np.pi, 2*np.pi, size)\n",
    "A, B, C = np.random.uniform(0.5, 2*np.pi, size=3)\n",
    "y = A*np.sin(B*t + C)\n",
    "x = y + np.random.normal(0, std, size)\n",
    "\n",
    "plt.scatter(t, x, s=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab8bc76b-75b8-434a-9746-d66fd6dabb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(t, y, s=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546afbe9-5108-4755-94f6-14ed2bda079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_tensor = tf.reshape(tf.constant(x), (1, -1)) # to change the shape from (254,) to (1, 254)\n",
    "# the first dimension is always the batch dimension even if there is only one data!\n",
    "\n",
    "y_pred = model.predict(x_tensor)\n",
    "plt.scatter(t, y_pred[0], s=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671aca48-ed38-43f5-9b15-8eb1919d5b30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36358c7a-0a30-4448-908b-8bc8c3e856fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = handson.mnist_TF(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "455eae85-cdc8-47df-a370-aae0fc478b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.Input((28, 28, 1)),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22ca14b-3ab0-4bc0-afaf-60feda628182",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "loss_metric = keras.metrics.SparseCategoricalCrossentropy(from_logits=False)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def update_acc(model, ds_test, acc):\n",
    "    acc.reset_state() # to make sure acc is reset\n",
    "    for x_batch, y_batch in ds_test:\n",
    "        y_pred = model(x_batch, training=True)\n",
    "        acc.update_state(y_batch, y_pred)\n",
    "\n",
    "    return f\"{acc.result().numpy():.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8ddad2-bff1-49dc-810d-ace25d3ff0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]: █████████████████████████████ :1024/1024 [ET=00:18, acc=0.933, loss=237.6m, test=0.970]\n",
      "Epoch [2/3]: █████████████████████████████ :1024/1024 [ET=00:15, acc=0.974, loss=089.8m, test=0.978]\n",
      "Epoch [3/3]: █████████████████████████████ :1024/1024 [ET=00:15, acc=0.980, loss=068.6m, test=0.978]\n"
     ]
    }
   ],
   "source": [
    "# tqdm module to wrap train data to show progress bar with custom inputs\n",
    "num_batches = ds_train.cardinality().numpy()\n",
    "custom_bar_format = \"{desc}{bar} :{n_fmt}/{total_fmt} [ET={elapsed}{postfix}]\"\n",
    "fixed_width = 100 # size of the output (progress bar size will be adjusted accordingly)\n",
    "z_num = len(str(num_epochs)) # for proper description text sizing\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # train dataset iterable with progress bar\n",
    "    train_iterator = tqdm(\n",
    "        ds_train, \n",
    "        bar_format=custom_bar_format,\n",
    "        ncols=fixed_width,\n",
    "        total = num_batches,\n",
    "        leave=True)\n",
    "\n",
    "    # message before progress bar \n",
    "    epoch = str(epoch+1).zfill(z_num)\n",
    "    train_iterator.set_description(\"Epoch [\" + epoch + f\"/{num_epochs}]\")\n",
    "    acc_test = \".....\"\n",
    "\n",
    "    # batch training for loop\n",
    "    for ind, (x_batch, y_batch) in enumerate(train_iterator):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch, training=True)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "\n",
    "        # get gradients and optimize the loss with respect to weights\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # obtain loss and accuracy numerals to show after progress bar\n",
    "        loss_metric.update_state(y_batch, y_pred)\n",
    "        loss=mods.float2SI(loss_metric.result().numpy())\n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "        acc=f\"{acc_metric.result().numpy():.3f}\"\n",
    "        if ind+1 == num_batches: acc_test = update_acc(model, ds_test, acc_metric)\n",
    "\n",
    "        # add loss, acc, and test accuracy script after progress bar\n",
    "        train_iterator.set_postfix(loss=loss, acc=acc, test=acc_test)\n",
    "\n",
    "    # end of epoch training: reset metrics for later epoch loops\n",
    "    loss_metric.reset_state()\n",
    "    acc_metric.reset_state()\n",
    "\n",
    "acc_metric.reset_states() # alias of reset_state() for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fae868c-9fdb-4c6d-8845-6a719276cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 1, 32)\n",
      "(3, 3, 1, 32)\n",
      "conv2d/kernel:0\n",
      "\n",
      "(32,)\n",
      "(32,)\n",
      "conv2d/bias:0\n",
      "\n",
      "(21632, 10)\n",
      "(21632, 10)\n",
      "dense/kernel:0\n",
      "\n",
      "(10,)\n",
      "(10,)\n",
      "dense/bias:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, weight in enumerate(model.weights):\n",
    "    print(gradients[index].shape)\n",
    "    print(weight.shape)\n",
    "    print(weight.name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e49cf1-ac4a-4d70-bee1-f1a723c33194",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gradient Accumulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bca2972-888a-47e7-bfa1-97241087fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "ds_train, ds_test = handson.mnist_TF(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17df226b-68e8-49e2-b56e-b9df82cc81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.Input((28, 28, 1)),\n",
    "    keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a404842-32a3-4697-b836-161467d3e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "loss_metric = keras.metrics.SparseCategoricalCrossentropy(from_logits=False)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# optimizer has smaller learning rate since gradients will be combined\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "def update_acc(model, ds_test, acc):\n",
    "    acc.reset_state() # to make sure acc is reset\n",
    "    for x_batch, y_batch in ds_test:\n",
    "        y_pred = model(x_batch, training=True)\n",
    "        acc.update_state(y_batch, y_pred)\n",
    "\n",
    "    return f\"{acc.result().numpy():.3f}\"\n",
    "\n",
    "def grad_shape_dtype(model):\n",
    "    for weight in model.trainable_weights:\n",
    "        yield weight.shape, weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a11a6bd3-b0d7-4b4a-b384-ce3e4b132f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]: █████████████████████████████ :1024/1024 [ET=01:03, acc=0.971, loss=106.4m, test=0.974]\n",
      "Epoch [2/3]: █████████████████████████████ :1024/1024 [ET=01:03, acc=0.981, loss=068.8m, test=0.975]\n",
      "Epoch [3/3]: █████████████████████████████ :1024/1024 [ET=01:03, acc=0.986, loss=051.6m, test=0.980]\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "num_batches = ds_train.cardinality().numpy() # total number of batches per epoch\n",
    "mini_batch_size = 4 # size of mini batch of epoch batches\n",
    "custom_bar_format = \"{desc}{bar} :{n_fmt}/{total_fmt} [ET={elapsed}{postfix}]\"\n",
    "fixed_width = 100 # size of the output (progress bar size will be adjusted accordingly)\n",
    "z_num = len(str(num_epochs)) # for proper description text sizing\n",
    "\n",
    "# zero gradients to initialize gradients for grad accumulation\n",
    "grad_zeros = [tf.zeros(shape, dtype=dtype) for shape, dtype in grad_shape_dtype(model)]\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # train dataset iterable with progress bar\n",
    "    train_iterator = tqdm(\n",
    "        ds_train, \n",
    "        bar_format=custom_bar_format,\n",
    "        ncols=fixed_width,\n",
    "        total = num_batches,\n",
    "        leave=True)\n",
    "\n",
    "    # message before progress bar \n",
    "    epoch = str(epoch+1).zfill(z_num)\n",
    "    train_iterator.set_description(\"Epoch [\" + epoch + f\"/{num_epochs}]\")\n",
    "    acc_test = \".....\"\n",
    "\n",
    "    # batch training for loop\n",
    "    for ind, (x_batch, y_batch) in enumerate(train_iterator):\n",
    "        # number of mini batches of epoch batch\n",
    "        num_mini_batches = x_batch.shape[0] // mini_batch_size\n",
    "\n",
    "        # reshape the dataset batch for inner mini batch for loop\n",
    "        x_batch_reshaped = tf.reshape(x_batch, \n",
    "            (num_mini_batches, mini_batch_size, *x_batch.shape[1:]))\n",
    "        y_batch_reshaped = tf.reshape(y_batch, \n",
    "            (num_mini_batches, mini_batch_size, *y_batch.shape[1:]))\n",
    "\n",
    "        # initialize gradients to zero\n",
    "        gradients = deepcopy(grad_zeros)\n",
    "        \n",
    "        # obtain gradients of mini batches for gradients accumulation\n",
    "        for x_data, y_data in zip(x_batch_reshaped, y_batch_reshaped):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_data, training=True)\n",
    "                loss = loss_fn(y_data, y_pred)\n",
    "    \n",
    "            # get smaller gradients and add them to accumulated gradients\n",
    "            mini_grads = tape.gradient(loss, model.trainable_weights)\n",
    "            gradients = [g1 + g2 for g1, g2 in zip(gradients, mini_grads)]\n",
    "\n",
    "        # optimize the weights from accumulated gradients\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # obtain loss and accuracy numerals to show after progress bar\n",
    "        y_pred = model(x_batch)\n",
    "        loss_metric.update_state(y_batch, y_pred)\n",
    "        loss=mods.float2SI(loss_metric.result().numpy())\n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "        acc=f\"{acc_metric.result().numpy():.3f}\"\n",
    "        if ind+1 == num_batches: acc_test = update_acc(model, ds_test, acc_metric)\n",
    "\n",
    "        # add loss, acc, and test accuracy script after progress bar\n",
    "        train_iterator.set_postfix(loss=loss, acc=acc, test=acc_test)\n",
    "\n",
    "    # end of epoch training: reset metrics for later epoch loops\n",
    "    loss_metric.reset_state()\n",
    "    acc_metric.reset_state()\n",
    "\n",
    "acc_metric.reset_states() # alias of reset_state() for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4e3bd82-7603-4f88-ab56-f8487e821481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06453507393598557, 0.98046875]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc77ac-4d72-4248-8227-ad4107e6982a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b91492a7-66cc-48b5-9cf8-c564ecca13a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360373d-8b92-4621-9003-b3317d1d699b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
