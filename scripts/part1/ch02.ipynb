{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{RMSE} (\\textbf{X},h) = \\sqrt{\\frac{1}{m} \\sum\\limits_{i = 1}^m (h(\\textbf{x}^{(i)}) - y^{(i)})^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above performance measure called *root mean squared error*, $m$ is the number of instances in the dataset, $\\textbf{x}^{(i)}$ is a vector of all the feature values for $i\\text{th}$ instance, $\\textbf{X}$ is a matrix containing all the feature values of all instances in the dataset, $h$ is the system's prediction function, also called a hypothesis. $\\text{RMSE} (\\textbf{X},h)$ is the cost function measured on the set of examples using the hypothesis $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{MAE} (\\textbf{X},h) = \\frac{1}{m} \\sum\\limits_{i = 1}^m |h(\\textbf{x}^{(i)}) - y^{(i)}| $\n",
    "\n",
    "*mean absolute error* is another cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data snooping* refers to statistical inference that the researcher decides to perform after looking at the data (as contrasted with pre-planned inference, which the researcher plans before looking at the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*stratified sampling* is a method of sampling from a population which can be partitioned into subpopulations called strata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*standard correlation coefficient* is also called *Pearson's r*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-learn, any object that can estimate some parameters based on a dataset is called an *estimator* (e.g., an imputer is an estimator). The estimation itself is performed by the **fit()** method, and it takes only a dataset as a parameter (or two for supervised learning algorithms; the second dataset contains the labels). Any other parameter needed to guide the estimation process is considered a hyperparameter (such as an imputer ’s strategy ), and it must be set as an instance variable (generally via a constructor parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some estimators (such as an imputer ) can also transform a dataset; these are called *transformers*. Once again, the scikit-learn API is simple: the transformation is performed by the **transform()** method with the dataset to transform as a parameter. It returns the transformed dataset. This transformation generally relies on the learned parameters, as is the case for an imputer . All transformers also have a convenience method called **fit_transform()** that is equivalent to calling fit() and then transform() (but sometimes fit_transform() is optimized and runs much faster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some estimators, given a dataset, are capable of making predictions; they are called *predictors*. For example, the LinearRegression model is a predictor. A predictor has a **predict()** method that takes a dataset of new instances and returns a dataset of corresponding predictions. It also has a **score()** method that measures the quality of the predictions, given a test set (and the corresponding labels, in the case of supervised learning algorithms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*One hot encoding* is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction. In implementing one hot encoding, you would have to create new attributes, sometimes called *dummy* attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SciPy Sparse matrices* are memory efficient data structures that enable us store large matrices with very few non-zero elements aka sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature scaling* is a method used to normalize the range of independent variables or features of data. There are two common ways to get all attributes to have the same scale: *min-max scaling* and *standardization*. Min-max scaling (many people call this normalization) is the simplest: values are shif‐ ted and rescaled so that they end up ranging from 0 to 1. Standardization is different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *loss function* is a part of a cost function which is a type of an *objective function*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a vector $\\boldsymbol{v} = (v_{1}, v_{2}, ..., v_{n-1}, v_{n})$, a norm of $v$ is writte as $\\parallel \\boldsymbol {v} \\parallel$, and defined as\n",
    "\n",
    "$\\parallel \\boldsymbol {v} \\parallel = \\sqrt{\\sum\\limits_{i = 1}^n v_{i}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cost function of **LinearRegression()** from scikit-learn is ordinary least squares, which is\n",
    "\n",
    "$\\parallel \\textbf{y - Xw}\\parallel^2$\n",
    "\n",
    "where $\\textbf{w}$ is a vector containing coefficients of the linear equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model on top of many other models is called *Ensemble Learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bootstrapping* is any test or metric that uses random sampling with replacement, meaning the multiple instances of the same original sample from the data can be present in the sampling data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is probably RMSE^2, and NMSE is probably -MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE, *Standard error*, is equal to SD divided by a square root of number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
